{"meta":{"title":"彤哥哥的博客","subtitle":"为梦想而战","description":"95后,技术爱好者","author":"YeaMin","url":"http://ltyeamin.github.io"},"pages":[{"title":"李彤","date":"2017-12-02T08:42:39.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"about/index.html","permalink":"http://ltyeamin.github.io/about/index.html","excerpt":"","text":"👱简介李彤,90后,陕西西安人,目前在上海工作.闲暇时间喜欢技术钻研,技术略杂,但小有成就.欢迎技术人员多多交流.业余爱好喜欢摄影和旅游,正准备入手Canon 80D单反相机,这是我一直以来的追求. 💻我的技术栈Java: 日常开发语言,主要构建企业级Web应用.熟悉Maven+Spring Boot+Spring Cloud+MybatisJavaScript: Web开发必会语言.熟悉ES6+Vue2.0+NodeJs+Express/KoaPython: 目前暂时用不到,我主要用于做爬虫以及数据分析.运维: Linux+Jenkins+Docker 🎵我所喜欢的音乐 💫梦想 曾经的梦想:组建一家属于自己的公司-【奕明创意传媒-YeaMin】,很明显这个计划失败了. 现在的梦想: 买房+健康+家庭 = 提高人生品质 ☎️联系方式 邮箱: ltyeamin@gmail.com 微信: YeaMin2014 QQ: 1301015490"}],"posts":[{"title":"Linux基础-SSH免密登录","slug":"Linux基础-SSH免密登录","date":"2019-11-23T05:01:17.000Z","updated":"2019-11-23T03:10:40.215Z","comments":true,"path":"2019/11/23/Linux基础-SSH免密登录/","link":"","permalink":"http://ltyeamin.github.io/2019/11/23/Linux基础-SSH免密登录/","excerpt":"","text":"Linux SSH登录由两种方式: 账户密码登录 密钥登录 我有两台主机，ip分别为192.168.5.1和192.168.5.100，我要从前者远程登录到后者主机上，下面我分别来演示一下两种方式: 账号密码登录1ssh root@192.168.5.100 注意： 默认端口号是22,如果不是22需要加入-p+端口号进行登录，比如远程登录示例: 123456789101112litong@LT:~$ ssh -p22 root@192.168.5.100root@192.168.5.100's password: Last login: Sat Nov 23 18:34:53 2019 from 192.168.5.1[root@localhost ~]# ifconfig ens33ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.5.100 netmask 255.255.255.0 broadcast 192.168.5.255 inet6 fe80::79ad:6fa6:c473:3647 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:b3:a4:0f txqueuelen 1000 (Ethernet) RX packets 281 bytes 40054 (39.1 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 211 bytes 37007 (36.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 公钥免密登录 先在192.168.5.1这太机器上生成公钥； 1ssh-keygen -t rsa 执行上述命令后，敲三次回车即可生成，生成后会在当前账号的home的.ssh目录中。 12345678910litong@LT:~$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/home/litong/.ssh/id_rsa): /home/litong/.ssh/id_rsa already exists.Overwrite (y/n)? litong@LT:~$ ls -l ~/.ssh/总用量 12-rw------- 1 litong litong 1675 9月 10 22:03 id_rsa-rw-r--r-- 1 litong litong 400 9月 10 22:03 id_rsa.pub-rw-r--r-- 1 litong litong 2214 11月 20 21:54 known_hosts ​ authorized_keys:存放远程免密登录的公钥,主要通过这个文件记录多台机器的公钥,这个文件可以没有； id_rsa : 生成的私钥文件； id_rsa.pub ： 生成的公钥文件； know_hosts : 已知的主机公钥清单。 注意: ​ 1). ssh目录的权限必须是700 ​ 2). .ssh/authorized_keys文件权限必须是600 确认公钥文件id_rsa.pub是否存在，并把公钥文件上传到远程登录的机器上。 复制文件有多种方式： 通过ssh-copy-id的方式 1ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.5.100 通过scp将内容写到对方的文件中 1scp -p ~/.ssh/id_rsa.pub root@192.168.5.100:/root/.ssh/authorized_keys 上传成功后，查看远程主机~/.ssh/authorized_keys文件的内容，其中内容包含要远程主机的公钥则说吗配置完成 192.168.5.1机器公钥12litong@LT:~/.ssh$ cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDEeCQP2arzLybGinLvKEgN6cJtINUhDL8uLIwaCJdsv7FbYrBK9R2I01F+pftjiiILCrg0GgwSThAJ7cCxbmriw+D1ZoZdC+MJPONiv4PF9KBWNTGdZ1fLjpEifUI3Aax23TdQqkHs+4+T8zOK2v4MsDgit4nqJheV2I+cXuumPlCONndfr43KxPsGJqAtb8yzkMA20/r8fnnOMbfblDnsAOTGWjC+ond2Eph5AlY2tW+s9JiFBHVawalheqYBVmKlNT3vqVp5IKrnJrIVagN59FKqSOAYTFc/7eR61npGtf0+Ftew137FICGp7F6v4JxjqNuSkxsXsH6+2Z071A3X ltyeamin@gmail.com 192.168.5.100远程机器免密登录公钥12root@localhost .ssh]# cat authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDEeCQP2arzLybGinLvKEgN6cJtINUhDL8uLIwaCJdsv7FbYrBK9R2I01F+pftjiiILCrg0GgwSThAJ7cCxbmriw+D1ZoZdC+MJPONiv4PF9KBWNTGdZ1fLjpEifUI3Aax23TdQqkHs+4+T8zOK2v4MsDgit4nqJheV2I+cXuumPlCONndfr43KxPsGJqAtb8yzkMA20/r8fnnOMbfblDnsAOTGWjC+ond2Eph5AlY2tW+s9JiFBHVawalheqYBVmKlNT3vqVp5IKrnJrIVagN59FKqSOAYTFc/7eR61npGtf0+Ftew137FICGp7F6v4JxjqNuSkxsXsH6+2Z071A3X ltyeamin@gmail.com 尝试免密登录。 12litong@LT:~/.ssh$ ssh root@192.168.5.100Last login: Sat Nov 23 19:07:01 2019 from 192.168.5.1 总结 日常工作中，免密登录用处特别多，项目部署的时候上传时候需要免密登录，不可能将密码原文设置到配置文件中，这样特别不安全。","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ltyeamin.github.io/tags/Linux/"}]},{"title":"RocketMQ概述","slug":"RocketMQ概述","date":"2019-11-08T14:15:16.000Z","updated":"2019-11-23T04:18:53.354Z","comments":true,"path":"2019/11/08/RocketMQ概述/","link":"","permalink":"http://ltyeamin.github.io/2019/11/08/RocketMQ概述/","excerpt":"","text":"1. MQ介绍1.1 为什么要用MQ消息队列是一种“先进先出”的数据结构 其应用场景主要包含以下3个方面 应用解耦 系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。 使用消息队列解耦合，系统的耦合性就会提高了。比如物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中，用户的下单操作正常完成。当物流系统回复后，补充处理存在消息队列中的订单消息即可，终端系统感知不到物流系统发生过几分钟故障。 流量削峰 应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。 一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好。 处于经济考量目的： 业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量高峰配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰 数据分发 通过消息队列可以让数据在多个系统更加之间进行流通。数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可 1.2 MQ的优点和缺点优点：解耦、削峰、数据分发 缺点包含以下几点： 系统可用性降低 系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。 如何保证MQ的高可用？ 系统复杂度提高 MQ的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过MQ进行异步调用。 如何保证消息没有被重复消费？怎么处理消息丢失情况？那么保证消息传递的顺序性？ 一致性问题 A系统处理完业务，通过MQ给B、C、D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败。 如何保证消息数据处理的一致性？ 1.3 RocetMQ历史及其特征​ 阿里的消息中间件有很长的历史，从2007年的Notify到2010年的Napoli, 2011年升级后改为MetaQ，然后到2012年开始做RocketMQ, RocketMQ使用Java语言开发，于2016年开源。第一代的Notify主要使用了推模型，解决了事务消息；第二代的MetaQ主要使用了拉模型，解决了顺序消息和海量堆积的问题。RocketMQ基于长轮询的拉取方式，兼有两者的优点。​ 每一次产品迭代，都吸取了之前的经验教训，目前RocketMQ已经成为Apache顶级项目。在阿里内部，RocketMQ很好地服务了集团大大小小上千个应用，在每年的双十一当天，更有不可思议的万亿级消息通过RocketMQ流转（在2017年的双十一当天，整个阿里巴巴集团通过RocketMQ流转的线上消息达到了万亿级，峰值TPS达到5600万），在阿里大中台策略上发挥着举足轻重的作用。此外，RocketMQ是使用Java语言开发的，比起Kafka的Scala语言和RabbitMQ的Erlang语言，更容易找到技术人员进行定制开发。 从RocketMQ Github主页上可以找到如下表述。 Apache RocketMQ is a distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability. It offers a variety of features: Pub/Sub messaging model Financial grade transactional message A variety of cross language clients, such as Java, C/C++, Python, Go Pluggable transport protocols, such as TCP, SSL, AIO Inbuilt message tracing capability, also support opentracing Versatile big-data and streaming ecosytem integration Message retroactivity by time or offset Reliable FIFO and strict ordered messaging in the same queue Efficient pull&amp;push consumption model Million-level message accumulation capacity in a single queue Multiple messaging protocols like JMS and OpenMessaging Flexible distributed scale-out deployment architecture Lightning-fast batch message exchange system Various message filter mechanics such as SQL and Tag Docker images for isolated testing and cloud isolated clusters Feature-rich administrative dashboard for configuration, metrics and monitoring Authentication and authorisation 大概意思我在这里翻译一下: ​ Apache RocketMQ是一个分布式消息传递和流媒体平台，具有低延迟，高性能和可靠性，万亿级容量和灵活的可伸缩性。 它具有多种功能： 发布/订阅消息传递模型 金融级交易消息 各种跨语言客户端，例如Java，C / C ++，Python，Go 可插拔的传输协议，例如TCP，SSL，AIO 内置的消息跟踪功能，还支持开放式跟踪 多功能的大数据和流生态系统集成 按时间或偏移量追溯消息 可靠的FIFO和严格的有序消息传递在同一队列中 高效的推拉消费模型 单个队列中的百万级消息累积容量 多种消息传递协议，例如JMS和OpenMessaging 灵活的分布式横向扩展部署架构 快如闪电的批量消息交换系统 如SQL和Tag各种消息过滤器机制 用于隔离测试和云隔离群集的Docker映像 功能丰富的管理仪表板，用于配置，指标和监视 认证与授权管理 1.4 各种MQ产品的比较常见的MQ产品包括Kafka、ActiveMQ、RabbitMQ、RocketMQ。 1.5 总结​ RocketMQ基于Java开发的，完全的分布式架构，API相对比较简单(相比RabbitMQ)，容易掌握，并在阿里巴巴集团内部经过了大量(双11)的实践，分性能强悍。唯一不足的一点是文档相对不是很多，若能跟随源码深入了解其内部机制，这也不算缺点。 1.6 参考文档 Rocket主页 为什么选择RocketMQ RocketMQ Github 常见MQ产品对比 17个方面对比主流MQ差异 Rocket技术内幕 Rocket实战与原理","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://ltyeamin.github.io/tags/RocketMQ/"}]},{"title":"七牛云对象存储空间迁移脚本","slug":"七牛云对象存储空间迁移脚本","date":"2019-11-02T10:15:00.000Z","updated":"2019-11-23T03:14:33.631Z","comments":true,"path":"2019/11/02/七牛云对象存储空间迁移脚本/","link":"","permalink":"http://ltyeamin.github.io/2019/11/02/七牛云对象存储空间迁移脚本/","excerpt":"","text":"前言现在博客的图片都放在七牛云对象存储上面，个人用户有免费10GB的存储空间。 因为每一个的bucket空间分配一个七牛云的空间域名，如下示例： S3 域名 Endpoint(区域节点)： s3-cn-east-1.qiniucs.com 空间域名： 20191119.s3-cn-east-1.qiniucs.com 融合 CDN 测试域名 七牛融合 CDN 测试域名（以 clouddn.com/qiniucdn.com/qiniudn.com/qnssl.com/qbox.me 结尾），每个域名每日限总流量 10GB，每个测试域名自创建起 30 个自然日后系统会自动回收，仅供测试使用并且不支持 Https 访问，详情查看 七牛测试域名使用规范 。点击域名可查看剩余回收时间。 q176n8af9.bkt.clouddn.com 七牛云很坑的一点就是这个测试域名有效期是30天(随口一说，人家免费给你的10G存储已经很不错了)，所以30天以后域名会自动过期，意味着里面存储的图片以及对象都不能访问。 解决这种问题有两种方法： 绑定一个备案的域名(非常建议)； 优点：快速好管理，只有域名不过期，终身享受； 缺点：条件限制比较大，域名要备案。 切换bucket空间，即新建一个新的bucket，然后将旧的bucket迁移过去。 优点：免费 缺点：麻烦，每隔30天迁移一次 迁移我只有国内的域名：http://yeamin.top 。 我的Blog域名是http://blog.yeamin.top 。 因为我个人没有服务器，主域名都没有在国内备案，在我这里选择了第二种方式：迁移空间换取新的bucket和域名。 准备工作打开七牛云官网，登录进入到管理控制台，左侧选择对象存储 找到要迁移的bucket,即源存储； 新建一个bucket，即便目标存储空间； 下载并解压七牛云官方提供的同步迁移工具：http://developer.qiniu.com/docs/v6/tools/qshell.html； 在右上角找到我的图像悬浮出来菜单后，选择秘钥管理，准备好AK和SK(AccessKey/SecretKey)。 具体迁移可以参照七牛云的迁移文档可完成迁移工作，但是我觉得每次都这样一个一个这样迁移很麻烦，所以我今天抽空写了一段脚本去处理迁移工作。 脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#!/bin/bash## author: tong.li# description: qshell bucket transfer# date: 2019-11-02 14:45:22#准备配置环境echo \"Prepare Environment...\"if [ ! -x './qshell-windows-x64-v2.4.0' ] then echo \"qshell script file not exist\"fiif [[ !\"$1\" ]]; then echo -n \"please input account:\" read accountfiecho -n 'please input your AK:'read AKecho -n 'please input your SK:'read SKif [[ ! \"$AK\" || ! \"$SK\" ]]; then echo \"AK OR SK is null, please try again\" exit 0fi# 已有账户列表rs=`./qshell-windows-x64-v2.4.0 user ls | awk '&#123;print $2&#125;'`if [[ $rs=~$AK &amp;&amp; $rs=~$SK &amp;&amp; $rs=~$account ]]; then echo \"Config OK...\"else echo \"Starting AK、SK Config...\" ./qshell-windows-x64-v2.4.0 account ak sk namefiecho \"account: $account\"echo \"AK is : $AK\"echo \"SK is: $SK\"if [[ !\"$sourcebucket\" ]]; then echo -n \"please input sourcebucket:\" read sourcebucketfiif [[ !\"$desbucket\" ]]; then echo -n \"please input desbucket:\" read desbucketfi# 列举当前需要复制bucket数据./qshell-windows-x64-v2.4.0 listbucket $sourcebucket -o cp.txt# 生成文件列表cat cp.txt | awk '&#123;print $1&#125;' &gt; cpp.txtsize=$(du -sb cpp.txt|cut -f1)if [[ size &lt;=0 ]]; then echo \"cpp.txt size is 0KB\" exit 0fi# 开始批量迁移./qshell-windows-x64-v2.4.0 batchcopy $sourcebucket $desbucket -i cpp.txtif [ $? -eq 0 ]; then echo \"==============transfer bucket From $sourcebucket to $desbucket success==============================\"else echo \"=============================transfer bucket failed,please try again==================================\"fi 执行迁移 将上述代码保存batchcopy.sh，并赋予可执行权限； 执行./batchcopy.sh 你的七牛云账户名 之后按输入提示输入AK、SK、源bucket、目标bucket即可完成迁移操作。 总结​ 经常看别人的shell脚本，自己从来也没写过，这是是第一次写脚本，多少可能有些bug。后续发现了会及时更正他。总之还是多学多实践一下没坏处。 参考文档 七牛云对象存储迁移文档 七牛云对象存储空间迁移详解","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"跨平台办公利器-uTools","slug":"跨平台办公利器-uTools","date":"2019-10-12T14:40:10.000Z","updated":"2019-11-09T03:44:53.969Z","comments":true,"path":"2019/10/12/跨平台办公利器-uTools/","link":"","permalink":"http://ltyeamin.github.io/2019/10/12/跨平台办公利器-uTools/","excerpt":"","text":"之前习惯了Mac Pro 的Spotlight模式进行检索应用和文件，在前段日子中，我成功的找到了一款Windows上类似的软件Everything+Wox，仍在使用Windows的朋友有兴趣可以看我阅读这边文章进行操作体验。 言归正传，我在家使用的电脑系统是Deepin Linux,曾经也想找到这种款速检索工具，但是找了很长时间却没有找到。 今天我偶尔在深度应用商店发现一款名叫utools的软件，类似于Spotlight模式。 于是我打开官网，官网是这样介绍的： 你的生产力工具集uTools是一个极简、插件化、跨平台的现代桌面软件。通过自由选配丰富的插件，打造你得心应手的工具集合。当你熟悉它后，能够为你节约大量时间，让你可以更加专注地改变世界。 uTools是跨平台的软件,同时支持Windows、Mac、Linux等平台，不同平台稍微有些差别。Linux平台没有文件检索，这点是很遗憾的，但是笔者相信开发者后续会慢慢完善。 utools常用体验插件中心 快速启动 本地搜索注意：仅支持Windows和Mac平台，Linux平台下会很快开发 图略 自动识别 数据同步 Http抓包 图略 剪贴板 图略 图床 图略 hosts切换 图略 翻译 图略 计算器 图略 内网穿透 图略 相关站点 官网地址：https://www.u.tools/ 官网下载地址：https://www.u.tools/download.html 使用文档地址: https://www.u.tools/docs/guide/about-uTools.html 讨论社区: https://yuanliao.info/","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"【Python爬虫】使用Requests库爬取猫眼电影TOP100数据","slug":"【Python爬虫】使用Requests库爬取猫眼电影TOP100数据","date":"2019-10-12T12:23:11.000Z","updated":"2019-11-09T03:25:49.482Z","comments":true,"path":"2019/10/12/【Python爬虫】使用Requests库爬取猫眼电影TOP100数据/","link":"","permalink":"http://ltyeamin.github.io/2019/10/12/【Python爬虫】使用Requests库爬取猫眼电影TOP100数据/","excerpt":"","text":"爬虫分析爬虫需求描述: 爬取猫眼电影TOP100的电影名称、时间、评分、海报图片等信息 站点: https://maoyan.com/board/4 分析: 打开站点即是猫眼电影TOP100的第一页,点击下一页，我们观察地址栏URL后边追加了?offset=10的参数，显然offset参数代表偏移量，offset=10表示第一页，offset=20表示第二页，由此可推，若偏移量未n，则电影序号就是n+1到n+10，每页显示10个。因此，想要获取TOP100，要分开请求10次，而10次的offset参数值分别设置为0、10、20…90即可，这样获取不同的页面之后，再通过任意一个的解析器提取相关的数据即可完成。 代码编写利用正则进行解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#!/usr/bin python3.6# -*- encoding: utf-8 -*-\"\"\"@File : __init__.py.py@Description : 利用requests库和lxml解析库爬取猫眼电影TOP100数据@Author : tong.li@Email : lt_alex@163.com@Blog : http://blog.yeamin.top@Time : 2019/10/12 下午8:31\"\"\"import requestsimport reimport timefrom requests.exceptions import RequestExceptiondef request_page(url): try: # 设置请求头 headers = &#123; 'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36' &#125; response = requests.get(url, headers=headers) if response.status_code == 200: text = response.text # 获取电影排名、海报、名称、主演、发布时间、评分 regx = re.compile('&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=\"(.*?)\".*?name.*?a.*?&gt;(.*?)&lt;/a&gt;' '.*?star.*?&gt;.*?：(.*?)\\s*&lt;/p&gt;.*?releasetime.*?&gt;.*?：(.*?)&lt;/p&gt;.*?integer.*?&gt;(.*?)&lt;/i&gt;' '.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;', re.S) items = re.findall(regx, text) for item in items: yield &#123; 'index': item[0], 'name': item[2], 'actor': item[3], 'post_img': item[1], 'time': item[4], 'score': item[5]+item[6] &#125; return items return None except RequestException: return None# 存储:文件/数据库def store(text,filename): with open(filename, 'a', encoding='utf-8') as file: file.write(str(text) + '\\n')def getData(url): datas = request_page(url) for data in datas: # 控制台打印数据 print(data) # 将数据写入txt纯文本文件中 store(data,'result.txt')if __name__ == '__main__': # 猫眼电影TOP100榜单 url = 'https://maoyan.com/board/4?offset=' for i in range(10): getData(url + str(i * 10)) # 猫眼电影有反爬虫限制,爬的太多会有IP或验证码限制,等待0.5毫秒再次请求 time.sleep(0.5) 利用xlml及Xpath解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/usr/bin python3.6# -*- encoding: utf-8 -*-\"\"\"@File : __init__.py.py@Description : 利用requests库和lxml解析库爬取猫眼电影TOP100数据@Author : tong.li@Email : lt_alex@163.com@Blog : http://blog.yeamin.top@Time : 2019/10/12 下午8:31\"\"\"from lxml import etreeimport requestsimport timefrom requests.exceptions import RequestExceptiondef request_page(url): try: # 设置请求头 headers = &#123; 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36' &#125; response = requests.get(url, headers=headers) if response.status_code == 200: text = response.text return text return None except RequestException: return Nonedef dealData(items): for item in items: yield &#123; 'index': item[0], 'name': item[1], 'actor': item[2].strip(), 'time': item[3][5:], 'score': item[4] + item[5], 'post_img': item[6] &#125; return itemsif __name__ == '__main__': for i in range(10): # 猫眼电影TOP100榜单 url = 'https://maoyan.com/board/4?offset='+ str(i * 10) html = etree.HTML(request_page(url)) indexs = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/i/text()') name = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/div/div/div[1]/p[1]/a/text()') actor = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/div/div/div[1]/p[2]/text()') times = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/div/div/div[1]/p[3]/text()') score1 = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/div/div/div[2]/p/i[1]/text()') score2 = html.xpath('//*[@id=\"app\"]/div/div/div[1]/dl/dd/div/div/div[2]/p/i[2]/text()') # 取图片地址的时候发现问题,打开浏览器F12控制台,在Element看到的img标签图片地址属性名为src, # 但是在Source下看到的属性名是data-src,原因可能是浏览器对JavaScript代码进行了渲染 images = html.xpath('//*[@class=\"board-img\"]/@data-src') datas = zip(indexs,name,actor,times,score1,score2,images) for data in dealData(datas): print(data) # 猫眼电影有反爬虫限制,爬的太多会有IP或验证码限制,等待0.5毫秒再次请求 time.sleep(0.5) 爬取结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100&#123;'index': '1', 'name': '霸王别姬', 'actor': '主演：张国荣,张丰毅,巩俐', 'time': '1993-07-26', 'score': '9.5', 'post_img': 'https://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c'&#125;&#123;'index': '2', 'name': '肖申克的救赎', 'actor': '主演：蒂姆·罗宾斯,摩根·弗里曼,鲍勃·冈顿', 'time': '1994-09-10(加拿大)', 'score': '9.5', 'post_img': 'https://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg@160w_220h_1e_1c'&#125;&#123;'index': '3', 'name': '罗马假日', 'actor': '主演：格利高里·派克,奥黛丽·赫本,埃迪·艾伯特', 'time': '1953-09-02(美国)', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/289f98ceaa8a0ae737d3dc01cd05ab052213631.jpg@160w_220h_1e_1c'&#125;&#123;'index': '4', 'name': '这个杀手不太冷', 'actor': '主演：让·雷诺,加里·奥德曼,娜塔莉·波特曼', 'time': '1994-09-14(法国)', 'score': '9.5', 'post_img': 'https://p1.meituan.net/movie/6bea9af4524dfbd0b668eaa7e187c3df767253.jpg@160w_220h_1e_1c'&#125;&#123;'index': '5', 'name': '泰坦尼克号', 'actor': '主演：莱昂纳多·迪卡普里奥,凯特·温丝莱特,比利·赞恩', 'time': '1998-04-03', 'score': '9.5', 'post_img': 'https://p1.meituan.net/movie/b607fba7513e7f15eab170aac1e1400d878112.jpg@160w_220h_1e_1c'&#125;&#123;'index': '6', 'name': '唐伯虎点秋香', 'actor': '主演：周星驰,巩俐,郑佩佩', 'time': '1993-07-01(中国香港)', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/da64660f82b98cdc1b8a3804e69609e041108.jpg@160w_220h_1e_1c'&#125;&#123;'index': '7', 'name': '魂断蓝桥', 'actor': '主演：费雯·丽,罗伯特·泰勒,露塞尔·沃特森', 'time': '1940-05-17(美国)', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/46c29a8b8d8424bdda7715e6fd779c66235684.jpg@160w_220h_1e_1c'&#125;&#123;'index': '8', 'name': '乱世佳人', 'actor': '主演：费雯·丽,克拉克·盖博,奥利维娅·德哈维兰', 'time': '1939-12-15(美国)', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/223c3e186db3ab4ea3bb14508c709400427933.jpg@160w_220h_1e_1c'&#125;&#123;'index': '9', 'name': '天空之城', 'actor': '主演：寺田农,鹫尾真知子,龟山助清', 'time': '1992-05-01', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/ba1ed511668402605ed369350ab779d6319397.jpg@160w_220h_1e_1c'&#125;&#123;'index': '10', 'name': '辛德勒的名单', 'actor': '主演：连姆·尼森,拉尔夫·费因斯,本·金斯利', 'time': '1993-12-15(美国)', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/b0d986a8bf89278afbb19f6abaef70f31206570.jpg@160w_220h_1e_1c'&#125;&#123;'index': '11', 'name': '音乐之声', 'actor': '主演：朱莉·安德鲁斯,克里斯托弗·普卢默,埃琳诺·帕克', 'time': '1965-03-02(美国)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/6bc004d57358ee6875faa5e9a1239140128550.jpg@160w_220h_1e_1c'&#125;&#123;'index': '12', 'name': '喜剧之王', 'actor': '主演：周星驰,莫文蔚,张柏芝', 'time': '1999-02-13(中国香港)', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/18e3191039d5e71562477659301f04aa61905.jpg@160w_220h_1e_1c'&#125;&#123;'index': '13', 'name': '大闹天宫', 'actor': '主演：邱岳峰,毕克,富润生', 'time': '1965-12-31', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/14a7b337e8063e3ce05a5993ed80176b74208.jpg@160w_220h_1e_1c'&#125;&#123;'index': '14', 'name': '春光乍泄', 'actor': '主演：张国荣,梁朝伟,张震', 'time': '1997-05-30(中国香港)', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/ae7245920d95c03765fe1615f3a1fe3865785.jpg@160w_220h_1e_1c'&#125;&#123;'index': '15', 'name': '剪刀手爱德华', 'actor': '主演：约翰尼·德普,薇诺娜·瑞德,黛安·韦斯特', 'time': '1990-12-06(美国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/6a964e9cee699267053bd6a4bf6f2671195394.jpg@160w_220h_1e_1c'&#125;&#123;'index': '16', 'name': '美丽人生', 'actor': '主演：罗伯托·贝尼尼,尼可莱塔·布拉斯基,乔治·坎塔里尼', 'time': '1997-12-20(意大利)', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/43d259ecbcd53e8bbe902632772281d6327525.jpg@160w_220h_1e_1c'&#125;&#123;'index': '17', 'name': '黑客帝国', 'actor': '主演：基努·里维斯,凯瑞-安·莫斯,劳伦斯·菲什伯恩', 'time': '2000-01-14', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/ad974d3527879f00be2eec29135118163728582.jpg@160w_220h_1e_1c'&#125;&#123;'index': '18', 'name': '哈利·波特与魔法石', 'actor': '主演：丹尼尔·雷德克里夫,鲁伯特·格林特,艾玛·沃特森', 'time': '2002-01-26', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/aacb9ed2a6601bfe515ef0970add1715623792.jpg@160w_220h_1e_1c'&#125;&#123;'index': '19', 'name': '指环王3：王者无敌', 'actor': '主演：伊莱贾·伍德,伊恩·麦克莱恩,丽芙·泰勒', 'time': '2004-03-15', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/932bdfbef5be3543e6b136246aeb99b8123736.jpg@160w_220h_1e_1c'&#125;&#123;'index': '20', 'name': '无间道', 'actor': '主演：刘德华,梁朝伟,黄秋生', 'time': '2003-09-05', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/606de8f394d40dbcbb9b87943fec71a2130408.jpg@160w_220h_1e_1c'&#125;&#123;'index': '21', 'name': '蝙蝠侠：黑暗骑士', 'actor': '主演：克里斯蒂安·贝尔,希斯·莱杰,阿伦·伊克哈特', 'time': '2008-07-18(美国)', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/09658109acfea0e248a63932337d8e6a4268980.jpg@160w_220h_1e_1c'&#125;&#123;'index': '22', 'name': '楚门的世界', 'actor': '主演：金·凯瑞,劳拉·琳妮,诺亚·艾默里奇', 'time': '1998-06-01(美国)', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/8959888ee0c399b0fe53a714bc8a5a17460048.jpg@160w_220h_1e_1c'&#125;&#123;'index': '23', 'name': '加勒比海盗', 'actor': '主演：约翰尼·德普,凯拉·奈特莉,奥兰多·布鲁姆', 'time': '2003-11-21', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/b05b94b28eca53f325ae8d807fcd4ce01798036.jpg@160w_220h_1e_1c'&#125;&#123;'index': '24', 'name': '教父2', 'actor': '主演：阿尔·帕西诺,罗伯特·德尼罗,黛安·基顿', 'time': '1974-12-12(美国)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/bb1dee5e0b25889a2410211c1d5010ae190824.jpg@160w_220h_1e_1c'&#125;&#123;'index': '25', 'name': '射雕英雄传之东成西就', 'actor': '主演：张国荣,梁朝伟,张学友', 'time': '1993-02-05(中国香港)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/53b6f0b66882a53b08896c92076515a8236400.jpg@160w_220h_1e_1c'&#125;&#123;'index': '26', 'name': '机器人总动员', 'actor': '主演：本·贝尔特,艾丽莎·奈特,杰夫·格尔林', 'time': '2008-06-27(美国)', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/267dd2483f0fb57081474c00fbea38451415571.jpg@160w_220h_1e_1c'&#125;&#123;'index': '27', 'name': '指环王1：护戒使者', 'actor': '主演：伊莱贾·伍德,伊恩·麦克莱恩,丽芙·泰勒', 'time': '2002-04-04', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/dd08154878aac7c8c649fe3eeb8ccd0a2498277.jpg@160w_220h_1e_1c'&#125;&#123;'index': '28', 'name': '指环王2：双塔奇兵', 'actor': '主演：伊莱贾·伍德,伊恩·麦克莱恩,丽芙·泰勒', 'time': '2003-04-25', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/02bb9fd161c05bad6089133098efcdb5546589.jpg@160w_220h_1e_1c'&#125;&#123;'index': '29', 'name': '狮子王', 'actor': '主演：马修·布罗德里克,尼基塔·卡兰姆,詹姆斯·厄尔·琼斯', 'time': '1995-07-15', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/27b76fe6cf3903f3d74963f70786001e1438406.jpg@160w_220h_1e_1c'&#125;&#123;'index': '30', 'name': '活着', 'actor': '主演：葛优,巩俐,牛犇', 'time': '1994-05-18(法国)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/4c41068ef7608c1d4fbfbe6016e589f7204391.jpg@160w_220h_1e_1c'&#125;&#123;'index': '31', 'name': '拯救大兵瑞恩', 'actor': '主演：汤姆·汉克斯,马特·达蒙,汤姆·塞兹摩尔', 'time': '1998-11-13', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/a2a287c77415dc1f85b04d288f7d63ab1089754.jpg@160w_220h_1e_1c'&#125;&#123;'index': '32', 'name': '盗梦空间', 'actor': '主演：莱昂纳多·迪卡普里奥,渡边谦,约瑟夫·高登-莱维特', 'time': '2010-09-01', 'score': '9.2', 'post_img': 'https://p1.meituan.net/movie/2f344a9f9575edbcae9f0abe0578bc90339773.jpg@160w_220h_1e_1c'&#125;&#123;'index': '33', 'name': '哈尔的移动城堡', 'actor': '主演：倍赏千惠子,木村拓哉,美轮明宏', 'time': '2004-11-20(日本)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/0127b451d5b8f0679c6f81c8ed414bb2432442.jpg@160w_220h_1e_1c'&#125;&#123;'index': '34', 'name': '忠犬八公的故事', 'actor': '主演：Forest,理查·基尔,琼·艾伦', 'time': '2010-03-12(英国)', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/7787c10ad5e95b03cf83ef9473500d8e282796.jpg@160w_220h_1e_1c'&#125;&#123;'index': '35', 'name': '疯狂原始人', 'actor': '主演：尼古拉斯·凯奇,艾玛·斯通,瑞安·雷诺兹', 'time': '2013-04-20', 'score': '9.5', 'post_img': 'https://p1.meituan.net/movie/bc022b86345c643ca21d759166f77a553679589.jpg@160w_220h_1e_1c'&#125;&#123;'index': '36', 'name': '搏击俱乐部', 'actor': '主演：爱德华·哈里森·诺顿,布拉德·皮特,海伦娜·伯翰·卡特', 'time': '1999-10-15(美国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/b3defc07dfaa1b6f5b74852ce38a3f8f242792.jpg@160w_220h_1e_1c'&#125;&#123;'index': '37', 'name': '东邪西毒', 'actor': '主演：张国荣,梁朝伟,刘嘉玲', 'time': '1994-09-17', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/7e471a9171a410ebc9413b2f1de67afc130067.jpg@160w_220h_1e_1c'&#125;&#123;'index': '38', 'name': '幽灵公主', 'actor': '主演：松田洋治,石田百合子,田中裕子', 'time': '1998-05-01', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/a08f65e6cb50fab32df5da69ff116f593095363.jpg@160w_220h_1e_1c'&#125;&#123;'index': '39', 'name': '阿凡达', 'actor': '主演：萨姆·沃辛顿,佐伊·索尔达娜,米歇尔·罗德里格兹', 'time': '2010-01-04', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/91f575ec93f019f428d1f33e3ceca7c5115495.jpg@160w_220h_1e_1c'&#125;&#123;'index': '40', 'name': '风之谷', 'actor': '主演：岛本须美,永井一郎,坂本千夏', 'time': '1992', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/4f9638ba234c3fb673f23a09968db875371576.jpg@160w_220h_1e_1c'&#125;&#123;'index': '41', 'name': '十二怒汉', 'actor': '主演：亨利·方达,李·科布,马丁·鲍尔萨姆', 'time': '1957-04-13(美国)', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/df15efd261060d3094a73ef679888d4f238149.jpg@160w_220h_1e_1c'&#125;&#123;'index': '42', 'name': '大话西游之月光宝盒', 'actor': '主演：周星驰,莫文蔚,吴孟达', 'time': '2014-10-24', 'score': '9.6', 'post_img': 'https://p0.meituan.net/movie/92eb862c42c49f8e41e459c369c4512b226610.jpg@160w_220h_1e_1c'&#125;&#123;'index': '43', 'name': 'V字仇杀队', 'actor': '主演：娜塔莉·波特曼,雨果·维文,斯蒂芬·瑞', 'time': '2006-03-17(美国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/06ec3c1c647942b1e40bca84036014e9490863.jpg@160w_220h_1e_1c'&#125;&#123;'index': '44', 'name': '放牛班的春天', 'actor': '主演：热拉尔·朱尼奥,让-巴蒂斯特·莫尼耶,玛丽·布奈尔', 'time': '2004-10-16', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/70de97ebb6b5251ecb7c3f6d7a782a7f189340.jpg@160w_220h_1e_1c'&#125;&#123;'index': '45', 'name': '当幸福来敲门', 'actor': '主演：威尔·史密斯,贾登·史密斯,坦迪·牛顿', 'time': '2008-01-17', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/5896de3c1474277730e321c9b1db04a9205644.jpg@160w_220h_1e_1c'&#125;&#123;'index': '46', 'name': '速度与激情5', 'actor': '主演：范·迪塞尔,保罗·沃克,道恩·强森', 'time': '2011-05-12', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/845ce32778a1b3f258de089f91a3979b5766154.jpg@160w_220h_1e_1c'&#125;&#123;'index': '47', 'name': '驯龙高手', 'actor': '主演：杰伊·巴鲁切尔,杰拉德·巴特勒,亚美莉卡·费雷拉', 'time': '2010-05-14', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/b0d97e4158b47d653d7a81d66f7dd3092146907.jpg@160w_220h_1e_1c'&#125;&#123;'index': '48', 'name': '勇敢的心', 'actor': '主演：梅尔·吉布森,苏菲·玛索,帕特里克·麦高汉', 'time': '1995-05-24(美国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/f8e9d5a90224746d15dfdbd53d4fae3d209420.jpg@160w_220h_1e_1c'&#125;&#123;'index': '49', 'name': '闻香识女人', 'actor': '主演：阿尔·帕西诺,克里斯·奥唐纳,加布里埃尔·安瓦尔', 'time': '1992-12-23(美国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/8d7b0b902afd4ec1a3dd7a9c6149463c187734.jpg@160w_220h_1e_1c'&#125;&#123;'index': '50', 'name': '神偷奶爸', 'actor': '主演：史蒂夫·卡瑞尔,杰森·席格尔,拉塞尔·布兰德', 'time': '2010-07-09(美国)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/85c2bfba6025bfbfb53291ae5924c215308805.jpg@160w_220h_1e_1c'&#125;&#123;'index': '51', 'name': '黑客帝国3：矩阵革命', 'actor': '主演：基努·里维斯,雨果·维文,凯瑞-安·莫斯', 'time': '2003-11-05', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/2e383b5f5f306f10f9f26d9f1c28cf1d825537.jpg@160w_220h_1e_1c'&#125;&#123;'index': '52', 'name': '飞屋环游记', 'actor': '主演：爱德华·阿斯纳,乔丹·长井,鲍勃·彼德森', 'time': '2009-08-04', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/47dd790e19dad72b50580641de5608c5199014.jpg@160w_220h_1e_1c'&#125;&#123;'index': '53', 'name': '断背山', 'actor': '主演：希斯·莱杰,杰克·吉伦哈尔,米歇尔·威廉姆斯', 'time': '2006-01-13(美国)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/e71affe126eeb4f8bfcc738cbddeebc8288766.jpg@160w_220h_1e_1c'&#125;&#123;'index': '54', 'name': '怦然心动', 'actor': '主演：玛德琳·卡罗尔,卡兰·麦克奥利菲,艾丹·奎因', 'time': '2010-08-06(美国)', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/15f1ac49b6d1ff7b71207672993ed6901536456.jpg@160w_220h_1e_1c'&#125;&#123;'index': '55', 'name': '三傻大闹宝莱坞', 'actor': '主演：阿米尔·汗,黄渤,卡琳娜·卡普', 'time': '2011-12-08', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/ca4a128a5a54d5b5e35ceba622636c831810197.jpg@160w_220h_1e_1c'&#125;&#123;'index': '56', 'name': '末代皇帝', 'actor': '主演：尊龙,陈冲,彼得·奥图尔', 'time': '1987-10-23', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/21b9211eb1094af360842472018db634286646.jpg@160w_220h_1e_1c'&#125;&#123;'index': '57', 'name': '无敌破坏王', 'actor': '主演：约翰·C·赖利,萨拉·西尔弗曼,简·林奇', 'time': '2012-11-06', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/fcc17667b8343131101eeb4c67d90bf9150883.jpg@160w_220h_1e_1c'&#125;&#123;'index': '58', 'name': '致命魔术', 'actor': '主演：休·杰克曼,克里斯蒂安·贝尔,迈克尔·凯恩', 'time': '2006-10-20(美国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/75c0d3eb584be030a01f2e26741a8f41251454.jpg@160w_220h_1e_1c'&#125;&#123;'index': '59', 'name': '少年派的奇幻漂流', 'actor': '主演：苏拉·沙玛,伊尔凡·可汗,塔布', 'time': '2012-11-22', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/34998e31c6d07475f1add6b8b16fd21d192579.jpg@160w_220h_1e_1c'&#125;&#123;'index': '60', 'name': '鬼子来了', 'actor': '主演：姜文,姜宏波,陈强', 'time': '2000-05-12(法国戛纳)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/0b507aa44c4dfbbcc91949b69b1b39a168922.jpg@160w_220h_1e_1c'&#125;&#123;'index': '61', 'name': '蝙蝠侠：黑暗骑士崛起', 'actor': '主演：克里斯蒂安·贝尔,迈克尔·凯恩,加里·奥德曼', 'time': '2012-08-27', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/96bb58f3e9d213fb0438987d16d27561379209.jpg@160w_220h_1e_1c'&#125;&#123;'index': '62', 'name': '美丽心灵', 'actor': '主演：罗素·克洛,詹妮弗·康纳利,艾德·哈里斯', 'time': '2001-12-21(美国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/7b7d1f8aa36d7a15463ce6942708a1a7265296.jpg@160w_220h_1e_1c'&#125;&#123;'index': '63', 'name': '哈利·波特与死亡圣器（下）', 'actor': '主演：丹尼尔·雷德克里夫,鲁伯特·格林特,艾玛·沃特森', 'time': '2011-08-04', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/bb0eca029cd25329776a4549b3fbe262924727.jpg@160w_220h_1e_1c'&#125;&#123;'index': '64', 'name': '倩女幽魂', 'actor': '主演：张国荣,王祖贤,午马', 'time': '2011-04-30', 'score': '9.2', 'post_img': 'https://p1.meituan.net/movie/96d98200d2afb4b87ff189f9c15b6545568339.jpg@160w_220h_1e_1c'&#125;&#123;'index': '65', 'name': '夜访吸血鬼', 'actor': '主演：汤姆·克鲁斯,布拉德·皮特,克尔斯滕·邓斯特', 'time': '1994-11-11(美国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/7ec873ba943f13e3c63789d899bd0e23256871.jpg@160w_220h_1e_1c'&#125;&#123;'index': '66', 'name': '钢琴家', 'actor': '主演：艾德里安·布洛迪,艾米莉娅·福克斯,米哈乌·热布罗夫斯基', 'time': '2002-09-25(法国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/484171372de45945e8bbbcc97db57e09136701.jpg@160w_220h_1e_1c'&#125;&#123;'index': '67', 'name': '触不可及', 'actor': '主演：弗朗索瓦·克鲁塞,奥玛·希,安娜·勒尼', 'time': '2011-11-02(法国)', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/1e700e53e4fe29dd5942381bb353c8532239179.jpg@160w_220h_1e_1c'&#125;&#123;'index': '68', 'name': '本杰明·巴顿奇事', 'actor': '主演：布拉德·皮特,凯特·布兰切特,塔拉吉·P·汉森', 'time': '2008-12-25(美国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/2526f77c650bf7cf3d5ee2dccdeac332244951.jpg@160w_220h_1e_1c'&#125;&#123;'index': '69', 'name': '甜蜜蜜', 'actor': '主演：黎明,张曼玉,曾志伟', 'time': '2015-02-13', 'score': '9.2', 'post_img': 'https://p1.meituan.net/movie/0b0d45b58946078dd24d4945dd6be3b51329411.jpg@160w_220h_1e_1c'&#125;&#123;'index': '70', 'name': '大话西游之大圣娶亲', 'actor': '主演：周星驰,朱茵,莫文蔚', 'time': '2014-10-24', 'score': '8.8', 'post_img': 'https://p1.meituan.net/moviemachine/508056769092059fe43a611b949f27d14863831.jpg@160w_220h_1e_1c'&#125;&#123;'index': '71', 'name': '初恋这件小事', 'actor': '主演：马里奥·毛瑞尔,平采娜·乐维瑟派布恩,阿查拉那·阿瑞亚卫考', 'time': '2012-06-05', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/7ed07b8ea8c0e0d0c7b685d20e3ec64e232004.jpg@160w_220h_1e_1c'&#125;&#123;'index': '72', 'name': '熔炉', 'actor': '主演：孔刘,郑有美,金智英', 'time': '2011-09-22(韩国)', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/2a0783b4fd95566568f24adfad2181bb5392280.jpg@160w_220h_1e_1c'&#125;&#123;'index': '73', 'name': '新龙门客栈', 'actor': '主演：张曼玉,梁家辉,甄子丹', 'time': '2012-02-24', 'score': '8.8', 'post_img': 'https://p1.meituan.net/movie/7833126c8c21a11571bb52fbdece0acb811449.jpg@160w_220h_1e_1c'&#125;&#123;'index': '74', 'name': '素媛', 'actor': '主演：李来,薛耿求,严志媛', 'time': '2013-10-02(韩国)', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/19653e8af59cf473cd40f9ccc0658d93692304.jpg@160w_220h_1e_1c'&#125;&#123;'index': '75', 'name': '小鞋子', 'actor': '主演：默罕默德·阿米尔·纳吉,Kamal Mirkarimi,Behzad Rafi', 'time': '1999-01-22(美国)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/135c612860fae899df2220149664d97a173555.jpg@160w_220h_1e_1c'&#125;&#123;'index': '76', 'name': '萤火之森', 'actor': '主演：内山昂辉,佐仓绫音,后藤弘树', 'time': '2011-09-17(日本)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c'&#125;&#123;'index': '77', 'name': '教父', 'actor': '主演：马龙·白兰度,阿尔·帕西诺,詹姆斯·肯恩', 'time': '2015-04-18', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/1199dc6273680f175fd9b06c9c36d08a219658.jpg@160w_220h_1e_1c'&#125;&#123;'index': '78', 'name': '穿条纹睡衣的男孩', 'actor': '主演：阿沙·巴特菲尔德,维拉·法梅加,大卫·休里斯', 'time': '2008-09-12(英国)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/d5970e36c8868a4b746c80f3b3f8a404174615.jpg@160w_220h_1e_1c'&#125;&#123;'index': '79', 'name': '时空恋旅人', 'actor': '主演：瑞秋·麦克亚当斯,多姆纳尔·格里森,比尔·奈伊', 'time': '2013-09-04(英国)', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/4abc8c932cfacfc0089e2883765d02d1295222.jpg@160w_220h_1e_1c'&#125;&#123;'index': '80', 'name': '窃听风暴', 'actor': '主演：乌尔里希·穆埃,塞巴斯蒂安·科赫,马蒂娜·格德克', 'time': '2006-03-23(德国)', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/3985eaf3858bea0f2a3d966bf7ee2103178217.jpg@160w_220h_1e_1c'&#125;&#123;'index': '81', 'name': '7号房的礼物', 'actor': '主演：柳承龙,郑镇荣,朴信惠', 'time': '2013-01-23(韩国)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/6a6e74b2c289f9fa4433dd2dc04a7741331638.jpg@160w_220h_1e_1c'&#125;&#123;'index': '82', 'name': '恐怖直播', 'actor': '主演：河正宇,李璟荣,李大为', 'time': '2013-07-31(韩国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/b5ff0216e689b3fcc065590c48cd5105255305.jpg@160w_220h_1e_1c'&#125;&#123;'index': '83', 'name': '海豚湾', 'actor': '主演：里克·奥巴瑞,路易·西霍尤斯,哈迪·琼斯', 'time': '2009-07-31(美国)', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/7373dbba07b50ce6f24336edb96b2ea4271536.jpg@160w_220h_1e_1c'&#125;&#123;'index': '84', 'name': '忠犬八公物语', 'actor': '主演：仲代达矢,春川真澄,井川比佐志', 'time': '1987-08-01(日本)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/c835b3588d0061ed3b992388a0a96f15160913.jpg@160w_220h_1e_1c'&#125;&#123;'index': '85', 'name': '上帝之城', 'actor': '主演：亚历桑德雷·罗德里格斯,艾莉丝·布拉加,莱安德鲁·菲尔米诺', 'time': '2002-08-30(巴西)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/b553d13f30100db731ab6cf45668e52d94703.jpg@160w_220h_1e_1c'&#125;&#123;'index': '86', 'name': '辩护人', 'actor': '主演：宋康昊,郭度沅,吴达洙', 'time': '2013-12-18(韩国)', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/8fabf3894b7d12d3d2f6e66404813670265761.jpg@160w_220h_1e_1c'&#125;&#123;'index': '87', 'name': '美国往事', 'actor': '主演：罗伯特·德尼罗,詹姆斯·伍兹,伊丽莎白·麦戈文', 'time': '2015-04-23', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/92198a6fc8c3f5d13aa1bdf203572c0f99438.jpg@160w_220h_1e_1c'&#125;&#123;'index': '88', 'name': '完美的世界', 'actor': '主演：凯文·科斯特纳,克林特·伊斯特伍德,T·J·劳瑟', 'time': '1993-11-24(美国)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/30310858fdab34c7a17cfd7ec8ad8bfc112201.jpg@160w_220h_1e_1c'&#125;&#123;'index': '89', 'name': '七武士', 'actor': '主演：三船敏郎,志村乔,千秋实', 'time': '1954-04-26(日本)', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/4ffca83fd972f71e291f8ea8d78a4b58594878.jpg@160w_220h_1e_1c'&#125;&#123;'index': '90', 'name': '一一', 'actor': '主演：吴念真,金燕玲,李凯莉', 'time': '2000-09-20(法国)', 'score': '8.9', 'post_img': 'https://p1.meituan.net/movie/2c0a5fedf4b43d142121b91c6ccabe1b59051.jpg@160w_220h_1e_1c'&#125;&#123;'index': '91', 'name': '英雄本色', 'actor': '主演：狄龙,张国荣,周润发', 'time': '2017-11-17', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/3e5f5f3aa4b7e5576521e26c2c7c894d253975.jpg@160w_220h_1e_1c'&#125;&#123;'index': '92', 'name': '阿飞正传', 'actor': '主演：张国荣,张曼玉,刘德华', 'time': '2018-06-25', 'score': '8.8', 'post_img': 'https://p0.meituan.net/movie/885fc379c614a2b4175587b95ac98eb95045650.jpg@160w_220h_1e_1c'&#125;&#123;'index': '93', 'name': '爱·回家', 'actor': '主演：俞承豪,金艺芬,童孝熙', 'time': '2002-04-05(韩国)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/36a893c53a13f9bb934071b86ae3b5c492427.jpg@160w_220h_1e_1c'&#125;&#123;'index': '94', 'name': '海洋', 'actor': '主演：雅克·贝汉,姜文,兰斯洛特·佩林', 'time': '2011-08-12', 'score': '9.0', 'post_img': 'https://p0.meituan.net/movie/0018b57299d0d4540330a31244c880a9112971.jpg@160w_220h_1e_1c'&#125;&#123;'index': '95', 'name': '我爱你', 'actor': '主演：宋在浩,李顺才,尹秀晶', 'time': '2011-02-17(韩国)', 'score': '9.0', 'post_img': 'https://p1.meituan.net/movie/ed50b58bf636d207c56989872a91f4cf305138.jpg@160w_220h_1e_1c'&#125;&#123;'index': '96', 'name': '黄金三镖客', 'actor': '主演：克林特·伊斯特伍德,李·范·克里夫,埃里·瓦拉赫', 'time': '1966-12-23(意大利)', 'score': '8.9', 'post_img': 'https://p0.meituan.net/movie/cd18ed2c5cda9e71e17e5e6ef61ced172912303.jpg@160w_220h_1e_1c'&#125;&#123;'index': '97', 'name': '迁徙的鸟', 'actor': '主演：雅克·贝汉,Philippe Labro', 'time': '2001-12-12(法国)', 'score': '9.1', 'post_img': 'https://p1.meituan.net/movie/a1634f4e49c8517ae0a3e4adcac6b0dc43994.jpg@160w_220h_1e_1c'&#125;&#123;'index': '98', 'name': '千与千寻', 'actor': '主演：柊瑠美,周冬雨,入野自由', 'time': '2019-06-21', 'score': '9.3', 'post_img': 'https://p0.meituan.net/movie/30b20139e68c46d02e0893277d633b701292458.jpg@160w_220h_1e_1c'&#125;&#123;'index': '99', 'name': '天堂电影院', 'actor': '主演：菲利浦·诺瓦雷,赛尔乔·卡斯特利托,蒂兹亚娜·罗达托', 'time': '2019-06-15', 'score': '9.2', 'post_img': 'https://p0.meituan.net/movie/76fc92cfa6c8f2959431b8aa604ef7ae126414.jpg@160w_220h_1e_1c'&#125;&#123;'index': '100', 'name': '龙猫', 'actor': '主演：秦岚,糸井重里,岛本须美', 'time': '2018-12-14', 'score': '9.1', 'post_img': 'https://p0.meituan.net/movie/c304c687e287c7c2f9e22cf78257872d277201.jpg@160w_220h_1e_1c'&#125; 总结其实还可以利用其他解析库进行解析，比如Beautiful Soup 4和PyQuery库,这两个库相比正则和Xpath解析轻巧简单，但是相比之下性能会有所牺牲。 Beautiful Soup 4 解析库对XMl文档的宽容度不好，在当下的互联网环境下，网站结构开发、升级和维护变的很复杂，对于一些不规范的网站而言，解析会有问题，而lxml解决了该问题。另外， Beautiful Soup 4 解析时候会将所有的XMl节点加载到内存中形成DOM树，性能相比正则下降了很多。 PyQuery解析库，其实语法结构其实就是由JavaScript的JQuery库演变而来的，该库CSS选择器支持性特别好，熟练使用JQuery的朋友也必定会使用该会。 因为我本人不喜欢用这个Beautiful Soup 4 库，所以不打算深入研究，另外,PyQuery和JQuery操作类似，我在本文也不做累述。若有读者对该库感兴趣可自行研究。","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://ltyeamin.github.io/tags/Python/"}]},{"title":"Nginx设置黑白名单","slug":"Nginx设置黑白名单","date":"2019-09-02T10:15:00.000Z","updated":"2019-11-20T15:08:56.125Z","comments":true,"path":"2019/09/02/Nginx设置黑白名单/","link":"","permalink":"http://ltyeamin.github.io/2019/09/02/Nginx设置黑白名单/","excerpt":"","text":"在日常运维工作中，会碰到这样的需求，对于一些http请求只对某些ip开发，其他的ip的客户端都不能访问。 在测试之前我列一下本次测试的终端IP。 宿主机Deepin Linux ： 192.168.1.106 虚拟机Windows 10 : 192.168.1.107 移动Android终端机 MIUI10: 192.168.1.100 Nginx是在Deepin部署的，现在我们启动Nginx 12cd /usr/local/nginx/sbin./nginx 1启动后，在宿主机随便访问一个请求(这里是我之前文章配置的静态图片资源的转发)，比如http://127.0.0.1或http://192.168.1.106 此外，我们用Android手机和Windows 10虚拟机同样访问http://192.168.1.106也能访问到，手机和宿主机是同一个路由器，而虚拟机网络是桥接模式。所以是在同一局域网都能够互通。 我们让手机无法访问，让虚拟机可以通过。 利用allow、deny参数进行访问限制 更改nginx.conf。 12345678location / &#123; deny 192.168.1.100; #禁止IP为192.168.1.100访问 allow all; # 除过上述黑名单的限制外，允许其他IP访问 autoindex on; #开启索引功能 autoindex_exact_size off; # 关闭计算文件确切大小（单位bytes），只显示大概大小（单位kb、mb、gb） autoindex_localtime on; # 显示本机时间而非 GMT 时间 &#125; 重新加载配置。 1sudo ./nginx -s reload 黑名单限制效果。","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://ltyeamin.github.io/tags/Nginx/"}]},{"title":"Deepin Linux安装Docker","slug":"Deepin Linux安装Docker","date":"2019-09-01T04:45:00.000Z","updated":"2019-09-13T02:55:05.743Z","comments":true,"path":"2019/09/01/Deepin Linux安装Docker/","link":"","permalink":"http://ltyeamin.github.io/2019/09/01/Deepin Linux安装Docker/","excerpt":"","text":"普通安装一般的Linux(Debian、Unbantu)发行版可以执行以下命令进行安装： 1wget -qO- https://get.docker.com/ | sh 但是在Deepin执行这命令会安装失败。 查阅资料可以找到docker支持的Linux发行版。 123456789101112131415161718192021222324252627282930313233343536x86_64-centos-7x86_64-fedora-28x86_64-fedora-29x86_64-debian-jessiex86_64-debian-stretchx86_64-debian-busterx86_64-ubuntu-trustyx86_64-ubuntu-xenialx86_64-ubuntu-bionicx86_64-ubuntu-cosmics390x-ubuntu-xenials390x-ubuntu-bionics390x-ubuntu-cosmicppc64le-ubuntu-xenialppc64le-ubuntu-bionicppc64le-ubuntu-cosmicaarch64-ubuntu-xenialaarch64-ubuntu-bionicaarch64-ubuntu-cosmicaarch64-debian-jessieaarch64-debian-stretchaarch64-debian-busteraarch64-fedora-28aarch64-fedora-29aarch64-centos-7armv6l-raspbian-jessiearmv7l-raspbian-jessiearmv6l-raspbian-stretcharmv7l-raspbian-stretcharmv7l-debian-jessiearmv7l-debian-stretcharmv7l-debian-busterarmv7l-ubuntu-trustyarmv7l-ubuntu-xenialarmv7l-ubuntu-bionicarmv7l-ubuntu-cosmic 查看了我的系统的版本： 123456litong@LT:~$ cat /etc/issueDeepin GNU/Linux 15.10.2 \\n \\llitong@LT:~$ cat /etc/debian_version 9.0litong@LT:~$ uname -r4.15.0-29deepin-generic 这里我的系统是Deepin 15.10.2，而我的Deepin Linux是基于Debian 9.0，即上述的版本x86_64-debian-stretch进行的深度开发，我系统Debian 9.0是sid版的，并不是release版本，所以不是docker官方认证的stable版本，故不支持Deepin Linux。 Deepin上安装Docker 若以前安装过旧版本则先卸载旧版本，如没有安装过，则跳过； 1sudo apt-get remove docker.io docker-engine 安装docker-ce与密钥管理与下载相关依赖工具； 1sudo apt-get install apt-transport-https ca-certificates curl python-software-properties software-properties-common 下载并安装密匙并验证秘钥，若成功则返回OK； 1curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - 如果不成功（docker官方在墙外，需科学上网），则使用国内镜像源将上述命令换成 1curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/debian/gpg | sudo apt-key add - 验证秘钥是否安装成功； 123456litong@LT:~$ sudo apt-key fingerprint 0EBFCD88[sudo] litong 的密码：pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ 未知 ] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S] 安装docker-ce组件； 1sudo apt-get install docker-ce 测试是否安装成功； 123456789101112131415161718192021222324252627litong@LT:~$ docker versionClient: Docker Engine - Community Version: 19.03.2 API version: 1.40 Go version: go1.12.8 Git commit: 6a30dfca03 Built: Thu Aug 29 05:29:49 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 19.03.2 API version: 1.40 (minimum version 1.12) Go version: go1.12.8 Git commit: 6a30dfca03 Built: Thu Aug 29 05:28:23 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.6 GitCommit: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc: Version: 1.0.0-rc8 GitCommit: 425e105d5a03fabd737a126ad93d62a9eeede87f docker-init: Version: 0.18.0 GitCommit: fec3683 普通用户运行docker 安装docker完成后，普通用户执行docker命令时候，有可能会出现错误提示： 1Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.26/images/json: dial unix /var/run/docker.sock: connect: permission denied 通过查阅资料，在docker mannual找到解决思路： Manage Docker as a non-root userThe docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user.If you don’t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group. 大概翻译了一下，意思是：Docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。 解决方案： docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令。 添加docker用户组，若已由docker组则跳过； 1sudo groupadd docker 将登陆用户加入到docker用户组中； 1sudo gpasswd -a $USER docker 更新用户组； 1newgrp docker 测试docker命令是否可以使用sudo正常使用。 1docker ps 使用阿里云docker镜像加速 进入阿里云控制台，选择容器镜像服务，左边菜单最下方的镜像中心-镜像加速器； 根据阿里云操作文档选择不同系统的镜像加速命令； 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"替换你的加速器地址\"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ltyeamin.github.io/tags/Docker/"}]},{"title":"百度网盘破速解决","slug":"百度网盘破速解决","date":"2019-08-11T14:22:13.000Z","updated":"2019-11-20T15:09:00.757Z","comments":true,"path":"2019/08/11/百度网盘破速解决/","link":"","permalink":"http://ltyeamin.github.io/2019/08/11/百度网盘破速解决/","excerpt":"","text":"今天在家下载一个别人给我的百度网盘资料，资料大小差不多2个G,但是打开浏览器发现有一件是非常烦躁的事情:小文件可以直接在浏览器端进行下载,但是大文件必须下载百度网盘客户端进行下载. 没办法,我只好去应用商店去下载百度网盘客户端,在深度应用商店还好找到了百度网盘的客户端(国产Deepin系统第三方软件源还是比较给力)。紧接着我就在客户端端登录下载,如下图: 用了客户端之后发现,下载速度特别慢,于是在网上找到一些解决方案:浏览器插件+第三方网络下载工具(Motrix/Aria2)进行下载.我这里采用Motrix方式,Aria2的方式读者可自行研究安装与使用。 安装与设置 安装浏览器插件 Motrix:在Chrome浏览器应用商店搜索百度网盘助手并下载安装。 Aria2: 在Chrome浏览器应用商店搜索YAAW for Chrome并下载安装。 网络下载工具安装 Motrix: 下载地址 Aria2:下载地址 使用体验 总结由上可知,百度云网盘确实做了网速限制。虽然通过第三方下载工具提升了一些下载速度,但是下载还是有点慢，这个其实可以理解的，因为当下的网络是长城宽带，慢也是正常的。","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"魔都上海","slug":"魔都上海","date":"2019-06-09T04:57:10.000Z","updated":"2019-11-20T15:09:02.024Z","comments":true,"path":"2019/06/09/魔都上海/","link":"","permalink":"http://ltyeamin.github.io/2019/06/09/魔都上海/","excerpt":"","text":"上海宣传片 const dp0 = new DPlayer({ container: document.getElementById('dplayer0'), screenshot: true, video: { url: 'http://q176n8af9.bkt.clouddn.com/videos/lvyou/shanghai2.mp4' }, subtitle: { url: 'webvtt.vtt' }, danmaku: { id: 'demo', api: 'https://api.prprpr.me/dplayer/' } }); const dp1 = new DPlayer({ container: document.getElementById('dplayer1'), screenshot: true, video: { url: 'http://q176n8af9.bkt.clouddn.com/videos/lvyou/shanghai1.mp4' }, subtitle: { url: 'webvtt.vtt' }, danmaku: { id: 'demo', api: 'https://api.prprpr.me/dplayer/' } });","categories":[{"name":"others","slug":"others","permalink":"http://ltyeamin.github.io/categories/others/"}],"tags":[{"name":"自媒体","slug":"自媒体","permalink":"http://ltyeamin.github.io/tags/自媒体/"}]},{"title":"Samba服务器搭建","slug":"Samba服务器搭建","date":"2019-06-08T07:17:23.000Z","updated":"2019-11-20T15:08:55.207Z","comments":true,"path":"2019/06/08/Samba服务器搭建/","link":"","permalink":"http://ltyeamin.github.io/2019/06/08/Samba服务器搭建/","excerpt":"","text":"","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Samba","slug":"Samba","permalink":"http://ltyeamin.github.io/tags/Samba/"}]},{"title":"记录一次Maven中配置文件尾回车换行引发的问题","slug":"记录一次Maven中配置文件尾回车换行引发的问题","date":"2019-06-04T14:22:13.000Z","updated":"2019-11-20T15:08:56.465Z","comments":true,"path":"2019/06/04/记录一次Maven中配置文件尾回车换行引发的问题/","link":"","permalink":"http://ltyeamin.github.io/2019/06/04/记录一次Maven中配置文件尾回车换行引发的问题/","excerpt":"","text":"问题描述今天打开IDEA加载项目时，发现一个很诡异的问题：项目依赖及代码没任何问题，Maven依赖检测红色波浪线依旧存在。虽说项目依旧能跑起来不影响开发，但是maven命令操作用不了。 遇到问题后，我大吃一惊。昨天看项目还好好的，今天就报出某个项目一个依赖包找不到。可实际上。该依赖包在本地库是存在的。于是，我删掉了依赖包，重新远程仓库下载。 私服和中央仓库切换好几次，重新下载的依赖包都是完整没问题的。同样Maven的Clean或Install搭配使用多次，这让我更加郁闷，寻找着解决方案。 问题排查与解决解决一在项目中的pom.xml文件里把红色波浪线的依赖线注释掉，然后重新加载之后，就不会出现。 然后撤销注释，然后加载就OK了，网上上说这是IDEA开发工具的BUG，这谁晓得，先这样干吧。 解决二解决一虽然解决了依赖找不到红色波浪线问题，但还是预留一些问题，那就是Maven的基本命令操作用不了。比如我使用了mvn clean进行操作，控制台则报出一段日志: 12345D:\\applications\\develop\\JDK8\\bin\\java.exe -Dmaven.multiModuleProjectDirectory=E:\\work\\code\\cashloan-api -Dmaven.home=D:\\applications\\develop\\apache-maven-3.6.1 -Dclassworlds.conf=D:\\applications\\develop\\apache-maven-3.6.1\\bin\\m2.conf \"-javaagent:D:\\applications\\develop\\IntelliJ IDEA 2019.1.3\\lib\\idea_rt.jar=57134:D:\\applications\\develop\\IntelliJ IDEA 2019.1.3\\bin\" -Dfile.encoding=UTF-8 -classpath D:\\applications\\develop\\apache-maven-3.6.1\\boot\\plexus-classworlds-2.6.0.jar org.codehaus.classworlds.Launcher -Didea.version2019.1.3 -s D:\\applications\\develop\\apache-maven-3.6.1\\conf\\settings.xml -Dmaven.repo.local=D:\\applications\\develop\\apache-maven-3.6.1\\repo install[ERROR] Error executing Maven.[ERROR] 2 problems were encountered while building the effective settings[FATAL] Non-parseable settings D:\\applications\\develop\\apache-maven-3.6.1\\conf\\settings.xml: in epilog non whitespace content is not allowed but got j (position: END_TAG seen ...&lt;/settings&gt;\\n\\nj... @300:2) @ D:\\applications\\develop\\apache-maven-3.6.1\\conf\\settings.xml, line 300, column 2[FATAL] Non-parseable settings D:\\applications\\develop\\apache-maven-3.6.1\\conf\\settings.xml: in epilog non whitespace content is not allowed but got j (position: END_TAG seen ...&lt;/settings&gt;\\n\\nj... @300:2) @ D:\\applications\\develop\\apache-maven-3.6.1\\conf\\settings.xml, line 300, column 2 通过日志我觉得Maven的配置文件settings.xml有问题，第300行第2列有疑惑。 我打开settings.xmls文件，没有300行，查看好像并没有什么问题，但是仔细阅读日志END_TAG seen …\\n\\nj… @300:2，这个让我有所启示，猜测是换行的问题。 What？xml文件尾不能有回车换行，我不信这个邪，我就去试试。 试了以后，才知道真的是这个问题。该死，想了一下，自己今天早上改动过配置文件，可能在保存之前敲了回车，真是该死！！！ 总结有坑不重要，重要的是如何去填坑。","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://ltyeamin.github.io/tags/Maven/"}]},{"title":"Windows搜索利器","slug":"Windows搜索利器","date":"2019-06-03T14:22:13.000Z","updated":"2019-11-20T15:09:00.464Z","comments":true,"path":"2019/06/03/Windows搜索利器/","link":"","permalink":"http://ltyeamin.github.io/2019/06/03/Windows搜索利器/","excerpt":"","text":"前几周忙于换工作，博客没有太多的更新。今天刚好入职新公司的第一天，办公电脑是台式DELL+Intel i5七代(四核四线程，主频3.1HZ，睿频3.6HZ)+8G DDR4。笔者前公司办公环境是Mac Pro + Mac OS X 10，家里日常环境是联想Lenovo+Deepin Linux。可以说已经一年多没接触Windows系统了，现在使用起来多少有些不习惯，主要是各个操作系统操作理念不同。 我几乎每天都在使用计算机进行工作和个人生活，那么我可能会在计算机上拥有大量文件，照片，文件夹，文档和其他数据。如果找到一个特定的文件是非常痛苦的。幸运的是，Mac中的Spotlight模式可让我在Mac上搜索几乎任何内容，从而轻松找到您需要的任何内容。如下图： 正是因为习惯了在Mac OS X通过Spotlight模式进行搜索应用、文件，所以今天装机的时候找了一下Windows的替代方案。 文件搜索神器-Everything基本简介基于名称快速定位文件和文件夹。 轻量安装文件 干净简洁的用户界面 快速文件索引 快速搜索 最小资源使用 便于文件分享 实时更新 更多… 中文官网 下载地址 中文文档 使用体验 Spotlight快速检索替代方案-Wox基本简介Wox是一款国产开源免费的软件快捷启动工具，它可以快速搜索并打开你电脑上的程序、文件、查词翻译、网站查找等其他操作，同时还支持插件安装。 Tips: 如果你需要用到文件的快速搜索、打开功能，需要预先安装Everything。 官网 下载地址 中文文档 Github地址 使用体验启动方式快捷键启动按下【Alt+Space】即可，可以在setting里设置。我设置的快捷键设置为【Ctrl+Space】,和Mac快捷键保持一致。 设置刚刚使用Wox的用户，常常会找不到Wox的设置页面。目前，用户有两种方式打开设置界面： 通过setting命令（推荐）。如下图所示，直接输入setting然后选择第一项； 通过右键托盘图标。 在setting里，可以设置主题、窗口设置、快捷键设置、搜索设置、插件设置，读者可根据自身需求进行相应的设置即可。 应用搜索 浏览器搜索 命令终端执行替换Windows的命令终端，替换Windows键+R键。","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"Spring Cloud-Feign使用时获取apollo配置失败问题","slug":"Spring Cloud-Feign使用时获取apollo配置失败问题","date":"2019-05-28T01:27:55.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2019/05/28/Spring Cloud-Feign使用时获取apollo配置失败问题/","link":"","permalink":"http://ltyeamin.github.io/2019/05/28/Spring Cloud-Feign使用时获取apollo配置失败问题/","excerpt":"","text":"问题描述今天发现一个很诡异的事情，就是本地写死的FeignClient的url属性配置进行feign调用没问题，但是把配置迁移到Ctrip Apollo配置中心feign调用就有问题。 代码片段123456789101112131415@FeignClient(url = \"$&#123;api.service.baseUrl&#125;\",name = \"sms-service\")public interface SmsClient &#123; /** * 发送短信验证码,4位数字,5分钟有效 */ @PostMapping(\"xxxx/xxxxx\") ApiResult&lt;String&gt; sendSmsVerifyCode(String xxx, Integer xxx) ; /** * 校验短信验证码 */ @PostMapping(\"xxxx/xxxxx\") ApiResult&lt;String&gt; checkSmsVerifyCode(String xxx, Integer codeType, String xxx) ;&#125; 报错日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115feign.RetryableException: $&#123;api.service.baseUrl&#125; executing POST http://$&#123;api.service.baseUrl&#125;/xxx/xxx?xxx=18800009999&amp;xxx=8 at feign.FeignException.errorExecuting(FeignException.java:65) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:105) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:77) at feign.ReflectiveFeign$FeignInvocationHandler.invoke(ReflectiveFeign.java:102) at com.sun.proxy.$Proxy148.sendSmsVerifyCode(Unknown Source) at com.yimi.darwin.biz.open.copartner.service.impl.SmsServiceImpl.sendVerifyCode(SmsServiceImpl.java:33) at com.yimi.darwin.biz.open.copartner.controller.SmsController.sendVerifyCode(SmsController.java:62) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:891) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.yimi.tools.filter.RequestAndResponseLoggingFilter.doFilterWrapped(RequestAndResponseLoggingFilter.java:55) at com.yimi.tools.filter.RequestAndResponseLoggingFilter.doFilterInternal(RequestAndResponseLoggingFilter.java:47) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.cloud.sleuth.instrument.web.ExceptionLoggingFilter.doFilter(ExceptionLoggingFilter.java:48) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at brave.servlet.TracingFilter.doFilter(TracingFilter.java:86) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: java.net.UnknownHostException: $&#123;api.service.baseUrl&#125; at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at sun.net.NetworkClient.doConnect(NetworkClient.java:175) at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java:242) at sun.net.www.http.HttpClient.New(HttpClient.java:339) at sun.net.www.http.HttpClient.New(HttpClient.java:357) at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220) at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156) at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050) at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984) at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1564) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492) at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) at feign.Client$Default.convertResponse(Client.java:150) at feign.Client$Default.execute(Client.java:72) at org.springframework.cloud.sleuth.instrument.web.client.feign.TracingFeignClient.execute(TracingFeignClient.java:91) at org.springframework.cloud.sleuth.instrument.web.client.feign.LazyTracingFeignClient.execute(LazyTracingFeignClient.java:55) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:98) ... 89 common frames omitted 问题分析与解决我们从报错日志发现，api.service.baseUrl这个配置注入失败。 我为了验证，专门写一个测试接口，查看配置到底有没有加载： 1234567@Value(\"$&#123;api.service.baseUrl&#125;\")private String url;@GetMapping(\"/url\")public String getUrl() &#123; return url;&#125; 通过调用localhost:8301/url，接口响应了结果：https://xxx.com/, 此时，我们发现，项目中api.service.baseUrl却能拿到值，说明整个项目配置是OK的。 紧接着我们去apollo官方的github上找答案，也是在官方issue和wiki找到答案的。 当项目启动时候，会扫描@FeignClient注解，扫描的过程中，会注入url的值。但此时apollo配置是在Feign扫描后加载的，其实解决方案就是让apollo先于feign的扫描加载，即apollo配置饥饿加载。 1234# will inject &apos;application&apos; namespace in bootstrap phaseapollo.bootstrap.enabled = true# put apollo initialization before logging system initializationapollo.bootstrap.eagerLoad.enabled=true Spring Boot除了支持上述两种集成方式以外，还支持通过application.properties/bootstrap.properties来配置，该方式能使配置在更早的阶段注入，比如使用@ConditionalOnProperty的场景或者是有一些spring-boot-starter在启动阶段就需要读取配置做一些事情（如dubbo-spring-boot-project），所以对于Spring Boot环境建议通过以下方式来接入Apollo(需要0.10.0及以上版本）。 从1.2.0版本开始，如果希望把日志相关的配置（如logging.level.root=info或logback-spring.xml中的参数）也放在Apollo管理，那么可以额外配置apollo.bootstrap.eagerLoad.enabled=true来使Apollo的加载顺序放到日志系统加载之前，不过这会导致Apollo的启动过程无法通过日志的方式输出(因为执行Apollo加载的时候，日志系统压根没有准备好呢！所以在Apollo代码中使用Slf4j的日志输出便没有任何内容)，更多信息可以参考PR 1614。参考配置示例如下： # will inject ‘application’ namespace in bootstrap phase apollo.bootstrap.enabled = true # put apollo initialization before logging system initialization apollo.bootstrap.eagerLoad.enabled=true 值得注意的是，如果您的apollo client依赖版本是1.1.0及以下的，加了以上的配置，发现是没有用的。我们可以尝试手动去加载。 12345678910111213import com.ctrip.framework.apollo.ConfigService;public class ClientUrlConfig &#123; public void init() &#123; this.initSet(\"此处写你需要提前初始化的key\"); &#125; private void initSet(String... keys) &#123; for (String key : keys) &#123; String val = ConfigService.getAppConfig().getProperty(key, null); System.setProperty(key, val); &#125; &#125;&#125; 然后在SpringApplication.run() 之前加载 1234public static void main(String[] args) &#123; new ClientUrlConfig().init(); SpringApplication.run(Application.class, args);&#125; 手动加载后，我们就可以正常使用 ${api.service.baseUrl}进行加载以及Feign调用了。","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ltyeamin.github.io/tags/Spring-Cloud/"}]},{"title":"聊聊Java锁的那些事","slug":"聊聊Java锁的那些事","date":"2019-04-02T13:12:49.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2019/04/02/聊聊Java锁的那些事/","link":"","permalink":"http://ltyeamin.github.io/2019/04/02/聊聊Java锁的那些事/","excerpt":"","text":"昨天我们学习了HashMap相关的源码，本来打算今天写ConcurrentHashMap源码分析，但是ConcurrentHashMap涉及到一些锁的概念，所以我觉得越是底层的东西，越是要好好研究一番，今天趁此机会好好的系统学习一下。 那么今天就来聊聊Java锁的那些事情。Java为我们提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据(比较悲观)，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 根据从上面的概念描述我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 只说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例： 1234567891011121314151617181920// ------------------------- 悲观锁的调用方式 -------------------------// synchronizedpublic void testMethod() &#123; synchronized &#123; // 操作同步资源 &#125;&#125;// ReentrantLock// 需要保证多个线程使用的是同一个锁private ReentrantLock lock = new ReentrantLock(); public void modifyPublicResources() &#123; lock.lock(); // 操作同步资源 lock.unlock();&#125;// ------------------------- 乐观锁的调用方式 -------------------------// 需要保证多个线程使用的是同一个private AtomicInteger atomicInteger = new AtomicInteger();// 执行自增1AtomicInteger atomicInteger.incrementAndGet(); 通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。 CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。 CAS算法涉及到三个操作数： 需要读写的内存值 V； 进行比较的值 A； 要写入的新值 B。 当且仅当 V 内存值指向的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。 之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义： 12345678910111213141516public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; &#125; 根据定义我们可以看出各属性的作用： unsafe： 获取并操作内存的数据。 valueOffset： 存储value在AtomicInteger中的偏移量。 value： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。 接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码： 123456789101112131415161718192021222324/ ------------------------- JDK 8 -------------------------// AtomicInteger 自增方法public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;// Unsafe.classpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;// ------------------------- OpenJDK 8 -------------------------// Unsafe.javapublic final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; 根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。 后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。 CAS虽然很高效，但是它也存在三大问题，这里也简单说一下： ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作 。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 有关于CAS和Unsafe的具体详解，我后续为大家梳理。 自旋锁 VS 适应性自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的大家可以自行查阅相关资料。 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 首先为什么Synchronized能实现线程同步？ 在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 Java对象头synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？ 我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 锁状态 存储内容 存储内容 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 无锁无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 直接用语言描述可能有点抽象，这里笔者用从别处看到的一个例子来讲述一下公平锁和非公平锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： 接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。 根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 下面我们来看一下公平锁与非公平锁的加锁方法的源码: 通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget &#123; public synchronized void doSomething() &#123; System.out.println(\"方法1执行...\"); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(\"方法2执行...\"); &#125;&#125; 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。 还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。 释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。 独享锁 VS 共享锁独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 了解了概念之后我们再来看代码，先看写锁的加锁源码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码： 我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。 闭锁 VS 死锁 VS 活锁闭锁闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当到达结束状态时，这扇门会打开允许所有的线程通过。当闭锁到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动指导其他活动都完成后才继续执行。CountDownLatch就是一种灵活的闭锁实现。 死锁死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待（锁嵌套）的现象，若无外力作用，他们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足一下4个条件： 互斥条件：一个资源每次只能被一个进程使用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序做操作来避免死锁。 活锁LiveLock是一种形式活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。活锁通常发送在处理事务消息的应用程序中：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头。如果消息处理器在处理某种特定类型的消息时存在错误并导致它失败，那么每当这个消息从队列中取出并传递到存在错误的处理器时，都会发生事务回滚。由于这条消息又被放回到队列开头，因此处理器将被反复调用，并返回相同的结果。 总结本文Java中常用的锁以及常见的锁的概念进行了基本介绍，并从源码以及实际应用的角度进行了对比分析。限于篇幅以及个人水平，没有在本篇文章中对所有内容进行深层次的讲解。后续我本人将会对Java的锁进行依次讲解。 其实Java本身已经对锁本身进行了良好的封装，降低了我们在平时工作中的使用难度。但是我们也需要熟悉锁的底层原理，不同场景下选择最适合的锁。而且源码中的思路都是非常好的思路，也是值得大家去学习和借鉴的。 参考文献 《深入理解Java虚拟机（第2版）》周志明著 《Java并发编程的艺术》方腾飞等著 Java CAS 原理剖析 Java中的锁 Java synchronized原理总结 Java并发—关键字synchronized解析 聊聊并发（二）—Java SE1.6中的Synchronized 深入理解读写锁—ReadWriteLock源码分析 【JUC】JDK1.8源码分析之ReentrantReadWriteLock Java多线程（十）之ReentrantReadWriteLock深入分析 Java–读写锁的实现原理","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"深入分析HashMap源码","slug":"深入分析HashMap源码","date":"2019-04-01T12:47:22.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2019/04/01/深入分析HashMap源码/","link":"","permalink":"http://ltyeamin.github.io/2019/04/01/深入分析HashMap源码/","excerpt":"","text":"Map这种Key-Value格式的数据结构在日常开发中是非常的常见，大部分的高级编程语言都有Map类型，Map类型常用于在内存中存取数据。 在Java中，HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文深入探讨JDK1.8的HashMap的结构实现和功能原理。 Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示： 下面针对各个实现类的特点做一些说明： HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁（JDK8还有优化）。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。 搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。众所周知 HashMap 底层是基于数组+链表组成的，下面我们针对这两个方面详细展开讲解。 数据结构在JDK1.7之前的HashMap的结构中，其实存在一个很明显的缺陷就是: 当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)。 JDK8重点优化了这个查询效率，在原先的数组+链表上再增加红黑树。当链表大小达到一定的阈值(HashMap是8)时，会自动转换为红黑树的数据结构。修改为红黑树之后查询效率即时间复杂度直接提高到了 O(logn)。 源码分析成员变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * 默认位桶数组初始容量,必须是2的幂,这里默认是16 * The default initial capacity - MUST be a power of two. */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * 位桶数组大小的最大值。构造参数的大小必须是2的几次幂并且小于等于1&lt;&lt;30 * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * 默认负载因子是0.75，可以在构造参数里设置 * The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 一个桶中的bin的存储方式由链表转换为红黑树的阈值，当链表大小超过TREEIFY_THRESHOLD的时候转换为红黑树 * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */static final int TREEIFY_THRESHOLD = 8;/** * 红黑数转换为链表(收缩机制)，当执行resize操作时,桶中bin的数量少于UNTREEIFY_THRESHOLD时6时，此时收 * 缩为普通链表，提高查询效率 * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */static final int UNTREEIFY_THRESHOLD = 6;/** * 当桶中bin被树化时最小的hash表容量.(若没有达到这个阈值,即hash表容量小于MIN_TREEIFY_CAPACITY * 当桶中bin数量太多时会执行resize扩容操作).这个MIN_TREEIFY_CAPACITY的值至少TREEIFY_THRESHOLD * 的4倍。 * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */static final int MIN_TREEIFY_CAPACITY = 64;/** * 位桶数组，即Hash表，其大小总是2的几次幂，JDK1.7类型是Entry&lt;K,V&gt;[],JDK8优化成Node&lt;K,V&gt;[] * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */transient Node&lt;K,V&gt;[] table;/** * 缓存的entrySet，即键值对映射对象，这里使用了AbstractMap的keyset()和values() * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;/** * 当前map中包含的key-value数，即map的大小 * The number of key-value mappings contained in this map. */transient int size;/** * * HashMap的修改次数，在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount， * 比如迭代器迭代时候我们手动删除元素时，modCount会增加这个值。在迭代过程中，判断modCount和 * expectedModCount是否相等，不相等则抛出ConcurrentModificationException异常，这就是所谓的 * Fail-Fast机制。同样，ArrayList,LinkedList也有这个字段。 * 具体详情请参照HashMap源码下的抽象迭代类HashIterator， * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */transient int modCount;/** * 要根据threshold的阈值来判断map是否要扩容，即threshold = capacity * load factor， * 第一次扩容为16 * 0.75 = 12 ， 当map的数组容量为12的时，此时需要继续扩容。 * The next size value at which to resize (capacity * load factor). * * @serial */// (The javadoc description is true upon serialization.// Additionally, if the table array has not been allocated, this// field holds the initial array capacity, or zero signifying// DEFAULT_INITIAL_CAPACITY.)int threshold;/** * hash table的默认负载因子，默认是DEFAULT_LOAD_FACTOR，即0.75 * The load factor for the hash table. * @serial */final float loadFactor; 数据结构Node位桶节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 基本的hash桶节点，即数组存放的元素类型，实现了Map.Entry&lt;K,V&gt;接口。 * JDK1.7的结构是Map.Entry&lt;K, V&gt;的子类HashEntry&lt;K, V&gt; * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // key的哈希值，用来定位数组索引位置 final int hash; // map的key，不可不变对象，一旦设置新Key，不可更改key的值，HashMap中可存null值 final K key; // map的value，也可以存放null值。key相同则覆盖value, V value; // 链表的下一个node Node&lt;K,V&gt; next; // 构造函数 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; // 获取key public final K getKey() &#123; return key; &#125; // 获取value public final V getValue() &#123; return value; &#125; // 重写toString public final String toString() &#123; return key + \"=\" + value; &#125; // 重写hashCode，node的hashCode为key的hashCode与value的hashCode的异或结果 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; // 设置新的value，返回旧的value public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 一般重写了hashCode方法，equals也会重写。 public final boolean equals(Object o) &#123; // 引用都是一个，则判断是同一个对象，直接返回true if (o == this) return true; // 判断是否是Map.Entry同一类型，若类型不同，则返回false if (o instanceof Map.Entry) &#123; // 若是 Map.Entry类型，进行向下转型。 Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; // 如果两个对象的key和value同时都相等，则认为是相等，返回true if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; TreeNode红黑树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/** * 红黑树节点，继承LinkedHashMap.Entry&lt;K,V&gt; * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; /** * 把红黑树的根节点设为 其所在的数组槽 的第一个元素 * 首先明确：TreeNode既是一个红黑树结构，也是一个双链表结构 * 这个方法里做的事情，就是保证树的根节点一定也要成为链表的首节点 */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; // 根节点不为空 并且 HashMap的元素数组不为空 int index = (n - 1) &amp; root.hash; // 根据根节点的Hash值 和 HashMap的元素数组长度 取得根节点在数组中的位置 TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; // 首先取得该位置上的第一个节点对象 if (root != first) &#123; // 如果该节点对象 与 根节点对象 不同 Node&lt;K,V&gt; rn; // 定义根节点的后一个节点 tab[index] = root; // 把元素数组index位置的元素替换为根节点对象 TreeNode&lt;K,V&gt; rp = root.prev; // 获取根节点对象的前一个节点 if ((rn = root.next) != null) // 如果后节点不为空 ((TreeNode&lt;K,V&gt;)rn).prev = rp; // root后节点的前节点 指向到 root的前节点，相当于把root从链表中摘除 if (rp != null) // 如果root的前节点不为空 rp.next = rn; // root前节点的后节点 指向到 root的后节点 if (first != null) // 如果数组该位置上原来的元素不为空 first.prev = root; // 这个原有的元素的 前节点 指向到 root，相当于root目前位于链表首位 root.next = first; // 原来的第一个节点现在作为root的下一个节点，变成了第二个节点 root.prev = null; // 首节点没有前节点 &#125; /* * 这一步是防御性的编程 * 校验TreeNode对象是否满足红黑树和双链表的特性 * 如果这个方法校验不通过：可能是因为用户编程失误，破坏了结构（例如：并发场景下）；也可能是TreeNode * 的实现有问题（这个是理论上的以防万一）； */ assert checkInvariants(root); &#125; &#125; /** * 参数为HashMap的元素数组 */ final void treeify(Node&lt;K,V&gt;[] tab) &#123; // 定义树的根节点 TreeNode&lt;K,V&gt; root = null; // 遍历链表，x指向当前节点、next指向下一个节点 for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; // 下一个节点 x.left = x.right = null; // 设置当前节点的左右节点为空 if (root == null) &#123; // 如果还没有根节点 x.parent = null; // 当前节点的父节点设为空 x.red = false; // 当前节点的红色属性设为false（把当前节点设为黑色） root = x; // 根节点指向到当前节点 &#125; else &#123; // 如果已经存在根节点了 K k = x.key; // 取得当前链表节点的key int h = x.hash; // 取得当前链表节点的hash值 Class&lt;?&gt; kc = null; // 定义key所属的Class for (TreeNode&lt;K,V&gt; p = root;;) &#123; // 从根节点开始遍历，此遍历没有设置边界，只能从内部跳出 // GOTO1 int dir, ph; // dir 标识方向（左右）、ph标识当前树节点的hash值 K pk = p.key; // 当前树节点的key if ((ph = p.hash) &gt; h) // 如果当前树节点hash值 大于 当前链表节点的hash值 dir = -1; // 标识当前链表节点会放到当前树节点的左侧 else if (ph &lt; h) dir = 1; // 右侧 /* * 如果两个节点的key的hash值相等，那么还要通过其他方式再进行比较 * 如果当前链表节点的key实现了comparable接口，并且当前树节点和链表节点是相同Class的实 * 例，那么通过comparable的方式再比较两者。 * 如果还是相等，最后再通过tieBreakOrder比较一次 */ else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; // 保存当前树节点 /* * 如果dir 小于等于0 ： 当前链表节点一定放置在当前树节点的左侧，但不一定是该树节点的左孩 * 子，也可能是左孩子的右孩子 或者 更深层次的节点。如果dir 大于0 ： 当前链表节点一定放置在 * 当前树节点的右侧，但不一定是该树节点的右孩子，也可能是右孩子的左孩子 或者 更深层次的节 * 点。 * * 如果当前树节点不是叶子节点，那么最终会以当前树节点的左孩子或者右孩子为起始节点 再从 * GOTO1 处开始 重新寻找自己（当前链表节点）的位置。 * 如果当前树节点就是叶子节点，那么根据dir的值，就可以把当前链表节点挂载到当前树节点的左或 * 者右侧了。 * 挂载之后，还需要重新把树进行平衡。平衡之后，就可以针对下一个链表节点进行处理了。 */ if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; // 当前链表节点 作为 当前树节点的子节点 if (dir &lt;= 0) xp.left = x; // 作为左孩子 else xp.right = x; // 作为右孩子 root = balanceInsertion(root, x); // 重新平衡 break; &#125; &#125; &#125; &#125; // 把所有的链表节点都遍历完之后，最终构造出来的树可能经历多个平衡操作，根节点目前到底是链表的哪一个节点是不确定的 // 因为我们要基于树来做查找，所以就应该把 tab[N] 得到的对象一定根节点对象，而目前只是链表的第一个节点对象，所以要做相应的处理。 moveRootToFront(tab, root); &#125;&#125; 重要方法hash方法1234567891011121314151617181920212223242526272829303132/** * 计算key的hash值， * key为null则hashCode为0;不为null则将key的hashCode赋值给h，最终的hashCode = h ^ (h &gt;&gt;&gt; 16); * 这里我们要讲讲数组索引的计算方式：(n- 1) &amp; hash,n表示table.length * 这里通过key.hashCode()计算出key的哈希值，然后将哈希值h右移16位，再与原来的h做异或^运算，这一步是高位运 * 算。设想一下，如果没有高位运算，那么hash值将是一个int型的32位数。而从2的-31次幂到2的31次幂之间，有将近几 * 十亿的空间，如果我们的HashMap的table有这么长，内存早就爆了。所以这个散列值不能直接用来最终的取模运算，而 * 需要先加入高位运算，将高16位和低16位的信息\"融合\"到一起，也称为\"扰动函数\"。这样才能保证hash值所有位的数值 * 特征都保存下来而没有遗漏，从而使映射结果尽可能的松散。最后，根据 n-1 做与操作的取模运算。这里也能看出为什么 * HashMap要限制table的长度为2的n次幂，因为这样，n-1可以保证二进制展示形式是（以16为例）0000 0000 0000 * 0000 0000 0000 0000 1111。在做\"与\"操作时，就等同于截取hash二进制值得后四位数据作为下标。这里也可以看 * 出\"扰动函数\"的重要性了，如果高位不参与运算，那么高16位的hash特征几乎永远得不到展现，发生hash碰撞的几率就 * 会增大，从而影响性能。 * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; put方法1234// 我们实际用的put方法，底层调用的是putVal方法public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * Implements Map.put and related methods. * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * (onlyIfAbsent为true时，如果key存在，就不会进行put操作，原有的对应的value不会被覆盖) * @param evict if false, the table is in creation mode. * (evict参数用于LinkedHashMap中的尾部操作，这里没有实际意义。) * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 定义变量tab是将要操作的Node数组引用，p表示tab上的某Node节点，n为tab的长度，i为tab的下标。 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断当table为null或者tab的长度为0时，即table尚未初始化，此时通过resize()方法得到初始化的table。 if ((tab = table) == null || (n = tab.length) == 0) // 这种情况是可能发生的，HashMap的table字段注释中提到：The table, initialized on first use, and resized as necessary。 n = (tab = resize()).length; // 此处通过(n - 1)&amp; hash计算出的值作为tab的下标i，并另p表示tab[i]，也就是该链表第一个节点的位置。并判断p是否为null。 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 当p为null时，表明tab[i]上没有任何元素，即不存在Hash冲突，那么接下来就new第一个Node节点，调用newNode方法返回新节点赋值给tab[i]。这里值得注意的是i = (n - 1) &amp; hash相当于对hash对n的取模 tab[i] = newNode(hash, key, value, null); // 下面进入p不为null的情况，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。 else &#123; // 定义e引用,表示即将插入的Node节点，并且下文可以看出 k = p.key。 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; // HashMap中判断key相同的条件是key的hash相同（Hash是否冲突），并且符合equals方法。这里判断了p.key是否和插入的key相等，如果相等，则将p的引用赋给e。e会在最后统一进行赋值及返回。 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 这一步的判断其实是属于一种特殊情况，上述三个条件都满足，即两者hash值相同且key完全相同，于是插入操作就不需要了，只要把原来的value覆盖就可以了。e会在最后统一进行赋值及返回，这里先不进行覆盖操作。 e = p; else if (p instanceof TreeNode) // 现在开始了第一种情况，当前桶p是红黑树节点，那么肯定插入后仍然是红黑树节点，就要按照红黑树的方式写入数据。所以我们直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e。 // 你可能好奇，这里怎么不遍历tree看看有没有key相同的节点呢？其实，putTreeVal内部进行了遍历，存在相同hash时返回被覆盖的TreeNode，否则返回null。 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 接下里就是p为链表节点的情形，也就是上述说的另外两类情况：插入后还是链表/插入后转红黑树。另外，上行转型代码也说明了TreeNode是Node的一个子类。 else &#123; // 我们需要一个计数器来计算当前链表的元素个数，并遍历链表，binCount就是这个计数器。 for (int binCount = 0; ; ++binCount) &#123; // 遍历过程中当发现p.next为null时，说明链表到头了，就需要将当前的key、value封装成一个新节点,将新的链表节点直接在p的后面插入即可，即把新节点的引用赋给p.next，插入操作就完成了。注意此时e赋给p。 if ((e = p.next) == null) &#123; // 最后一个参数为新节点的next，这里传入null，保证了新节点继续为该链表的末端。 p.next = newNode(hash, key, value, null); // 插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1。binCount大于等于7（其实实际上链表此时的大小为8）时转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 当满足上述转换条件时，调用treeifyBin方法，将该链表转换为红黑树。 treeifyBin(tab, hash); // 当然如果不满足转换条件，那么插入数据后结构也无需变动，所有插入操作也到此结束了，break退出即可。 break; &#125; // 在遍历链表的过程中，有可能遍历到与插入的key相同的节点，此时只要将这个节点引用赋值给e，最后通过e去把新的value覆盖掉就可以了。 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到了相同key的节点，那么插入操作也不需要了，直接break退出循环进行最后的value覆盖操作。 break; // e是当前遍历的节点p的下一个节点，p = e 就是依次遍历链表的核心语句。每次循环时p都是下一个node节点。 p = e; &#125; &#125; // 下面JDK注释已经很清晰了，针对已经存在key的情况做处理。即我们对e进行处理。 if (e != null) &#123; // existing mapping for key //定义oldValue，即原存在的节点e的value值。 V oldValue = e.value; // 方法注释提到，onlyIfAbsent为true时，若存在key相同时不做覆盖处理，这里作为判断条件，可以看出当onlyIfAbsent为默认值false或者oldValue为null时，进行覆盖操作。 if (!onlyIfAbsent || oldValue == null) // 覆盖操作，将原节点e上的value设置为插入的新value。 e.value = value; // 这个函数在hashmap中没有任何操作，是个空函数，它存在主要是为了linkedHashMap的一些后续处理工作。 afterNodeAccess(e); // 返回的是被覆盖的oldValue。我们在使用put方法时很少用他的返回值，甚至忘了它的存在，这里我们知道，他返回的是被覆盖的oldValue。 return oldValue; &#125; &#125; // 收尾工作，值得一提的是，对key相同而覆盖oldValue的情况，在前面已经return，不会执行这里，所以那一类情况不算数据结构变化，并不改变modCount值。如果走到这里，说明已经新增一个Key-Value的Node节点，modCount要自增 ++modCount; // 同理，覆盖oldValue时显然没有新元素添加，除此之外都新增了一个元素，这里++size并与threshold判断是否达到了扩容标准。 if (++size &gt; threshold) // 当HashMap中存在的node节点大于threshold时，hashmap进行扩容。 resize(); // 这里与前面的afterNodeAccess同理，是用于linkedHashMap的尾部操作，HashMap中并无实际意义。 afterNodeInsertion(evict); // 最终，对于真正进行插入元素(不是覆盖的操作)的情况，put函数一律返回null。 return null;&#125; get方法123456// 我们实际用的get方法，底层调用的是getNode方法public V get(Object key) &#123; Node&lt;K,V&gt; e; // 根据key及其hash值查询node节点，如果存在，则返回该节点的value值；如果不存在，则返回null。 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 1234567891011121314151617181920212223242526272829303132333435363738/** * Implements Map.get and related methods. * * @param hash hash for key * @param key the key * @return the node, or null if none 。 * 如果找到node返回node，没有找到node则返回null * 根据key搜索节点的方法。记住判断key相等的条件：hash值相同 并且 符合equals方法。 */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; // 定义变量tab是将要遍历查找的Node数组引用，first和e表示tab上的找到的Node节点，n为tab的长度，k为Key Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 根据输入的hash值，可以直接计算出对应的下标(n - 1) &amp; hash，缩小查询范围，如果存在结果，则必定在table的这个位置上。 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 判断第一个存在的节点的key是否和查询的key相等。如果相等，直接返回该节点。 return first; // 如果第一个不匹配，则判断它的下一个是红黑树还是链表。遍历该链表/红黑树直到next为null。 if ((e = first.next) != null) &#123; // 红黑树就按照树的查找方式返回值。 if (first instanceof TreeNode) // 当这个table节点上存储的是红黑树结构时，在根节点first上调用getTreeNode方法，在内部遍历红黑树节点，查看是否有匹配的TreeNode。 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表的方式遍历匹配返回值。 do &#123; // 当这个table节点上存储的是链表结构时，若两者hash相同且key是否完全相同则直接返回。 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; // 如果key不同，一直遍历下去直到链表尽头，直到e.next == null才终止循环。 &#125; while ((e = e.next) != null); &#125; &#125; // 没有找到则返回null。 return null;&#125; resize方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151/** * map扩容机制 * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; // 当前所有元素所在的数组，称为老的元素数组 Node&lt;K,V&gt;[] oldTab = table; // 老的元素数组长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 老的扩容阀值设置 int oldThr = threshold; // 新数组的容量，新数组的扩容阀值都初始化为0 int newCap, newThr = 0; // 如果老数组长度大于0，说明已经存在元素 if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，即2的30次方时，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 扩容阀值设置为int最大值（2的31次方 -1 ），因为oldCap再乘2就溢出了。 threshold = Integer.MAX_VALUE; // 超过了最大的容量，不能扩容，直接返回老的元素数组 return oldTab; &#125; /* 没超过最大值，就扩充为原来的2倍 * 如果数组元素个数在正常范围内，那么新的数组容量为老的数组容量的2倍（左移1位相当于乘以2） * 如果扩容之后的新容量小于最大容量并且老的数组容量大于等于默认初始化容量（16），那么新数组的扩 * 容阀值设置为老阀值的2倍。（老的数组容量大于16意味着：要么构造函数指定了一个大于16的初始化容量值， * 要么已经经历过了至少一次扩容） */ else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 运行到这个else if,说明老数组没有任何元素 else if (oldThr &gt; 0) // initial capacity was placed in threshold // 如果老数组的扩容阀值大于0，那么设置新数组的容量为该阀值,这一步也就意味着构造该map的时候，指定了初始化容量 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 能运行到这里的话，说明是调用无参构造函数创建的该map，并且第一次添加元素 // 设置新数组容量为16 newCap = DEFAULT_INITIAL_CAPACITY; // 设置新数组扩容阀值为 16 * 0.75 = 12。0.75为负载因子(当元素个数达到容量了4分之3，那么扩容) newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 如果扩容阀值为0 if (newThr == 0) &#123; // 计算新的resize上限 float ft = (float)newCap * loadFactor; // 计算扩容阀值 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 设置新数组的扩容阀值 threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) // 创建新的数组（对于第一次添加元素，那么这个数组就是第一个数组；对于存在oldTab的时候，那么这个数组就是要需要扩容到的新数组） Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 将该map的table属性指向到该新数组newTab table = newTab; // 如果老数组不为空，说明是扩容操作，那么涉及到元素的转移操作 if (oldTab != null) &#123; // 遍历老数组把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; // 数组中的某个元素 Node&lt;K,V&gt; e; // 如果当前位置元素不为空，那么需要转移该元素到新数组 if ((e = oldTab[j]) != null) &#123; // 释放掉老数组对于要转移走的元素的引用（主要为了使得数组可被回收） oldTab[j] = null; // 如果元素没有有下一个节点，说明该元素不存在hash冲突 if (e.next == null) // 把元素存储到新的数组中，存储到数组的哪个位置需要根据hash值和数组长度来进行取模 // 【hash值 % 数组长度】 = 【 hash值 &amp; （数组长度-1）】 // 这种与运算求模的方式要求 数组长度必须是2的N次方，但是可以通过构造函数随意指定初始化容量呀，如果指定了17,15这种，岂不是出问题了就？没关系，最终会通过tableSizeFor方法将用户指定的转化为大于其并且最相近的2的N次方。 15 -&gt; 16、17-&gt; 32 newTab[e.hash &amp; (newCap - 1)] = e; /* * 如果该元素有下一个节点，那么说明该位置上存在一个链表了（hash相同的多个元素以链表的方式存 * 储到了老数组的这个位置上了）。例如：数组长度为16，那么hash值为1（1%16=1）的和hash值为 * 17（17%16=1）的两个元素都是会存储在数组的第2个位置上（对应数组下标为1），当数组扩容为 * 32（1%32=1）时，hash值为1的还应该存储在新数组的第二个位置上，但是hash值为17(17%32=1 * 7)的就应该存储在新数组的第18个位置上了。所以，数组扩容后，所有元素都需要重新计算在新数组 * 中的位置。 */ else if (e instanceof TreeNode) // 如果该节点为TreeNode类型 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 链表优化重hash的代码块 // 按命名来翻译的话，应该叫低位首尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; // 按命名来翻译的话，应该叫高位首尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; // 以上的低位指的是新数组的 0 到 oldCap-1 、高位指定的是oldCap 到 newCap - 1 Node&lt;K,V&gt; next; // 遍历链表 do &#123; // next表示下一个node节点 next = e.next; // 原索引 // 这一步判断好狠，拿元素的hash值和老数组的长度做与运算 // 数组的长度一定是2的N次方(例如16)，如果hash值和该长度做与运算，结果为0，就说明该hash值和数组长度取模后的值一定小于数组长度（例如mod值为1）。 // 那么该hash值再和新数组的长度取摸的话mod值也不会放生变化，所以该元素的在新数组的位置和在老数组的位置是相同的，所以该元素可以放置在低位链表中。 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) // 如果没有尾，说明链表为空，链表为空时，头节点指向该元素。 loHead = e; else // 如果有尾，那么链表不为空，把该元素挂到链表的最后。 loTail.next = e; // 把尾节点设置为当前元素。 loTail = e; &#125; // 原索引+oldCap // 如果与运算结果不为0，说明hash值大于老数组长度（例如hash值为17）。 // 此时该元素应该放置到新数组的高位位置上。 // 例：老数组长度16，那么新数组长度为32，hash为17的应该放置在数组的第17个位置上，也就是下标为16，那么下标为16已经属于高位了，低位是[0-15]，高位是[16-31]。 else &#123; if (hiTail == null) // 如果没有尾，说明链表为空，链表为空时，头节点指向该元素。 hiHead = e; else // 如果有尾，那么链表不为空，把该元素挂到链表的最后。 hiTail.next = e; // 把尾节点设置为当前元素。 hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里，即低位的元素组成的链表还是放置在原来的位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里，即高位的元素组成的链表放置的位置只是在原有位置上偏移了老数组的长度个位置。 if (hiTail != null) &#123; hiTail.next = null; // 例1:hash为17在老数组放置在0下标,在新数组放置在16下标; // 例2:hash为18在老数组放置在1下标,在新数组放置在17下标。 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; // 返回新的位桶数组 return newTab;&#125; treeifyBin方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 转换为红黑树的操作 * 参数tab: 元素数组 * 参数hash: key的hashCode * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; /* * 如果元素数组为空或者数组长度小于 树结构化的最小限制 * MIN_TREEIFY_CAPACITY 默认值64，对于这个值可以理解为： * 如果元素数组长度小于这个值，没有必要去进行结构转换; * 当一个数组位置上集中了多个键值对，那是因为这些key的hash值和数组长度取模之后结果相同.(并不是因为这些 * key的hash值相同).因为hash值相同的概率不高，所以可以通过扩容的方式，来使得最终这些key的hash值在和新 * 的数组长度取模之后，拆分到多个数组位置上。 */ if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 如果数组为null或者小于MIN_TREEIFY_CAPACITY=64则进行扩容操作 resize(); // 如果元素数组长度已经大于等于了 MIN_TREEIFY_CAPACITY，那么就有必要进行结构转换了。 // 根据hash值和数组长度进行取模运算后，得到链表的首节点。 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // 定义首、尾节点。 TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; // 将该节点转换为树节点。 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); // 如果尾节点为空，说明还没有根节点。 if (tl == null) // 首节点（根节点）指向当前节点 hd = p; else &#123; // 尾节点不为空，以下两行代码是一个双向链表结构 // 当前树节点的 前一个节点指向尾节点 p.prev = tl; // 尾节点的 后一个节点指向当前节点 tl.next = p; &#125; // 把当前节点设为尾节 tl = p; // 当遍历尾节点为null时候，则结束，否则有节点继续遍历链表 &#125; while ((e = e.next) != null); // 到目前为止 也只是把Node对象转换成了TreeNode对象，把单向链表转换成了双向链表 // 把转换后的双向链表，替换原来位置上的单向链表 if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; tableSizeFor方法1234567891011121314/** * 返回大于输入参数且最近的2的整数次幂的数，例如输入14，则返回2的4次幂，即16。 * 如果算出来的n大于等于最大的容量，则取最大的容量。 * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 先来分析有关n位操作部分：先来假设n的二进制为01xxx…xxx。接着 对n右移1位：001xx…xxx，再位或：011xx…xxx 对n右移2为：00011…xxx，再位或：01111…xxx 此时前面已经有四个1了，再右移4位且位或可得8个1 同理，有8个1，右移8位肯定会让后八位也为1。 综上可得，该算法让最高位的1后面的位全变为1。 最后再让结果n+1，即得到了2的整数次幂的值了。 现在回来看看第一条语句： 1int n = cap - 1; 让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。 参考文献 Java8系列之重新认识HashMap Java7HashMap知识点整理","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ltyeamin.github.io/tags/Java/"}]},{"title":"红黑树深入剖析及Java实现","slug":"红黑树深入剖析及Java实现","date":"2019-03-29T11:00:09.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2019/03/29/红黑树深入剖析及Java实现/","link":"","permalink":"http://ltyeamin.github.io/2019/03/29/红黑树深入剖析及Java实现/","excerpt":"","text":"谈到数据结构的树，笔者的印象中还是在大学时期的概念，最早的概念源自于哈夫曼树(最优二叉树)，其他的树结构还有二叉查找树、完全二叉树、平衡二叉树(又分为AVL树、RB红黑树、SBT、伸展树、TREAP、替罪羊树 ）、平衡多叉树（B - Tree 和B+ Tree)等，今天我们来研究一下平衡二叉树的RB红黑树，因为RB红黑树在JAVA中的实现还是蛮多的。 红黑树是平衡二叉查找树的一种。为了深入理解红黑树，我们先回忆一下大学数据结构中的二叉查找树。 二叉查找树基本概念百度百科定义如下： 二叉排序树（Binary Sort Tree），又称二叉查找树（Binary Search Tree），亦称二叉搜索树。 二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： （1）若左子树不空，则左子树上所有结点的值均小于它的根结点的值； （2）若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； （3）左、右子树也分别为二叉排序树； 二叉查找树（Binary Search Tree，简称BST）是一棵二叉树，它的左子节点的值比父节点的值要小，右节点的值要比父节点的值大。它的高度决定了它的查找效率。 在理想的情况下，二叉查找树增删查改的时间复杂度为O(logN)（其中N为节点数），最坏的情况下为O(N)。当它的高度为logN+1时，我们就说二叉查找树是平衡的。 基本操作查找1234567891011121314151617181920212223242526// 定义一个搜索的KeyT key = a search key// 树的节点，当前节点指的是树的根节点Node root = point to the root of a BST//循环查找树while(true)&#123; // 根节点为空，直接结束，无法继续查询 if(root==null)&#123; break; &#125; // 如果查找到，直接返回当前的节点 if(root.value.equals(key))&#123; return root; &#125; // 没有查到则做比较继续查询，如果当前要查找的key与当前节点value做比较，若key小于当前节点的value在左子树查找 else if(key.compareTo(root.value)&lt;0)&#123; root = root.left; &#125; // 若key大于当前节点的value在右子树查找 else&#123; // 将右字数指向的root节点，继续查找 root = root.right; &#125;&#125;// 没有查找则返回nullreturn null; 从程序中可以看出，当BST查找的时候，先与当前节点进行比较： 如果相等的话就返回当前节点； 如果少于当前节点则继续查找当前节点的左节点； 如果大于当前节点则继续查找当前节点的右节点 直到当前节点指针为空或者查找到对应的节点，程序查找结束。 插入1234567891011121314151617181920212223242526272829303132333435// 新节点Node node = create a new node with specify value// 树的节点，默认当前节点指的是树的根节点Node root = point the root node of a BST// 父节点引用Node parent = null;//find the parent node to append the new node// 在循环中，找待插入节点的父节点while(true)&#123; // 如果根节点不存在，则直接结束，添加失败。 if(root==null) break; // 将父节点指向根节点 parent = root; // 如果新节点的value值小于等于root节点value的，添加到左子树，找左子树的父节点 if(node.value.compareTo(root.value)&lt;=0)&#123; root = root.left; &#125;else&#123; // 否则，添加到右子树，找右子树的父节点 root = root.right; &#125; &#125;//如果父节点不为null，执行添加操作if(parent!=null)&#123; // 开始添加操作 if(node.value.compareTo(parent.value)&lt;=0)&#123; // 添加左子树 //append to left parent.left = node; &#125;else&#123; // append to right // 开始添加操作，添加右子树 parent.right = node; &#125;&#125; 插入操作先通过循环查找到待插入的节点的父节点，和查找父节点的逻辑一样，都是比大小，小的往左，大的往右。找到父节点后，对比父节点，小的就插入到父节点的左节点，大就插入到父节点的右节点上。 删除1234567891011121314151617181920212223242526272829// 待删除节点，可根据查找代码查找出待删除的节点Node node = delete a new node with specify value// 如果节点存在，则进行删除if (node != null) &#123; // 如果节点有左子树，则继续操作 if (node.left != null) &#123; // 找到其左子树的最右边的叶子结点leftR，用该叶子结点leftR来替代待删除的节点node.把leftR的左孩子作为leftR的父亲的右孩子。 Node leftR = node.left; // 先前的节点的备份 Node prev = node.left; while(leftR.left != null) &#123; prev = leftR; leftR = leftR.right; &#125; // 将查找到的leftR.value赋值到node.value node.value = leftR.value; // 若leftR不是node的左子树,node的左子树不变，leftR的左子树作为leftR的父结点的右孩子结点 if(prev != leftR) &#123; prev.right = leftR.left; &#125; else &#123; // 若是leftR的左子树，则node的左子树指向leftR的左子树 node.left=leftR.right; &#125; &#125; else &#123; // 如果节点有左子树，直接用node节点的右孩子取代它 node = node.right; &#125;&#125; 删除操作的步骤如下： 查找到要删除的节点。 如果待删除的节点是叶子节点，即PL(左子树)和PR(右子树)均为空树，由于删去叶子结点不破坏整棵树的结构，则直接删除。 如果待删除的节点不是叶子节点，则先找到待删除节点的中序遍历的后继节点，用该后继节点的值替换待删除的节点的值，然后删除后继节点。 存在的弊端BST存在的主要问题是，数在插入的时候会导致树倾斜，不同的插入顺序会导致树的高度不一样，而树的高度直接的影响了树的查找效率。理想的高度是logN，最坏的情况是所有的节点都在一条斜线上，这样的树的高度为N。 介于以上的弊端，我们有其他新的的树结构选择：Size Balanced Tree(SBT)、AVL树、RB红黑树、Treap(Tree+Heap)。这些均可以使查找树的高度为O(log(n))。 RB红黑树基本概念 红黑树（Red Black Tree） 是一种自平衡二叉查找树，又称对称二叉B树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。 它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。 红黑树和AVL树类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。 基于BST存在的问题，一种新的树——平衡二叉查找树(Balanced BST)产生了。平衡树在插入和删除的时候，会通过旋转操作将高度保持在logN。其中两款具有代表性的平衡树分别为AVL树和红黑树。AVL树由于实现比较复杂，而且插入和删除性能差，在实际环境下的应用不如红黑树。 红黑树（Red-Black Tree，以下简称RBTree）的实际应用非常广泛，比如Linux内核中的完全公平调度器、高精度计时器、ext3文件系统等等，各种语言的函数库如Java的TreeMap和TreeSet，C++ STL的map、multimap、multiset等。 RBTree也是函数式语言中最常用的持久数据结构之一，在计算几何中也有重要作用。值得一提的是，Java 8中HashMap的实现也因为用RBTree取代链表，性能有所提升。 基本定义RBTree的定义如下: 任何一个节点都有颜色，黑色或者红色； 根节点是黑色的； 父子节点之间不能出现两个连续的红节点 ； 任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等 ； 空节点被认为是黑色的。 数据结构表示如下： 1234567lass Node&lt;T&gt;&#123; public T value; public Node&lt;T&gt; parent; public boolean isRed; public Node&lt;T&gt; left; public Node&lt;T&gt; right;&#125; RBTree在理论上还是一棵BST树，但是它在对BST的插入和删除操作时会维持树的平衡，即保证树的高度在[logN,logN+1]（理论上，极端的情况下可以出现RBTree的高度达到2*logN，但实际上很难遇到）。这样RBTree的查找时间复杂度始终保持在O(logN)从而接近于理想的BST。RBTree的删除和插入操作的时间复杂度也是O(logN)。RBTree的查找操作就是BST的查找操作。 基本操作旋转操作旋转操作(Rotate)的目的是使节点颜色符合定义，让RBTree的高度达到平衡。 Rotate分为left-rotate（左旋）和right-rotate（右旋），区分左旋和右旋的方法是：待旋转的节点从左边上升到父节点就是右旋，待旋转的节点从右边上升到父节点就是左旋。 查找操作RBTree的查找操作和BST的查找操作是一样的。请参考BST的查找操作代码。 插入操作RBTree的插入与BST的插入方式是一致的，只不过是在插入过后，可能会导致树的不平衡，这时就需要对树进行旋转操作和颜色修复（在这里简称插入修复），使得它符合RBTree的定义。 新插入的节点是红色的，插入修复操作如果遇到父节点的颜色为黑则修复操作结束。也就是说，只有在父节点为红色节点的时候是需要插入修复操作的。 插入修复操作分为以下的三种情况，而且新插入的节点的父节点都是红色的： 叔叔节点也为红色。 叔叔节点为空，且祖父节点、父节点和新节点处于一条斜线上。 叔叔节点为空，且祖父节点、父节点和新节点不处于一条斜线上。 插入操作示例1 示例1的操作是将父节点和叔叔节点与祖父节点的颜色互换，这样就符合了RBTRee的定义。即维持了高度的平衡，修复后颜色也符合RBTree定义的第三条和第四条。下图中，操作完成后A节点变成了新的节点。如果A节点的父节点不是黑色的话，则继续做修复操作。 插入操作示例2 示例2的操作是将B节点进行右旋操作，并且和父节点A互换颜色。通过该修复操作RBTRee的高度和颜色都符合红黑树的定义。如果B和C节点都是右节点的话，只要将操作变成左旋就可以了。 插入操作示例3 示例 3的操作是将C节点进行左旋，这样就从示例 3转换成示例 2了，然后针对示例 2进行操作处理就行了。示例 2操作做了一个右旋操作和颜色互换来达到目的。如果树的结构是下图的镜像结构，则只需要将对应的左旋变成右旋，右旋变成左旋即可。 插入操作的总结: 插入后的修复操作是一个向root节点回溯的操作，一旦牵涉的节点都符合了红黑树的定义，修复操作结束。之所以会向上回溯是由于示例 1操作会将父节点，叔叔节点和祖父节点进行换颜色，有可能会导致祖父节点不平衡(红黑树定义3)。这个时候需要对祖父节点为起点进行调节（向上回溯）。 祖父节点调节后如果还是遇到它的祖父颜色问题，操作就会继续向上回溯，直到root节点为止，根据定义root节点永远是黑色的。在向上的追溯的过程中，针对插入的3中情况进行调节。直到符合红黑树的定义为止。直到牵涉的节点都符合了红黑树的定义，修复操作结束。 如果上面的3中情况如果对应的操作是在右子树上，做对应的镜像操作就是了。 删除操作删除操作首先需要做的也是BST的删除操作，删除操作会删除对应的节点，如果是叶子节点就直接删除，如果是非叶子节点，会用对应的中序遍历的后继节点来顶替要删除节点的位置。删除后就需要做删除修复操作，使的树符合红黑树的定义，符合定义的红黑树高度是平衡的。 删除修复操作在遇到被删除的节点是红色节点或者到达root节点时，修复操作完毕。 删除修复操作是针对删除黑色节点才有的，当黑色节点被删除后会让整个树不符合RBTree的定义的第四条。需要做的处理是从兄弟节点上借调黑色的节点过来，如果兄弟节点没有黑节点可以借调的话，就只能往上追溯，将每一级的黑节点数减去一个，使得整棵树符合红黑树的定义。 删除操作的总体思想是从兄弟节点借调黑色节点使树保持局部的平衡，如果局部的平衡达到了，就看整体的树是否是平衡的，如果不平衡就接着向上追溯调整。 删除修复操作分为四种情况(删除黑节点后)： 待删除的节点的兄弟节点是红色的节点。 待删除的节点的兄弟节点是黑色的节点，且兄弟节点的子节点都是黑色的。 待调整的节点的兄弟节点是黑色的节点，且兄弟节点的左子节点是红色的，右节点是黑色的(兄弟节点在右边)， 如果兄弟节点在左边的话，就是兄弟节点的右子节点是红色的，左节点是黑色的。 待调整的节点的兄弟节点是黑色的节点，且右子节点是是红色的(兄弟节点在右边)，如果兄弟节点在左边，则就是对应的就是左节点是红色的。 删除操作示例1 由于兄弟节点是红色节点的时候，无法借调黑节点，所以需要将兄弟节点提升到父节点，由于兄弟节点是红色的，根据RBTree的定义，兄弟节点的子节点是黑色的，就可以从它的子节点借调了。 示例1这样转换之后就会变成后面的示例2，示例3，或者示例4进行处理了。上升操作需要对C做一个左旋操作，如果是镜像结构的树只需要做对应的右旋操作即可。 之所以要做示例1操作是因为兄弟节点是红色的，无法借到一个黑节点来填补删除的黑节点。 删除操作示例2 示例2的删除操作是由于兄弟节点可以消除一个黑色节点，因为兄弟节点和兄弟节点的子节点都是黑色的，所以可以将兄弟节点变红，这样就可以保证树的局部的颜色符合定义了。这个时候需要将父节点A变成新的节点，继续向上调整，直到整颗树的颜色符合RBTree的定义为止。 示例2这种情况下之所以要将兄弟节点变红，是因为如果把兄弟节点借调过来，会导致兄弟的结构不符合RBTree的定义，这样的情况下只能是将兄弟节点也变成红色来达到颜色的平衡。当将兄弟节点也变红之后，达到了局部的平衡了，但是对于祖父节点来说是不符合定义4的。这样就需要回溯到父节点，接着进行修复操作。 删除操作示例3 示例3的删除操作是一个中间步骤，它的目的是将左边的红色节点借调过来，这样就可以转换成示例4状态了，在示例4状态下可以将D，E节点都阶段过来，通过将两个节点变成黑色来保证红黑树的整体平衡。 之所以说case-3是一个中间状态，是因为根据红黑树的定义来说，下图并不是平衡的，他是通过示例2操作完后向上回溯出现的状态。之所以会出现示例3和后面的示例4的情况，是因为可以通过借用侄子节点的红色，变成黑色来符合红黑树定义4. 删除操作示例4 示例4的操作是真正的节点借调操作，通过将兄弟节点以及兄弟节点的右节点借调过来，并将兄弟节点的右子节点变成红色来达到借调两个黑节点的目的，这样的话，整棵树还是符合RBTree的定义的。 示例4这种情况的发生只有在待删除的节点的兄弟节点为黑，且子节点不全部为黑，才有可能借调到两个节点来做黑节点使用，从而保持整棵树都符合红黑树的定义。 删除操作的总结: 红黑树的删除操作是最复杂的操作，复杂的地方就在于当删除了黑色节点的时候，如何从兄弟节点去借调节点，以保证树的颜色符合定义。由于红色的兄弟节点是没法借调出黑节点的，这样只能通过选择操作让他上升到父节点，而由于它是红节点，所以它的子节点就是黑的，可以借调。 对于兄弟节点是黑色节点的可以分成3种情况来处理，当所以的兄弟节点的子节点都是黑色节点时，可以直接将兄弟节点变红，这样局部的红黑树颜色是符合定义的。但是整颗树不一定是符合红黑树定义的，需要往上追溯继续调整。 对于兄弟节点的子节点为左红右黑或者 (全部为红，右红左黑)这两种情况，可以先将前面的情况通过选择转换为后一种情况，在后一种情况下，因为兄弟节点为黑，兄弟节点的右节点为红，可以借调出两个节点出来做黑节点，这样就可以保证删除了黑节点，整棵树还是符合红黑树的定义的，因为黑色节点的个数没有改变。 红黑树的删除操作是遇到删除的节点为红色，或者追溯调整到了root节点，这时删除的修复操作完毕。 RB红黑树的Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584public class RBTreeNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T value;//node value private RBTreeNode&lt;T&gt; left;//left child pointer private RBTreeNode&lt;T&gt; right;//right child pointer private RBTreeNode&lt;T&gt; parent;//parent pointer private boolean red;//color is red or not red public RBTreeNode()&#123;&#125; public RBTreeNode(T value)&#123;this.value=value;&#125; public RBTreeNode(T value,boolean isRed)&#123;this.value=value;this.red = isRed;&#125; public T getValue() &#123; return value; &#125; void setValue(T value) &#123; this.value = value; &#125; RBTreeNode&lt;T&gt; getLeft() &#123; return left; &#125; void setLeft(RBTreeNode&lt;T&gt; left) &#123; this.left = left; &#125; RBTreeNode&lt;T&gt; getRight() &#123; return right; &#125; void setRight(RBTreeNode&lt;T&gt; right) &#123; this.right = right; &#125; RBTreeNode&lt;T&gt; getParent() &#123; return parent; &#125; void setParent(RBTreeNode&lt;T&gt; parent) &#123; this.parent = parent; &#125; boolean isRed() &#123; return red; &#125; boolean isBlack()&#123; return !red; &#125; /** * is leaf node **/ boolean isLeaf()&#123; return left==null &amp;&amp; right==null; &#125; void setRed(boolean red) &#123; this.red = red; &#125; void makeRed()&#123; red=true; &#125; void makeBlack()&#123; red=false; &#125; @Override public String toString()&#123; return value.toString(); &#125;&#125;public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private final RBTreeNode&lt;T&gt; root; //node number private java.util.concurrent.atomic.AtomicLong size = new java.util.concurrent.atomic.AtomicLong(0); //in overwrite mode,all node's value can not has same value //in non-overwrite mode,node can have same value, suggest don't use non-overwrite mode. private volatile boolean overrideMode=true; public RBTree()&#123; this.root = new RBTreeNode&lt;T&gt;(); &#125; public RBTree(boolean overrideMode)&#123; this(); this.overrideMode=overrideMode; &#125; public boolean isOverrideMode() &#123; return overrideMode; &#125; public void setOverrideMode(boolean overrideMode) &#123; this.overrideMode = overrideMode; &#125; /** * number of tree number * @return */ public long getSize() &#123; return size.get(); &#125; /** * get the root node * @return */ private RBTreeNode&lt;T&gt; getRoot()&#123; return root.getLeft(); &#125; /** * add value to a new node,if this value exist in this tree, * if value exist,it will return the exist value.otherwise return null * if override mode is true,if value exist in the tree, * it will override the old value in the tree * * @param value * @return */ public T addNode(T value)&#123; RBTreeNode&lt;T&gt; t = new RBTreeNode&lt;T&gt;(value); return addNode(t); &#125; /** * find the value by give value(include key,key used for search, * other field is not used,@see compare method).if this value not exist return null * @param value * @return */ public T find(T value)&#123; RBTreeNode&lt;T&gt; dataRoot = getRoot(); while(dataRoot!=null)&#123; int cmp = dataRoot.getValue().compareTo(value); if(cmp&lt;0)&#123; dataRoot = dataRoot.getRight(); &#125;else if(cmp&gt;0)&#123; dataRoot = dataRoot.getLeft(); &#125;else&#123; return dataRoot.getValue(); &#125; &#125; return null; &#125; /** * remove the node by give value,if this value not exists in tree return null * @param value include search key * @return the value contain in the removed node */ public T remove(T value)&#123; RBTreeNode&lt;T&gt; dataRoot = getRoot(); RBTreeNode&lt;T&gt; parent = root; while(dataRoot!=null)&#123; int cmp = dataRoot.getValue().compareTo(value); if(cmp&lt;0)&#123; parent = dataRoot; dataRoot = dataRoot.getRight(); &#125;else if(cmp&gt;0)&#123; parent = dataRoot; dataRoot = dataRoot.getLeft(); &#125;else&#123; if(dataRoot.getRight()!=null)&#123; RBTreeNode&lt;T&gt; min = removeMin(dataRoot.getRight()); //x used for fix color balance RBTreeNode&lt;T&gt; x = min.getRight()==null ? min.getParent() : min.getRight(); boolean isParent = min.getRight()==null; min.setLeft(dataRoot.getLeft()); setParent(dataRoot.getLeft(),min); if(parent.getLeft()==dataRoot)&#123; parent.setLeft(min); &#125;else&#123; parent.setRight(min); &#125; setParent(min,parent); boolean curMinIsBlack = min.isBlack(); //inherit dataRoot's color min.setRed(dataRoot.isRed()); if(min!=dataRoot.getRight())&#123; min.setRight(dataRoot.getRight()); setParent(dataRoot.getRight(),min); &#125; //remove a black node,need fix color if(curMinIsBlack)&#123; if(min!=dataRoot.getRight())&#123; fixRemove(x,isParent); &#125;else if(min.getRight()!=null)&#123; fixRemove(min.getRight(),false); &#125;else&#123; fixRemove(min,true); &#125; &#125; &#125;else&#123; setParent(dataRoot.getLeft(),parent); if(parent.getLeft()==dataRoot)&#123; parent.setLeft(dataRoot.getLeft()); &#125;else&#123; parent.setRight(dataRoot.getLeft()); &#125; //current node is black and tree is not empty if(dataRoot.isBlack() &amp;&amp; !(root.getLeft()==null))&#123; RBTreeNode&lt;T&gt; x = dataRoot.getLeft()==null ? parent :dataRoot.getLeft(); boolean isParent = dataRoot.getLeft()==null; fixRemove(x,isParent); &#125; &#125; setParent(dataRoot,null); dataRoot.setLeft(null); dataRoot.setRight(null); if(getRoot()!=null)&#123; getRoot().setRed(false); getRoot().setParent(null); &#125; size.decrementAndGet(); return dataRoot.getValue(); &#125; &#125; return null; &#125; /** * fix remove action * @param node * @param isParent */ private void fixRemove(RBTreeNode&lt;T&gt; node,boolean isParent)&#123; RBTreeNode&lt;T&gt; cur = isParent ? null : node; boolean isRed = isParent ? false : node.isRed(); RBTreeNode&lt;T&gt; parent = isParent ? node : node.getParent(); while(!isRed &amp;&amp; !isRoot(cur))&#123; RBTreeNode&lt;T&gt; sibling = getSibling(cur,parent); //sibling is not null,due to before remove tree color is balance //if cur is a left node boolean isLeft = parent.getRight()==sibling; if(sibling.isRed() &amp;&amp; !isLeft)&#123;//示例1 //cur in right parent.makeRed(); sibling.makeBlack(); rotateRight(parent); &#125;else if(sibling.isRed() &amp;&amp; isLeft)&#123; //cur in left parent.makeRed(); sibling.makeBlack(); rotateLeft(parent); &#125;else if(isBlack(sibling.getLeft()) &amp;&amp; isBlack(sibling.getRight()))&#123;//示例2 sibling.makeRed(); cur = parent; isRed = cur.isRed(); parent=parent.getParent(); &#125;else if(isLeft &amp;&amp; !isBlack(sibling.getLeft()) &amp;&amp; isBlack(sibling.getRight()))&#123;//示例3 sibling.makeRed(); sibling.getLeft().makeBlack(); rotateRight(sibling); &#125;else if(!isLeft &amp;&amp; !isBlack(sibling.getRight()) &amp;&amp; isBlack(sibling.getLeft()) )&#123; sibling.makeRed(); sibling.getRight().makeBlack(); rotateLeft(sibling); &#125;else if(isLeft &amp;&amp; !isBlack(sibling.getRight()))&#123;//示例4 sibling.setRed(parent.isRed()); parent.makeBlack(); sibling.getRight().makeBlack(); rotateLeft(parent); cur=getRoot(); &#125;else if(!isLeft &amp;&amp; !isBlack(sibling.getLeft()))&#123; sibling.setRed(parent.isRed()); parent.makeBlack(); sibling.getLeft().makeBlack(); rotateRight(parent); cur=getRoot(); &#125; &#125; if(isRed)&#123; cur.makeBlack(); &#125; if(getRoot()!=null)&#123; getRoot().setRed(false); getRoot().setParent(null); &#125; &#125; //get sibling node private RBTreeNode&lt;T&gt; getSibling(RBTreeNode&lt;T&gt; node,RBTreeNode&lt;T&gt; parent)&#123; parent = node==null ? parent : node.getParent(); if(node==null)&#123; return parent.getLeft()==null ? parent.getRight() : parent.getLeft(); &#125; if(node==parent.getLeft())&#123; return parent.getRight(); &#125;else&#123; return parent.getLeft(); &#125; &#125; private boolean isBlack(RBTreeNode&lt;T&gt; node)&#123; return node==null || node.isBlack(); &#125; private boolean isRoot(RBTreeNode&lt;T&gt; node)&#123; return root.getLeft() == node &amp;&amp; node.getParent()==null; &#125; /** * find the successor node * @param node current node's right node * @return */ private RBTreeNode&lt;T&gt; removeMin(RBTreeNode&lt;T&gt; node)&#123; //find the min node RBTreeNode&lt;T&gt; parent = node; while(node!=null &amp;&amp; node.getLeft()!=null)&#123; parent = node; node = node.getLeft(); &#125; //remove min node if(parent==node)&#123; return node; &#125; parent.setLeft(node.getRight()); setParent(node.getRight(),parent); //don't remove right pointer,it is used for fixed color balance //node.setRight(null); return node; &#125; private T addNode(RBTreeNode&lt;T&gt; node)&#123; node.setLeft(null); node.setRight(null); node.setRed(true); setParent(node,null); if(root.getLeft()==null)&#123; root.setLeft(node); //root node is black node.setRed(false); size.incrementAndGet(); &#125;else&#123; RBTreeNode&lt;T&gt; x = findParentNode(node); int cmp = x.getValue().compareTo(node.getValue()); if(this.overrideMode &amp;&amp; cmp==0)&#123; T v = x.getValue(); x.setValue(node.getValue()); return v; &#125;else if(cmp==0)&#123; //value exists,ignore this node return x.getValue(); &#125; setParent(node,x); if(cmp&gt;0)&#123; x.setLeft(node); &#125;else&#123; x.setRight(node); &#125; fixInsert(node); size.incrementAndGet(); &#125; return null; &#125; /** * find the parent node to hold node x,if parent value equals x.value return parent. * @param x * @return */ private RBTreeNode&lt;T&gt; findParentNode(RBTreeNode&lt;T&gt; x)&#123; RBTreeNode&lt;T&gt; dataRoot = getRoot(); RBTreeNode&lt;T&gt; child = dataRoot; while(child!=null)&#123; int cmp = child.getValue().compareTo(x.getValue()); if(cmp==0)&#123; return child; &#125; if(cmp&gt;0)&#123; dataRoot = child; child = child.getLeft(); &#125;else if(cmp&lt;0)&#123; dataRoot = child; child = child.getRight(); &#125; &#125; return dataRoot; &#125; /** * red black tree insert fix. * @param x */ private void fixInsert(RBTreeNode&lt;T&gt; x)&#123; RBTreeNode&lt;T&gt; parent = x.getParent(); while(parent!=null &amp;&amp; parent.isRed())&#123; RBTreeNode&lt;T&gt; uncle = getUncle(x); if(uncle==null)&#123;//need to rotate RBTreeNode&lt;T&gt; ancestor = parent.getParent(); //ancestor is not null due to before before add,tree color is balance if(parent == ancestor.getLeft())&#123; boolean isRight = x == parent.getRight(); if(isRight)&#123; rotateLeft(parent); &#125; rotateRight(ancestor); if(isRight)&#123; x.setRed(false); parent=null;//end loop &#125;else&#123; parent.setRed(false); &#125; ancestor.setRed(true); &#125;else&#123; boolean isLeft = x == parent.getLeft(); if(isLeft)&#123; rotateRight(parent); &#125; rotateLeft(ancestor); if(isLeft)&#123; x.setRed(false); parent=null;//end loop &#125;else&#123; parent.setRed(false); &#125; ancestor.setRed(true); &#125; &#125;else&#123;//uncle is red parent.setRed(false); uncle.setRed(false); parent.getParent().setRed(true); x=parent.getParent(); parent = x.getParent(); &#125; &#125; getRoot().makeBlack(); getRoot().setParent(null); &#125; /** * get uncle node * @param node * @return */ private RBTreeNode&lt;T&gt; getUncle(RBTreeNode&lt;T&gt; node)&#123; RBTreeNode&lt;T&gt; parent = node.getParent(); RBTreeNode&lt;T&gt; ancestor = parent.getParent(); if(ancestor==null)&#123; return null; &#125; if(parent == ancestor.getLeft())&#123; return ancestor.getRight(); &#125;else&#123; return ancestor.getLeft(); &#125; &#125; private void rotateLeft(RBTreeNode&lt;T&gt; node)&#123; RBTreeNode&lt;T&gt; right = node.getRight(); if(right==null)&#123; throw new java.lang.IllegalStateException(\"right node is null\"); &#125; RBTreeNode&lt;T&gt; parent = node.getParent(); node.setRight(right.getLeft()); setParent(right.getLeft(),node); right.setLeft(node); setParent(node,right); if(parent==null)&#123;//node pointer to root //right raise to root node root.setLeft(right); setParent(right,null); &#125;else&#123; if(parent.getLeft()==node)&#123; parent.setLeft(right); &#125;else&#123; parent.setRight(right); &#125; //right.setParent(parent); setParent(right,parent); &#125; &#125; private void rotateRight(RBTreeNode&lt;T&gt; node)&#123; RBTreeNode&lt;T&gt; left = node.getLeft(); if(left==null)&#123; throw new java.lang.IllegalStateException(\"left node is null\"); &#125; RBTreeNode&lt;T&gt; parent = node.getParent(); node.setLeft(left.getRight()); setParent(left.getRight(),node); left.setRight(node); setParent(node,left); if(parent==null)&#123; root.setLeft(left); setParent(left,null); &#125;else&#123; if(parent.getLeft()==node)&#123; parent.setLeft(left); &#125;else&#123; parent.setRight(left); &#125; setParent(left,parent); &#125; &#125; private void setParent(RBTreeNode&lt;T&gt; node,RBTreeNode&lt;T&gt; parent)&#123; if(node!=null)&#123; node.setParent(parent); if(parent==root)&#123; node.setParent(null); &#125; &#125; &#125; /** * debug method,it used print the given node and its children nodes, * every layer output in one line * @param root */ public void printTree(RBTreeNode&lt;T&gt; root)&#123; java.util.LinkedList&lt;RBTreeNode&lt;T&gt;&gt; queue =new java.util.LinkedList&lt;RBTreeNode&lt;T&gt;&gt;(); java.util.LinkedList&lt;RBTreeNode&lt;T&gt;&gt; queue2 =new java.util.LinkedList&lt;RBTreeNode&lt;T&gt;&gt;(); if(root==null)&#123; return ; &#125; queue.add(root); boolean firstQueue = true; while(!queue.isEmpty() || !queue2.isEmpty())&#123; java.util.LinkedList&lt;RBTreeNode&lt;T&gt;&gt; q = firstQueue ? queue : queue2; RBTreeNode&lt;T&gt; n = q.poll(); if(n!=null)&#123; String pos = n.getParent()==null ? \"\" : ( n == n.getParent().getLeft() ? \" LE\" : \" RI\"); String pstr = n.getParent()==null ? \"\" : n.getParent().toString(); String cstr = n.isRed()?\"R\":\"B\"; cstr = n.getParent()==null ? cstr : cstr+\" \"; System.out.print(n+\"(\"+(cstr)+pstr+(pos)+\")\"+\"\\t\"); if(n.getLeft()!=null)&#123; (firstQueue ? queue2 : queue).add(n.getLeft()); &#125; if(n.getRight()!=null)&#123; (firstQueue ? queue2 : queue).add(n.getRight()); &#125; &#125;else&#123; System.out.println(); firstQueue = !firstQueue; &#125; &#125; &#125; public static void main(String[] args) &#123; RBTree&lt;String&gt; bst = new RBTree&lt;String&gt;(); bst.addNode(\"d\"); bst.addNode(\"d\"); bst.addNode(\"c\"); bst.addNode(\"c\"); bst.addNode(\"b\"); bst.addNode(\"f\"); bst.addNode(\"a\"); bst.addNode(\"e\"); bst.addNode(\"g\"); bst.addNode(\"h\"); bst.remove(\"c\"); bst.printTree(bst.getRoot()); &#125;&#125; 代码调试的时候，printTree输出格式如下: 12345d(B)b(B d LE) g(R d RI)a(R b LE) e(B g LE) h(B g RI)f(R e RI) 括号左边表示元素的内容。括号内的第一个元素表示颜色，B表示black，R表示red；第二个元素表示父元素的值；第三个元素表示左右，LE表示在父元素的左边。RI表示在父元素的右边。 第一个元素d是root节点，由于它没有父节点，所以括号内只有一个元素。 总结作为平衡二叉查找树里面众多的实现之一，红黑树无疑是最简洁、实现最为简单的。红黑树通过引入颜色的概念，通过颜色这个约束条件的使用来保持树的高度平衡。作为平衡二叉查找树，旋转是一个必不可少的操作。通过旋转可以降低树的高度，在红黑树里面还可以转换颜色。 红黑树里面的插入和删除的操作比较难理解，这时要注意记住一点：操作之前红黑树是平衡的，颜色是符合定义的。在操作的时候就需要向兄弟节点、父节点、侄子节点借调和互换颜色，要达到这个目的，就需要不断的进行旋转。所以红黑树的插入删除操作需要不停的旋转，一旦借调了别的节点，删除和插入的节点就会达到局部的平衡（局部符合红黑树的定义），但是被借调的节点就不会平衡了，这时就需要以被借调的节点为起点继续进行调整，直到整棵树都是平衡的。在整个修复的过程中，插入具体的分为3种情况，删除分为4种情况。 整个红黑树的查找，插入和删除都是O(logN)的，原因就是整个红黑树的高度是logN，查找从根到叶，走过的路径是树的高度，删除和插入操作是从叶到根的，所以经过的路径都是logN。 参考文献 Cormen T H, Leiserson C E, Rivest R L, 等. 算法导论（第3版）. 殷建平, 等. 机械工业出版社, 2012. Sedgewick R, Wayne K. 算法（第4版）. 谢路云 译. 人民邮电出版社, 2012. Weiss M A. 数据结构与算法分析（第2版）. 冯舜玺 译. 机械工业出版社, 2004. Knuth D E. 计算机程序设计艺术 卷3：排序与查找（英文版 第2版）. 人民邮电出版社, 2010. 二叉查找树百度百科 RB红黑树百度百科","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://ltyeamin.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://ltyeamin.github.io/tags/二叉树/"}]},{"title":"谈谈国内大环境下的996加班文化","slug":"谈谈国内大环境下的996加班文化","date":"2019-03-28T04:57:10.000Z","updated":"2019-11-20T15:09:01.274Z","comments":true,"path":"2019/03/28/谈谈国内大环境下的996加班文化/","link":"","permalink":"http://ltyeamin.github.io/2019/03/28/谈谈国内大环境下的996加班文化/","excerpt":"","text":"LZ每天都要打开开源中国网站看看互联网百态，在今天的网站里，看到了两件有意思的趣事: 抵制996加班文化996.icu，大家在996I.ICU GitHub畅谈自由、吐槽加班 某程序员删库跑路制作的网站-安徽汽车网是由简单的图片显示拼接而成的。 996加班文化无论是传统行业，还是互联网行业，现在公司加班情况可以说得是司空见惯了。尤其是在互联网行业能更加体现出来，比如华为、京东最为常见。加班文化已经成为了普遍现象，劳动法规定在必要的情况下，公司可以适当安排一下加班，员工需配合，公司承诺并给更好的福利待遇。 在大公司里，工作强度大很正常，员工早已习以为常，不仅仅愿意接受加班，而且加班加的一身热血。我想接受的原因是各种福利待遇的诱惑。但是中小型公司里不见得是这样子的，如果普通公司都和华为、京东这样大型公司待遇一样的话，大家肯定对加班的积极性很强。 我曾经入职的一家公司也存在的996加班文化，当时公司业务正处于高速发展期，整个技术部门经常加班，当时福利待遇是按时支付加班费来兑现的，工作日晚上7点算加班，加班费按加班小时乘以1倍再乘以平均日薪去算，周末以及法定节日加班费按加班小时乘以1.5倍再乘以平均日薪，凡是加班超过3个小时的，有餐补，超过4个小时的，有餐补车补。 我上学期间曾经看过马克思主义哲学，马克思主义认为任何事物都是作为矛盾统一体而存在的，矛盾是事物发展的源泉和动力。简言之，矛盾就是对立统一，任何事情都有两面性。接下来我站在不同的客观角度来分析一下上述加班文化: 站在员工的角度 我们不可否认加班确实能提高工作效率，公司需要我们加班，我们绝不推辞，因为有了福利待遇的保证。 只要有福利待遇，大家都很愿意加班，如果没有福利，大家几乎是没有意向主动加班，除非有非常紧急的任务才勉强接受加班。如果没有福利待遇，作为员工宁愿提高工作效率，也不愿意在公司进行无偿加班。但是，话有说回来，如果有福利待遇，不见得能够提高工作效率。 站在公司的角度 从公司的角度上来讲，加班可以让人力资源合理分配，使得公司大步向前迈。但是客观来讲，一般公司大肆宣扬加班文化，有可能公司出现健康状况，这个是由加班效率高低来决定的，加班不一定提高效率。这就和中国50年代大跃进赶英超美思想一样，冒进思想，并没有立足现实。 这个让我想我的一个同事，他平时几乎也不怎么加班，只有紧急任务的时候才会选择加班。有一次他的Leader问：大家都在加班，为什么你不加班？它的回答Leader大吃一惊，他说他当天的任务已经完成，只要按照预期时间完成就好。如果公司技术氛围和BAT大型互联网公司一个级别的，我更愿意无偿加到11点。如果没有技术氛围，加班对自身来讲没有什么技术收获和能力提升。平时只需要保证正常的任务按点完成即可。他的Leader听到后也无语了，瞬间认为他不合群。 我觉得任何老板和Leader都没有强制要求加班的权利。我那个同事住的地方和公司很远，日常上下班坐地铁要1个小时四十分钟，即便晚上6点整下班，回去都快8点了。我问他为什么不给Leader反应这个问题，让Leader体谅一下。他说不用，他发现并不是他不合群，而是不习惯那种公司氛围，老板要产出要加班，加班没待遇，领导也是听老板的吩咐，就要求加班，于是效果很明显，大家都是白天干其他事情，晚上干活，如果是我的话，我也受不了，毕竟我们正年轻。后来我同事离职了，换了一家只有20人的天使轮创业型公司，他给我说虽然很累，但是每天很充实，对未来有了更好的希望。 听到我这个同事的情况，我的总结是：作为员工，尽量提高白天的工作效率，把自己的工作做好，自己做的东西尽量不要出大问题。如果真的有需要加班的，听从Leader的安排，如果有福利待遇的保证，多为公司产出，如果没有待遇，适当即可，毕竟自己的福利待遇也是有必要的。 大公司我就不说了，中小型公司我建议抵制996、985不良的加班文化，而提倡724的加班文化，这里的724并不是公司让员工每周工作7天，每日工作24小时。而是无论什么日子，如果有紧急任务，7天中，五天在公司正常上班，有必要加班可以在家完成工作，福利待遇保证，这样做一个协调，避免可能1个小时解决的问题，非要赶往公司造成多个小时加班，解决了效率低的问题，在家加班相信大部分程序员会不计较那一个小时的时间，如果加班时间较长，公司给予相应的福利待遇，即节省了员工返公司的时间，也解决了实际性问题。在这里，有些人可能质疑，因为在家具体是否做事，公司并不知情，但是这种情况，是永远无法避免的，因为这是程序员的职业操作，是一个人的基本素养问题。如果人都是这样自私自利、缺乏责任心，也就没有团队，更没有朋友，我相信这种人的人生不会走的更远。 程序员的抱怨大家经常听到一句话就是：干的不爽，删库跑路。每天全国的互联网公司都可能发生这样的事情，某程序员因和公司产生利益纠纷锁服务器、删库、删代码、故意挖坑。 出现这样的情况已经司空见惯了。我作为互联网行业的一份子，站在我的角度分析，每个程序员都应该有良好的职业操守，如果真出现利益纠纷，我们可以用合法的方式去解决，用法律方式去维权，和平解决，尽可能不要起任何冲突。说到这里有些时候靠法律确实没办法占据有利地位，毕竟单人不可能玩过公司的。我们只能从入职的那一天开始，什么的福利待遇都写在合同里，这才算数。如果因为其他原因的话，大可不必为之恼怒，因为物以类聚、人以群分，主动离职便是。 创业公司好多老板都在给员工画饼，这种洗脑式的画饼员工们还是斟酌斟酌。对老板说的话，去其糟粕，取其精华。只听对自己有益的话，之所以老板能开一个公司，肯定是在某方面有一定的过人之处。 写在最后的网络段子 2019年3月27日，996.icu项目上线，第二天，项目达到3w个star，就在当日，安徽汽车网的兄弟第一个揭竿起义，删库跑路，史称3.28事件，同年五月工程师们成立反加班工会。 2020年两会期间，迫于社会和反加班工会压力，国家将禁止加班写入宪法。","categories":[{"name":"others","slug":"others","permalink":"http://ltyeamin.github.io/categories/others/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://ltyeamin.github.io/tags/杂谈/"}]},{"title":"视频下载神器之you-get","slug":"视频下载神器之you-get","date":"2019-03-27T05:00:50.000Z","updated":"2019-11-20T15:08:51.075Z","comments":true,"path":"2019/03/27/视频下载神器之you-get/","link":"","permalink":"http://ltyeamin.github.io/2019/03/27/视频下载神器之you-get/","excerpt":"","text":"我们日常上网过程中，需要将网页中的视频资源提取下载出来，一般如果网站没有屏蔽视频地址且用的是非Flash播放器(现流行HTML5播放器),我们可以在视频播放器右键直接下载视频资源，但是国内网站运营商为了保护版权，会将真正的资源地址屏蔽起来，我们无法找到真实地址并进行下载。因此出现了好多第三方的应用来帮助我们提取网页中的视频，常见的提取软件有Chrome插件Video download helper和Video Downloader GetThemAll、国内以前很著名的硕鼠和维棠视频下载(这两个LZ之前经常用，硕鼠经常用于下载51CTO的教学视频，维棠经常用于电视剧批量下载)。 今天我给大家带来一款视频下载神器you-get，you-get 乃一小小哒命令行程序，提供便利的方式来下载网络上的媒体信息。好了，话不多说，接下来让我们开始体验一下吧。 为什么你要好好的用 你欢喜于互联网上的富媒体内容，并为个人寻欢而储存 你喜悦观看的视频，然而不得保存；对个人设备无从控制，此乃违背开放互联网之行为 你寻求解脱于闭源软件或JavaScript代码，并禁止Flash运行 你为黑客精神与自由软件而欣喜 功能特性 下载流行网站之音视频，例如YouTube, Youku, Niconico,以及更多. (查看完整支持列表) 于您心仪的媒体播放器中观看在线视频，脱离浏览器与广告 下载您喜欢的网页上的图片 下载任何非HTML内容，例如二进制文件 安装方式Mac安装 在Mac上安装Homebrew，Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能，功能类似于Linux平台上的apt-get或yum操作。进入Mac终端输入一下命令即可安装Homebrew; 1/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 安装完成Homebrew后，我们来安装you-get工具，输入一下命令即可安装完成; 1Yeamin:Hexo mac$ brew install you-get 安装完成后，我们检查版本来确认是否安装成功。 12Yeamin:Hexo mac$ you-get -Vyou-get: version 0.4.1205, a tiny downloader that scrapes the web. Linux安装 安装Python3； 使用pip来安装 1$ pip3 install you-get Windows安装 下载Windows预装包即可； 安装并执行可运行程序。 Git安装即使您不常使用Python，作为开发者，也请使用此方法。 下载安装资源，如下命令; 1$ git clone git://github.com/soimort/you-get.git 将目录加入 PATH, 或运行 make install 以安装you-get于永久路径。 使用体验以最近热播的电视剧《都挺好》为例，操作如下： 查询视频信息可以使用 --info/-i 以查看所有可用画质与格式 1you-get -i 'https://v.youku.com/v_show/id_XNDA3OTMzMTE4MA==.html?spm=a2h1n.8261147.reload_1.1~3~A&amp;s=4e4e42efbfbdefbfbd62' 执行上述命令后，观察执行结果我们可以观察出电视剧《都挺好》第1集的片源来自优酷，画质有超清、高清、渣清、标清，视频格式都为mp4，视频文件大小以及相关地址链接。 下载视频1you-get 'https://v.youku.com/v_show/id_XNDA3OTMzMTE4MA==.html?spm=a2h1n.8261147.reload_1.1~3~A&amp;s=4e4e42efbfbdefbfbd62' 输入上述命令后，即可开始下载，默认画质为超清画质，视频会分段下载，下载完成之后，you-get自动调用ffmpeg将多段视频进行合并操作。 加载Cookies在这个下载的过程中，我们发现一个问题，比如下载下来的视频大小与显示的大小不符合，我们下下来只有80M左右，视频时间为10分钟左右。 为什么会这样呢？LZ查好好阅读了一下WIKI，原因是网站视频只公开一部分视频片段，并非所有视频可供任何人观看。如果需要登录以观看 (例如, 私密视频), 可能必须将浏览器cookie通过--cookies/-c 加载入 you-get。需要我们登录的Cookies信息，我们登录后将打开F12查看Cookie信息，一查看，一大堆Cookie，怎么整，于是LZ又找到一个Chrome浏览器的插件，自动生成Cookies，如图，可以将红色区域拷贝到Cookies.txt中，然后继续执行下载操作。 注意: 目前我们支持两种cookie格式：Mozilla cookies.sqlite 和 Netscape cookies.txt. 1you-get -c Cookies.txt https://v.youku.com/v_show/id_XNDA3OTMzMTE4MA==.html 本地播放器播放如果你只是在用自己本地播放器进行观看的话使用而不是下载的话，则可以 --player/-p 将视频喂进播放器, 例如 mplayer或者 vlc。 1$ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 或者你想在浏览器中观看而不希望看广告或评论区: 1$ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 支持主流网站列表 网站 URL 视频? 图像? 音频? YouTube https://www.youtube.com/ ✓ Twitter https://twitter.com/ ✓ ✓ VK http://vk.com/ ✓ Vine https://vine.co/ ✓ Vimeo https://vimeo.com/ ✓ Vidto http://vidto.me/ ✓ Veoh http://www.veoh.com/ ✓ Tumblr https://www.tumblr.com/ ✓ ✓ ✓ TED http://www.ted.com/ ✓ SoundCloud https://soundcloud.com/ ✓ Pinterest https://www.pinterest.com/ ✓ MusicPlayOn http://en.musicplayon.com/ ✓ MTV81 http://www.mtv81.com/ ✓ Mixcloud https://www.mixcloud.com/ ✓ Metacafe http://www.metacafe.com/ ✓ Magisto http://www.magisto.com/ ✓ Khan Academy https://www.khanacademy.org/ ✓ JPopsuki TV http://www.jpopsuki.tv/ ✓ Internet Archive https://archive.org/ ✓ Instagram https://instagram.com/ ✓ ✓ Heavy Music Archive http://www.heavy-music.ru/ ✓ Google+ https://plus.google.com/ ✓ ✓ Freesound http://www.freesound.org/ ✓ Flickr https://www.flickr.com/ ✓ ✓ Facebook https://www.facebook.com/ ✓ eHow http://www.ehow.com/ ✓ Dailymotion http://www.dailymotion.com/ ✓ CBS http://www.cbs.com/ ✓ Bandcamp http://bandcamp.com/ ✓ AliveThai http://alive.in.th/ ✓ interest.me http://ch.interest.me/tvn ✓ 755ナナゴーゴー http://7gogo.jp/ ✓ ✓ niconicoニコニコ動画 http://www.nicovideo.jp/ ✓ 163网易视频网易云音乐 http://v.163.com/ http://music.163.com/ ✓ ✓ 56网 http://www.56.com/ ✓ AcFun http://www.acfun.tv/ ✓ Baidu百度贴吧 http://tieba.baidu.com/ ✓ ✓ 爆米花网 http://www.baomihua.com/ ✓ bilibili哔哩哔哩 http://www.bilibili.com/ ✓ Dilidili http://www.dilidili.com/ ✓ 豆瓣 http://www.douban.com/ ✓ 斗鱼 http://www.douyutv.com/ ✓ 凤凰视频 http://v.ifeng.com/ ✓ 风行网 http://www.fun.tv/ ✓ iQIYI 爱奇艺 http://www.iqiyi.com/ ✓ 激动网 http://www.joy.cn/ ✓ 酷6网 http://www.ku6.com/ ✓ 酷狗音乐 http://www.kugou.com/ ✓ 酷我音乐 http://www.kuwo.cn/ ✓ 乐视网 http://www.letv.com/ ✓ 荔枝FM http://www.lizhi.fm/ ✓ 秒拍 http://www.miaopai.com/ ✓ MioMio弹幕网 http://www.miomio.tv/ ✓ 痞客邦 https://www.pixnet.net/ ✓ PPTV聚力 http://www.pptv.com/ ✓ 齐鲁网 http://v.iqilu.com/ ✓ QQ 腾讯视频 http://v.qq.com/ ✓ 阡陌视频 http://qianmo.com/ ✓ Sina 新浪视频 微博秒拍视频 http://video.sina.com.cn/ http://video.weibo.com/ ✓ Sohu 搜狐视频 http://tv.sohu.com/ ✓ 天天动听 http://www.dongting.com/ ✓ Tudou土豆 http://www.tudou.com/ ✓ 虾米 http://www.xiami.com/ ✓ 阳光卫视 http://www.isuntv.com/ ✓ 音悦Tai http://www.yinyuetai.com/ ✓ Youku优酷 http://www.youku.com/ ✓ 战旗TV http://www.zhanqi.tv/lives ✓ 央视网 http://www.cntv.cn/ ✓ 其他类似工具 youtube-dl：youtube-dl功能和you-get类似。 Video Download Manager：可视化工具，相当于youtube-dl+you-get。 ykdl：专注于优酷视频。 annie：专注于在线视频下载的轻量级命令行工具 维棠:维棠最专业flv视频下载软件 硕鼠：硕鼠最稳定的FLV视频下载平台 无水印预览 参考资料you-get中文文档 you-get源码","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"GC调优基础之堆大小","slug":"GC调优基础之堆大小","date":"2019-01-05T11:11:09.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2019/01/05/GC调优基础之堆大小/","link":"","permalink":"http://ltyeamin.github.io/2019/01/05/GC调优基础之堆大小/","excerpt":"","text":"调整堆大小GC调整的第一堂课是调整应用程序堆的大小。关于堆大小的调整还有更高级的话题，不过作为第一步，我们首先讨论如何设置总体堆的大小。 与其他的性能问题一样，选择堆的大小其实是一种平衡。如果分配的堆过于小，程序的大部分时间可能都消耗在GC上，没有足够的时间去运行应用程序的逻辑。但是，简单粗暴地设置一个特别大的堆也不是解决问题的方法。 GC停顿消耗的时间取决于堆的大小，如果增大堆的空间，停顿的持续时间也会变长。这种情况下，停顿的频率会变得更少，但是它们持续的世界会让程序的整体性能变慢。 使用超大堆还有另一个风险。操作系统使用虚拟内存机制管理机器的物理内存。一台机器可能有8G的物理内存，不过操作系统可能让你感觉有更多的可用内存。虚拟内存的数量取决于操作系统的设置，譬如操作系统可能让你感觉到它的内存达到了16G。操作系统名为”交换”(swapping，称之为分页，虽然这两者在技术上存在着差异，但是这些差异，在这里不影响我们的讨论)。你可以载入需要16GG内存的应用程序，操作系统在需要时会将程序运行时不活跃的数据由内存复制到磁盘。再次需这部分内存的内容时，操作系统再将它们由磁盘重新载入到内存(为了腾出空间，通常它会先将另一部分内存的内容复制到磁盘)。 系统中运行着大量不同的应用程序时，这个流程工作得很不顺畅，因为大多数的应用程序不会同时处于活跃状态。但是，对于Java应用，它工作得并不是很好。如果一个Java应用使用了这个系统上大约12G的堆，操作系统可能在RAM上分配8G的堆空间，另外4G的空间存在于磁盘(这个假设对实际情况进行了一些简化，因为应用程序也会使用部分的RAM)。JVM不会了解这些：操作系统完全屏蔽了内存交互的细节。这样，JVM愉快的地填满了分配给它的12G堆空间。但这样就导致了严重的性能问题，因为操作系统需要将相当一部分的数据由磁盘交换到内存(这是一个昂贵操作的开始)。 更糟糕的是，这种原本期望一次性的内存交换操作在Full GC时一定会再次重演，因为JVM必须访问整个堆的内容。如果Full GC时系统发生内存交换，停顿时间会以正常停顿时间数个量级的方式增长。类似的，如果使用Concurrent收集器，后台线程在回收堆时，它的速度也可能会被拖慢，因为需要等待从裁判复制数据到内存，结果导致发生代价昂贵的并发模式失效。 因此，调整堆大小时首要的原则就是永远不要将堆的容量设置得比机器的物理内存还大。另外，如果同一台机器上运行着多个JVM实例，这个原则适用于所有堆的总和。除此之外，你还需要为JVM自身以及机器上其他的应用程序预留一部分的内存空间：通常情况下，对于普通的操作系统，应该预留至少1G的内存空间。 堆的大小由2个参数值控制：分别是初始值(通过-Xms N设置)和最大值(通过 -Xmx N设置)。默认值的调节取决于多个因素，包括操作系统类型、系统内存大小、使用的JVM。其他的命令标志也会对该值造成影响，堆大小的调节是JVm自适应调优的核心。 JVM的目标是一句系统可用的资源情况找到一个”合理的”默认初始化值，当且仅当应用程序需要更多的内存(依据垃圾回收时消耗的时间来决定)时将堆的大小增大到一个合理的最大值。到目前为止，JVM的高级调优标志以及调优细节都没有提及。为了让大家有个感性的认识，我们列出了堆大小的默认最大值和最小值供大家参考，参见如下表。(为了使内存对齐，JVM会对这些值进行圆整操作；所以GC日志中输出的大小可能与表中给出的值并不完全一致)。 操作系统及JVM类型 初始堆大小(Xms) 最大堆大小(Xmx) Linux/Solaris,32位客户端 16MB 256MB Linux/Solaris,32位客户端 64MB 取1GB和物理内存大小1/4二者中的最小值 Linux/Solaris,32位客户端 取512MB和物理内存大小1/64二者中的最小值 取32GB和物理内存大小1/4二者中的最小值 MacOS，64位服务器型JVM 64MB(数据有误,应该是256MB) 取1GB和物理内存大小1/4二者中的最小值 Windows，32位客户端JVM 16MB 256MB Windows，64位服务端JVM 64MB 取1GB和物理内存大小1/4二者中的最小值 如果机器的物理内存少于192MB，最大堆的大小会是物理内存的一半(大约96MB，或更少)。 堆大小具有初始值和最大值的这种设计让JVM能够根据实际的负荷情况更灵活地调整JVM的行为。如果JVM发现使用初始的堆大小，频繁地发生GC，它就会尝试增大堆的空间，直到JVM的GC的频率回归到正常的范围，或直到堆大小增大到它的上限值。 对很多应用来说，这意味着堆的大小不再需要调整了，实际上，你只需要为你选择的GC算法设定性能目标：譬如你能忍受的停顿的持续时间、你期望垃圾回收在整个时间中所占用的百分比等。 如果应用程序在GC时消耗了太长的时间，你很有可能需要使用-Xmx标志增大堆的大小。选择什么样的大小没有一个硬性的或简单的规则。一个经验法则是完成Full GC后，应该释放出70%的空间(30%的空间仍然占用)。 注意，即使你显示地设置了堆的最大容量，还是会发生堆的自动调节：初始时堆以默认的大小开始运行，为了达到根据垃圾收集算法设置的性能目标，JVM会逐步增大堆的大小。将堆的大小设置得比实际需要更大不一定会带来性能损耗：堆并不会无限地增大，JVM会调节堆的大小直到其满足GC的性能目标。 另一方面，如果你确切地了解应用程序需要多大的堆，那么你可以将堆的初始化和最大值设置一致数值(譬如：-Xms1024M -Xmx1024M)。这种设置能稍微提高GC的运行效率，因为它不再需要估算堆是否需要调整大小。 堆内存纠错在上述表我们知道了不同操作系统、不同JVM、不同物理内存的默认堆大小。但是实际上，Mac OS这个数据有问题的。我的Mac Pro 2013的配置物理内存是16G、64位的JVM。 下面两个命令用于查看当前JRE默认的堆大小，该方法适用于Java 6u20以及之后版本。 1234567891011121314151617181920# 使用-serverYeamin:~ mac$ java -server -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal -version | grep -i heapsize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 268435456 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 4294967296 &#123;product&#125;java version \"1.8.0_192\"Java(TM) SE Runtime Environment (build 1.8.0_192-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode)# 使用-clientYeamin:~ mac$ java -client -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal -version | grep -i heapsize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 268435456 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 4294967296 &#123;product&#125;java version \"1.8.0_192\"Java(TM) SE Runtime Environment (build 1.8.0_192-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode) 查看结果，我们发现，Mac OS中client和server模式的初始化堆大小是268435456(即268435456/1024/1024=256M=物理内存16G \\ 1024 \\ 1/64)。我们发现实际上这个表中数据是有误的。 其实不仅仅是Mac OS，Windows 64位也是这样的。 总结 堆分配过小，程序大部分时间消耗在GC上。堆分配过大，GC停顿时间加长，停顿频率减少，使得程序性能整天下降。 JVM不像是物理内存一样可以使用交互/分页技术。计算机是物理内存和虚拟内存结合使用，程序中运行不活跃的数据复制到虚拟内存(磁盘)，而JVM完全没有这种内存交换细节，分配多少G就是多少G。 不同操作系统、不同大小物理内存、不同JVM的默认堆大小有所差异。但是我们常用的都是64位的JVM，常用的初始化堆大小是物理内存的1/64,常用的最大堆大小为物理内存的1/4。 堆的初始化大小和最大堆大小由-Xms:N和-Xmx:N两个参数来控制。其中N表示存储大小，默认为MB为基本单位。 每次GC的时候会动态调整堆的大小。若默认空余堆内存小于40%时，JVM会动态将堆内存增大到-Xmx最大限制。若默认空余堆内存小于40%时，JVM会动态将堆内存减少到-Xms最小限制。因此我们一般设置-Xms和-Xmx相等，避免在每次GC后调整堆的大小。 除非应用程序需要比默认值更大的堆，否则在进行调优时，尽量考虑通过GC算法的性能目标，而非微调堆的大小来改善程序性能。 参考文献 《Java性能权威指南》","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"局域网文件共享与下载服务新姿势","slug":"局域网文件共享与下载服务新姿势","date":"2018-06-18T13:22:13.000Z","updated":"2019-11-20T15:08:51.556Z","comments":true,"path":"2018/06/18/局域网文件共享与下载服务新姿势/","link":"","permalink":"http://ltyeamin.github.io/2018/06/18/局域网文件共享与下载服务新姿势/","excerpt":"","text":"在平常生活或工作中，我们经常需要传输文件，比如将电脑上下载的App传送到手机或另一台PC上、同事之间传输一些大型的文件。当我们遇到此类问题时，首先想到的就是使用QQ或者微信，更深一层，去网上搜索一些文件传输工具，如Send Anywhere，LZ当时在大学时候经常使用的是FTP、Samba服务。但是这些第三方要么都显得太麻烦（如下图），要么就是不安全，安全隐患主要在数据传输安全以及数据备份上体现，我们都需要将文件传输到第三方服务器上，再通过需要接收数据的电脑或手机进行下载。 那么，有没有办法直接获取文件，而不通过这些繁琐的操作？在这里呢，LZ给大家推荐几种常见的文件共享方法。 文件共享下载新姿势最方便的Windows文件共享LZ本人一年多没用过Windows电脑了,现在公司配置的是Mac Pro，家用的Lenovo Y430P已被改装为Deepin Linux,由于现在日常生活、工作都是在非Windows操作,所以这里就不演示了，等有机会会把详细教程列到这里。 Windows文件共享 最简单的Python命令共享大家都知道Python2与Python3不兼容,一般Linux和Mac OS X默认集成Python2,因为这些系统一些应用工具是Python2开发的，所以系统只能默认Python2。 Python2的操作姿势 1234Yeamin:book mac$ echo litonglitongYeamin:book mac$ python -m SimpleHTTPServer 8900Serving HTTP on 0.0.0.0 port 8900 ... Python3的操作姿势 12Yeamin:work mac$ python3 -m http.server 8900Serving HTTP on 0.0.0.0 port 8900 (http://0.0.0.0:8900/) ... ​ 我在我的Mac或Linux终端执行简单的上述任意两个命令后，启动一个HTTP服务器，打开浏览器输入http://127.0.0.1:8900或http://localhost:8900 后回出现下图文件共享的列表，若其他人想下载可以将局域网IP和端口号告知其他人即可下载。在这不仅仅可以下载，也可以预览常见文件，比如音频、视频、图片、PDF、文本文件。 最专业的Nginx服务共享大家都知道单台的Nginx Web服务器并发性能较强,一般基本都是文件多并发大的情况下才用，企业里一般做路由转发、负载均衡、资源静态化，路由转发是为了对外统一暴露一个地址，负载均衡是根据某种算法(IP_HASH绑定策略、轮询策略、权重)将不同的请求分散到多台业务相同的机器上，资源静态化这个很常见，以前项目太大，会将JS/CSS单独分离，使得应用系统前端组件加载更快。 下载Nginx 1234567891011litong@LT:/media/litong/软件/programs/tools$ wget -c http://nginx.org/download/nginx-1.15.10.tar.gz--2019-03-31 14:03:53-- http://nginx.org/download/nginx-1.15.10.tar.gz正在解析主机 nginx.org (nginx.org)... 62.210.92.35, 95.211.80.227, 2001:1af8:4060:a004:21::e3正在连接 nginx.org (nginx.org)|62.210.92.35|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：1032228 (1008K) [application/octet-stream]正在保存至: “nginx-1.15.10.tar.gz”nginx-1.15.10.tar.gz 100%[===============================&gt;] 1008K 13.4KB/s 用时 55s 2019-03-31 14:04:48 (18.4 KB/s) - 已保存 “nginx-1.15.10.tar.gz” [1032228/1032228]) 解压Nginx 1tar -zxvf nginx-1.15.10.tar.gz 编译Nginx 1cd nginx-1.15.10/ 1./configure 1make 1sudo make install 启动Nginx 12cd /usr/local/nginx/sbin./nginx 启动成功后，输入localhost:80，看是否启动成功进入到index.html，如下图: 查看启动进程 如果懒得打开浏览器，直接看进程确认nginx是否启动 12litong@LT:usr/local/nginx/sbin$ ps -ef | grep nginxroot 7017 1 0 11:07 ? 00:00:00 nginx: master process ./nginx 重载Nginx 修改Nginx的配置文件nginx.conf,并进行重载配置: 12345678910listen 80; #端口 server_name localhost; #服务名 charset utf-8; # 避免中文乱码root /home/litong/Pictures; #显示的根索引目录，注意这里要改成你自己的，目录要存在 location / &#123; autoindex on; #开启索引功能 autoindex_exact_size off; # 关闭计算文件确切大小（单位bytes），只显示大概大小（单位kb、mb、gb） autoindex_localtime on; # 显示本机时间而非 GMT 时间 &#125; 1./nginx -s reload 在浏览器端输入localhost:80, 则出现如下界面: 不同终端效果欣赏[Python共享]Mac Pro / Mac OS X 10.14.1 Mojave [Nginx共享]Lenovo Y430P/ Deepin Linux [Python共享]XiaoMi 5X/ Android-MIUI10 [Windows共享]Lenovo ThinkPad T410/Microsoft Windows 10 家庭版Windows后续再体验，未完待续。。。","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"RabbitMQ工作模式之简单模式","slug":"RabbitMQ工作模式之简单模式","date":"2018-06-12T12:15:11.000Z","updated":"2019-11-20T15:08:59.508Z","comments":true,"path":"2018/06/12/RabbitMQ工作模式之简单模式/","link":"","permalink":"http://ltyeamin.github.io/2018/06/12/RabbitMQ工作模式之简单模式/","excerpt":"","text":"今天我们来学习一下RabbitMQ工作模式之简单模式，在学之前我们根据官方文档(纯英文文档，可以装个Chrome插件选中翻译)学习一下RabbitMQ的一些术语，这才能让我们更深入的了解。 准备条件本教程假定RabbitMQ已在标准端口（5672）上的localhost上安装并运行。如果您使用不同的主机，端口或认证，则需要调整连接设置。 术语介绍RabbitMQ是一个消息代理中间件：它接受和转发消息。您可以将其视为邮局：当您将要发布的邮件放在邮箱中时，您可以确定邮递员最终会将邮件发送给您的收件人。在这个比喻中，RabbitMQ是一个邮箱，邮局和邮递员只负责中转调度。 RabbitMQ和邮局之间的主要区别在于它不处理纸张，而是接受，存储和转发二进制blob数据 - 消息。 RabbitMQ和一般的消息传递使用了一些术语：生产者、队列、消费者。 生产者 发送消息的程序是生产者。 官网上青色椭圆P则标识消息生产者。 队列 队列是RabbitMQ中的邮箱的名称。虽然消息流经RabbitMQ和您的应用程序，但它们只能存储在队列中。队列只受主机的内存和磁盘限制的约束，它本质上是一个大的消息缓冲区。许多生产者可以发送到一个队列的消息，并且许多消费者可以尝试从一个队列接收数据。官网上红色多格子长方形则标识队列。 消费者 消费与接受有类似的意义。消费者是一个主要等待接收消息的程序： 请注意，生产者、消费者和消息代理不必驻留在同一主机上;实际上在大多数应用中，应用程序也可以是生产者和消费者。 总结：整个过程非常简单，生产者创建消息，消费者接收这些消息。你的应用程序既可以作为生产者向其他应用程序发送消息，也可以作为消费者，等待接收其他应用程序的消息。其中，存储消息的是消息队列，它类似于邮箱，消息通过消息队列进行投递。 案例实战在本教程的这一部分中，我们将用Java编写两个程序;发送单个消息的生产者，以及接收消息并将其打印出来的消费者。我们将掩盖Java API中的一些细节，专注于这个非常简单的事情，只是为了开始。这是消息传递的“Hello World”。 在下图中，“P”是我们的生产者，“C”是我们的消费者。中间的红框是一个队列 - RabbitMQ代表消费者保留的消息缓冲区。 了解到上述概念，现在我们开始动手实践吧！ 导入客户端依赖 Maven 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.6.0&lt;/version&gt;&lt;/dependency&gt; Gradle 123dependencies &#123; compile group: 'com.rabbitmq', name: 'amqp-client', version: '5.6.0'&#125; 导入完依赖后，我们将编写消息发布者（发送者）Send发送和我们的消息消费者（接收者）Recv。发布者将连接到RabbitMQ，发送单个消息，然后退出。 编写消息生产/发生者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.yeamin.actions.simple.produces;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Channel;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * 简单队列的消息生产者 */public class Send &#123; /** * 设置队列名称 */ private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws IOException, TimeoutException &#123; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置连接主机名 factory.setHost(\"localhost\"); //设置端口号,不设置默认为5672 factory.setPort(5672); /* * 如果可以通过连接工厂创建一个连接,则继续在连接基础上继续创建通道. * 这里我们可以使用try-with-resources语句，因为Connection和Channel都实现了java.io.Closeable。 * 这样我们就不需要在代码中明确地关闭它们。 */ try (Connection connection = factory.newConnection(); // 创建通道 Channel channel = connection.createChannel()) &#123; /* * 为了发送消息成功,我们必须声明一个队列供我们发送,队列只声明一次,不可能存在重复队列 * 参数1: queue表示队列名称 * 参数2: durable表示是否持久化 * 参数3: exclusive表示仅创建者可以使用的私有队列，断开后自动删除 * 参数4: autoDelete表示当所有消费客户端连接断开后，是否自动删除队列 * 参数5: arguments表示其他的构造参数,为队列构造而准备 */ channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 要发送的消息 String message = \"Hello World, lt, Welcome RabbitMQ!\"; /* * 最基本的消息发送 * 参数1: exchange表示交换机 * 参数2: routingKey表示路由Key * 参数3: props表示息的其他参数 * 参数4: autoDelete表示当所有消费客户端连接断开后，是否自动删除队列 * 参数5: body表示息体,是个字节数组,意味着可以传递任何数据 */ channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); //消息发送方的日志打印 System.out.println(\" [x] Sent '\" + message + \"'\"); &#125; &#125;&#125; 声明队列是幂等的 ，只有在它不存在的情况下才会创建它。消息内容是一个字节数组，因此您可以发送任何数据。 编写消息消费者12345678910111213141516171819202122232425262728293031323334353637383940package cn.yeamin.actions.simple.consumers;import com.rabbitmq.client.*;/** * 简单队列的消息消费者 */public class Recv &#123; private final static String QUEUE_NAME = \"hello\"; public static void main(String[] argv) throws Exception &#123; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置RabbitMQ主机名 factory.setHost(\"localhost\"); // 新建连接 Connection connection = factory.newConnection(); // 新建通道 Channel channel = connection.createChannel(); //绑定队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(\" [*] Waiting for messages. To exit press CTRL+C\"); // 创建消费者,消费消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\" [x] Received '\" + message + \"'\"); &#125;; /** * * 消费者消费 * 参数1 ：queue队列名 * 参数2 ：autoAck 是否自动ACK * 参数3 ：callback消费者对象的一个接口，用来配置回调 * */ channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 为什么我们不使用try-with-resource语句来自动关闭通道和连接？通过这样做，我们只需让程序继续运行，关闭所有内容，然后退出！这将是尴尬的，因为我们希望在消费者异步监听消息到达时，该进程保持活动状态。 我们即将告诉服务器从队列中传递消息。因为它会异步地向我们发送消息，所以我们以对象的形式提供一个回调，它将缓冲消息，直到我们准备好使用它们。这就是DeliverCallback子类的作用。 消息生产与发送我们先执行消息发送者，执行完成后如下图： 紧接着，我们进行消息消费，执行完成后如下图: 当消息生产者一直发送时，我们可以得到如下结果： 1234567891011121315:17:00: Executing task 'Recv.main()'...&gt; Task :compileJava UP-TO-DATE&gt; Task :processResources NO-SOURCE&gt; Task :classes UP-TO-DATE&gt; Task :Recv.main()SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.[*] Waiting for messages. To exit press CTRL+C[x] Received 'Hello World, litong, Welcome RabbitMQ!'[x] Received 'Hello World, lt, Welcome RabbitMQ!' 源码地址https://github.com/ltyeamin/RabbitMQ-Action/tree/master/patterns 参考资料 RabbitMQ官网文档 《RabbitMQ实战指南》朱忠华著","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://ltyeamin.github.io/tags/RabbitMQ/"}]},{"title":"RabbitMQ概述","slug":"RabbitMQ概述","date":"2018-06-11T11:45:21.000Z","updated":"2019-11-23T03:24:56.158Z","comments":true,"path":"2018/06/11/RabbitMQ概述/","link":"","permalink":"http://ltyeamin.github.io/2018/06/11/RabbitMQ概述/","excerpt":"","text":"之所以今天写RabbitMQ学习专栏，主要是因为自己没有真正的系统学习过。之前工作经历中都是为用MQ而用的MQ，对MQ整个内部机制没有一个深入的了解和系统的学习。比如我们用Spring Cloud Stream或Spring Cloud Bus组件时候，我们会经常碰到MQ。MQ产品市面上有很多种，不同MQ产品有不同的适应场景(领域)。这就和学什么语言一样，不分什么好坏。 在这我要插上一句，在讨论技术选型的时候，我经常听到很多人说哪种技术好，哪种技术坏，哪种技术流行，哪种技术淘汰。其实正解应该是每种技术方案有自己适应领域，存在即合理。面试的时候经常有面试官询问技术方案选型。什么Spring Cloud和Dubbo比（压根就不是一个领域，Spring Cloud是整套的微服务落地方案，Dubbo只是一个具有客户端负载均衡的高性能RPC框架，论功能Dubbo只是Spring Cloud的一个子集），什么Redis和MongoDB比，ES和Solr比，各种MQ的比较，其实我觉得问这些面试题是有局限性的，没有具体业务场景就是无解，具体选型还是要根据当前公司的现有业务和系统现状来选型。我觉得面试官应该先把公司的业务场景说出来，然后应聘者根据公司的业务进行客观性评定。 好了，言归正传，常见的高级的MQ产品有RabbitMQ、Apache ActiveMQ、Apache RocketMQ(Alibaba捐赠)、Apache Kafka(LinkedIn捐赠) 。那么，今天我这里选择RabbitMQ进行学习，其他MQ学习都是相通的，读者可根据自身情况阅读官网文档并进行学习。我这里只是介绍一种学习方式。下面从官方文档以及其他资料给大家进行梳理RabbitMQ系列的知识。 MQ消息队列MQ概述消息队列技术是分布式应用间交换信息的一种技术。 消息队列可驻留在内存或磁盘上,队列存储消息直到它们被应用程序读走。 通过消息队列，应用程序可独立地执行。它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。 MQ主要作用是接受和转发消息。你可以想想在生活中的一种场景：当你把信件的投进邮筒，邮递员肯定最终会将信件送给收件人。我们可以把MQ比作 邮局和邮递员。 MQ和邮局的主要区别是,它不处理消息,但是,它会接受数据、存储消息数据、转发消息。 MQ应用场景 应用解耦: 系统异步化改造； 用户注册后的邮件发送、验证码短信发送； 分布式延时队列应用，用户下单后，24小时未支付，需要取消订单，我们只需要下单时用MQ发个消息通知一下，客户端延时（下单时间24小时后）执行，消费成功则证明取消订单成功。 异步通知及数据同步: 提升系统性能，保证数据最终一致性； 用户在管理页面更新数据，通过MQ异步通知，更新缓存、更新ES或Solr索引 应用限流: 可以保证并发场景下系统的稳定性； 抢票系统，在并发大系统有瓶颈的情况下，可以将请求打到MQ队列依次限流消费。 分布式日志系统数据很大的时候，MQ作为分布式日志的缓冲层，典型应用就是ELK+Kafaka。 数据分发: 一对多或广播的模式进行数据分发； 支付完成后，需要及时的通知子系统（进销存系统发货，用户服务积分，发送短信） 分布式事务: 分布式架构的系统可以通过MQ的队列数据进行数据回滚操作 RabbitMQ产品介绍RabbitMQ产品打开RabbitMQ官网首页，能看到如下的一句话: RabbitMQ is the most widely deployed open source message broker. 翻译为：RabbitMQ是部署最广泛的开源消息代理。 RabbitMQ是一个Erlang开发的AMQP（Advanced Message Queuing Protocol ）的开源实现。AMQP 的出现其实也是应了广大人民群众的需求，虽然在同步消息通讯的世界里有很多公开标准（如 Cobar）的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 WebSphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Red Hat、iMatix 等联合制定了 AMQP 的公开标准。 RabbitMQ由RabbitMQ Technologies Ltd开发并且提供商业支持的。该公司在2010年4月被SpringSource（VMware的一个部门）收购。在2013年5月被并入Pivotal。其实VMware，Pivotal和EMC本质上是一家的。不同的是，VMware是独立上市子公司，而Pivotal是整合了EMC的某些资源，现在并没有上市。 RabbitMQ产品特性 开源免费； 可伸缩性：集群服务； 消息持久化：从内存持久化消息到硬盘，再从硬盘加载到内存； 多语言多客户端支持，支持Python、Java、Ruby、PHP、C#、JavaScript、Go、Elixir、Objective-C、Swift、Spring AMQP。 RabbitMQ常用模式打开官方文档，我们眼前一亮，会看到如下6种RabbitMQ的工作模式： 1. “Hello World!” The simplest thing that does something Java Spring AMQP 2. Work queues Distributing tasks among workers (the competing consumers pattern) Java Spring AMQP 3. Publish/Subscribe Sending messages to many consumers at once Java Spring AMQP 4. RoutingReceiving messages selectively Java Spring AMQP 5. Topics The simplest thing that does something Java Spring AMQP 6. RPC Request/reply patternexample Java Spring AMQP 看到上述的6种工作模式，其中我们日常使用最多的是前5种模式，我们列一个学习列表: 简单模式: 一个生产者，一个消费者 Work模式: 一个生产者，多个消费者，每个消费者获取到的消息唯一。 订阅模式: 一个生产者发送的消息会被多个消费者获取。 路由模式: 发送消息到交换机并且要指定路由key ，消费者将队列绑定到交换机时需要指定路由key Topic模式: 将路由键和某模式进行匹配，此时队列需要绑定在一个模式上，“#”匹配一个词或多个词，“*”只匹配一个词。 RPC远程调用：几乎不用，暂时先不考虑 参考资料 RabbitMQ官网快速入门文档 《RabbitMQ实战指南》朱忠华著 什么是消息队列","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://ltyeamin.github.io/tags/RabbitMQ/"}]},{"title":"Docker安装分布式消息中间件-RabbitMQ","slug":"Docker安装分布式消息中间件-RabbitMQ","date":"2018-06-10T11:45:21.000Z","updated":"2019-11-20T15:08:54.561Z","comments":true,"path":"2018/06/10/Docker安装分布式消息中间件-RabbitMQ/","link":"","permalink":"http://ltyeamin.github.io/2018/06/10/Docker安装分布式消息中间件-RabbitMQ/","excerpt":"","text":"RabbitMQ是流行的开源消息队列系统，采用天生抗并发的erlang语言开发。RabbitMQ是AMQP（高级消息队列协议）的标准实现。接下来，我们通过Docker的方式安装RabbitMQ。 查看RabbitMQ版本进入docker hub官方镜像仓库或阿里docker镜像库,搜索rabbitmq镜像。 当然我们也可以用命令搜索: 1docker search rabbitmq:management 这里，我们用web页面搜索，搜索后点击详情页面。 这里我们选择带有management的版本，此版本包含web可视化管理页面。 Docker拉取镜像1docker pull rabbitmq:3.7.14-management 输入以上命令后，镜像分片开始下载并完成rabbitmq镜像的合并。下载完成后，我们可以查询输入以下命令查看当前本地仓库所有的镜像文件。 1docker images 如图 创建并启动RabbitMQ应用容器1docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:3.7.14-management 执行上述命令，我们可以创建一个rabbitmq的docker容器，执行成功后回返回docker容器ID。 12Yeamin:~ mac$ docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:3.7.14-management5b2658f3fe04919883b4d0b3d2766220e1ecb983d715b5b6cbfec758634f2531 创建参数解释-d 后台运行容器； –name 指定容器名； -p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）； -v 映射目录或文件； –hostname 主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）； -e 指定环境变量；（RABBITMQ_DEFAULT_VHOST：默认虚拟机名；RABBITMQ_DEFAULT_USER：默认的用户名；RABBITMQ_DEFAULT_PASS：默认用户名的密码，我这里没配置） 启动rabbitmq应用容器执行如下命令进行启动 1Docker start 容器id前四位 我这里以下命令进行执行 1docker start 5b26 查询运行状态执行docker ps查看正在运行的容器状态 12345Yeamin:~ mac$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5b2658f3fe04 rabbitmq:3.7.14-management \"docker-entrypoint.s…\" 30 minutes ago Up 30 minutes 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq RabbitMQ的WEB控制台在浏览器打开http://localhost:15672,进入登录页面，默认账号和密码都为guest。 参考资料 Docker官网 RabbitMQ官网","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ltyeamin.github.io/tags/Docker/"}]},{"title":"【【Java并发编程实战】线程池应用之Executors线程池静态工厂","slug":"【Java并发编程实战】线程池应用之Executors线程池静态工厂","date":"2018-06-09T16:12:11.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/06/10/【Java并发编程实战】线程池应用之Executors线程池静态工厂/","link":"","permalink":"http://ltyeamin.github.io/2018/06/10/【Java并发编程实战】线程池应用之Executors线程池静态工厂/","excerpt":"","text":"今天我们来认识一下，线程池的静态工厂Executors类，平时写测试代码的时候可用一用，生产代码尽量少用。为什么说生产上尽量少用呢？这是有原因的，请耐心听彤哥讲解。 阿里的代码规约不建议使用这样的工厂类，而建议使用手动创建并管理ThreadPoolExecutor，在阿里巴巴Java开发手册中，编程规约下的并发处理规约第4点如下： 【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors返回的线程池对象的弊端如下： 1）FixedThreadPool和SingleThreadPool: 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。 2）CachedThreadPool和ScheduledThreadPool: 允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 正例 1： 1234&gt; //org.apache.commons.lang3.concurrent.BasicThreadFactory&gt; ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1,&gt; new BasicThreadFactory.Builder().namingPattern(\"example-schedule-pool-%d\").daemon(true).build());&gt; 正例 2： 123456789&gt; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()&gt; .setNameFormat(\"demo-pool-%d\").build();&gt; //Common Thread Pool&gt; ExecutorService pool = new ThreadPoolExecutor(5, 200,&gt; 0L, TimeUnit.MILLISECONDS,&gt; new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());&gt; pool.execute(()-&gt; System.out.println(Thread.currentThread().getName()));&gt; pool.shutdown();//gracefully shutdown &gt; 12345678910111213&gt; 正例 3：&gt; &lt;bean id=\"userThreadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"&gt;&gt; &lt;property name=\"corePoolSize\" value=\"10\" /&gt;&gt; &lt;property name=\"maxPoolSize\" value=\"100\" /&gt;&gt; &lt;property name=\"queueCapacity\" value=\"2000\" /&gt;&gt; &lt;property name=\"threadFactory\" value= threadFactory /&gt;&gt; &lt;property name=\"rejectedExecutionHandler\"&gt;&gt; &lt;ref local=\"rejectedExecutionHandler\" /&gt;&gt; &lt;/property&gt;&gt; &lt;/bean&gt;&gt; //in code&gt; userThreadPool.execute(thread);&gt; 看到如下的规约，我们是不是没必要往下学了？答案是当然不行的，我们虽然不怎么用，但是研究其源码，可以让我们更深入线程池原理（增强内力），使得我们以后更容易设计线程池并能够高效管理线程，以至于不像代码规约描述的那样：用而不当导致OOM的问题。 源码分析好了，话不多说，直接上菜(源码)，够我们今天喝几壶了，哈哈。。。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573package java.util.concurrent;import java.util.*;import java.util.concurrent.atomic.AtomicInteger;import java.security.AccessControlContext;import java.security.AccessController;import java.security.PrivilegedAction;import java.security.PrivilegedExceptionAction;import java.security.PrivilegedActionException;import java.security.AccessControlException;import sun.security.util.SecurityConstants;/** * Executors线程池静态工厂类 */public class Executors &#123; /** * 创建重用固定数量线程的线程池,使用的是共享无参无边界队列。 * 在任何时候，最多线程将是活动的处理任务。 * 如果在所有线程都处于活动状态时提交了其他任务，它们将在队列中等待，直到线程可用。 * 在关闭之前，如果任何线程在执行期间因失败而终止,如果需要，将更换一个新的，执行后续任务。 * 池中的线程将存在直到它显式executerservice关闭。 */ public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; /** * 该方法是JDk8提供的。特殊的线程池，采用JDK1.7的ForkJoinPool实现 * 创建一个线程池，以维护足够的线程来支持给定的并行级别，并且可以使用多个队列来减少争用。 * 平行度级别对应于主动参与或可用于的线程的最大数目从事，任务处理。 * 实际线程数可能动态增长和收缩。偷工减料是不行的，保证提交任务的顺序执行。 * * @param 并行级别 */ public static ExecutorService newWorkStealingPool(int parallelism) &#123; return new ForkJoinPool (parallelism, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); &#125; /** * 重载方法: 只是默认参数用的是当前机器可利用CPU核数 */ public static ExecutorService newWorkStealingPool() &#123; return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); &#125; /** * 重载方法: 创建重用固定数量线程的线程池 * 只不过参数多了一个，可以自定义线程池工厂 */ public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); &#125; /** * 创建使用单个工作线程操作的执行器，即单线程工作模式，不可配置线程的大小。 * 也是在一个无边界的队列中运行的。相当于newFixedThreadPool(1)， * 在任何时刻，当前线程池只有1个活动线程，不可能出现其他的工作线程。 */ public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; /** * 重载方法: 创建使用单个工作线程操作的执行器，即单线程工作模式，不可配置线程的大小。 * 只不过可以自定义线程池工厂 */ public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory)); &#125; /** * 创建一个可重用的线程池: 根据需要创建新线程，但将重用以前构造的线程可用。 * 执行许多短期异步任务的程序，使用这类线程池可以提升程序性能。 * 如果没有线程可用，则线程被创建并添加到池中。 * 具有60秒未使用的线程，线程池则回收该线程。 * 如果线程可用，则重用之前的活动线程。 * 如果使用不当可能导致OOM。 */ public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; /** * 重载方法: 创建一个可重用的线程池 * 只不过可以自定义线程池工厂 * 如果使用不当可能导致OOM。 */ public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory); &#125; /** * 创建一个单线程的延迟任务线程池，可代替Timer(使用繁琐，线程不安全类)， */ public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); &#125; /** * 重载方法: 创建一个单线程的延迟任务线程池，可代替Timer(使用繁琐，线程不安全类)， * 只不过可以自定义线程池工厂 * */ public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory)); &#125; /** * 重载方法: 创建一个延迟任务线程池 * 只不过可以自定义线程池核心大小 * */ public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; /** * 重载方法: 创建一个延迟任务线程池 * 只不过可以自定义线程池核心大小和最大线程数量 * */ public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); &#125; /** * Returns an object that delegates all defined &#123;@link * ExecutorService&#125; methods to the given executor, but not any * other methods that might otherwise be accessible using * casts. This provides a way to safely \"freeze\" configuration and * disallow tuning of a given concrete implementation. * @param executor the underlying implementation * @return an &#123;@code ExecutorService&#125; instance * @throws NullPointerException if executor null */ public static ExecutorService unconfigurableExecutorService(ExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedExecutorService(executor); &#125; /** * Returns an object that delegates all defined &#123;@link * ScheduledExecutorService&#125; methods to the given executor, but * not any other methods that might otherwise be accessible using * casts. This provides a way to safely \"freeze\" configuration and * disallow tuning of a given concrete implementation. * @param executor the underlying implementation * @return a &#123;@code ScheduledExecutorService&#125; instance * @throws NullPointerException if executor null */ public static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedScheduledExecutorService(executor); &#125; /** * Returns a default thread factory used to create new threads. * This factory creates all new threads used by an Executor in the * same &#123;@link ThreadGroup&#125;. If there is a &#123;@link * java.lang.SecurityManager&#125;, it uses the group of &#123;@link * System#getSecurityManager&#125;, else the group of the thread * invoking this &#123;@code defaultThreadFactory&#125; method. Each new * thread is created as a non-daemon thread with priority set to * the smaller of &#123;@code Thread.NORM_PRIORITY&#125; and the maximum * priority permitted in the thread group. New threads have names * accessible via &#123;@link Thread#getName&#125; of * &lt;em&gt;pool-N-thread-M&lt;/em&gt;, where &lt;em&gt;N&lt;/em&gt; is the sequence * number of this factory, and &lt;em&gt;M&lt;/em&gt; is the sequence number * of the thread created by this factory. * @return a thread factory */ public static ThreadFactory defaultThreadFactory() &#123; return new DefaultThreadFactory(); &#125; /** * Returns a thread factory used to create new threads that * have the same permissions as the current thread. * This factory creates threads with the same settings as &#123;@link * Executors#defaultThreadFactory&#125;, additionally setting the * AccessControlContext and contextClassLoader of new threads to * be the same as the thread invoking this * &#123;@code privilegedThreadFactory&#125; method. A new * &#123;@code privilegedThreadFactory&#125; can be created within an * &#123;@link AccessController#doPrivileged AccessController.doPrivileged&#125; * action setting the current thread's access control context to * create threads with the selected permission settings holding * within that action. * * &lt;p&gt;Note that while tasks running within such threads will have * the same access control and class loader settings as the * current thread, they need not have the same &#123;@link * java.lang.ThreadLocal&#125; or &#123;@link * java.lang.InheritableThreadLocal&#125; values. If necessary, * particular values of thread locals can be set or reset before * any task runs in &#123;@link ThreadPoolExecutor&#125; subclasses using * &#123;@link ThreadPoolExecutor#beforeExecute(Thread, Runnable)&#125;. * Also, if it is necessary to initialize worker threads to have * the same InheritableThreadLocal settings as some other * designated thread, you can create a custom ThreadFactory in * which that thread waits for and services requests to create * others that will inherit its values. * * @return a thread factory * @throws AccessControlException if the current access control * context does not have permission to both get and set context * class loader */ public static ThreadFactory privilegedThreadFactory() &#123; return new PrivilegedThreadFactory(); &#125; /** * Returns a &#123;@link Callable&#125; object that, when * called, runs the given task and returns the given result. This * can be useful when applying methods requiring a * &#123;@code Callable&#125; to an otherwise resultless action. * @param task the task to run * @param result the result to return * @param &lt;T&gt; the type of the result * @return a callable object * @throws NullPointerException if task null */ public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result); &#125; /** * Returns a &#123;@link Callable&#125; object that, when * called, runs the given task and returns &#123;@code null&#125;. * @param task the task to run * @return a callable object * @throws NullPointerException if task null */ public static Callable&lt;Object&gt; callable(Runnable task) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;Object&gt;(task, null); &#125; /** * Returns a &#123;@link Callable&#125; object that, when * called, runs the given privileged action and returns its result. * @param action the privileged action to run * @return a callable object * @throws NullPointerException if action null */ public static Callable&lt;Object&gt; callable(final PrivilegedAction&lt;?&gt; action) &#123; if (action == null) throw new NullPointerException(); return new Callable&lt;Object&gt;() &#123; public Object call() &#123; return action.run(); &#125;&#125;; &#125; /** * Returns a &#123;@link Callable&#125; object that, when * called, runs the given privileged exception action and returns * its result. * @param action the privileged exception action to run * @return a callable object * @throws NullPointerException if action null */ public static Callable&lt;Object&gt; callable(final PrivilegedExceptionAction&lt;?&gt; action) &#123; if (action == null) throw new NullPointerException(); return new Callable&lt;Object&gt;() &#123; public Object call() throws Exception &#123; return action.run(); &#125;&#125;; &#125; /** * Returns a &#123;@link Callable&#125; object that will, when called, * execute the given &#123;@code callable&#125; under the current access * control context. This method should normally be invoked within * an &#123;@link AccessController#doPrivileged AccessController.doPrivileged&#125; * action to create callables that will, if possible, execute * under the selected permission settings holding within that * action; or if not possible, throw an associated &#123;@link * AccessControlException&#125;. * @param callable the underlying task * @param &lt;T&gt; the type of the callable's result * @return a callable object * @throws NullPointerException if callable null */ public static &lt;T&gt; Callable&lt;T&gt; privilegedCallable(Callable&lt;T&gt; callable) &#123; if (callable == null) throw new NullPointerException(); return new PrivilegedCallable&lt;T&gt;(callable); &#125; public static &lt;T&gt; Callable&lt;T&gt; privilegedCallableUsingCurrentClassLoader(Callable&lt;T&gt; callable) &#123; if (callable == null) throw new NullPointerException(); return new PrivilegedCallableUsingCurrentClassLoader&lt;T&gt;(callable); &#125; // Non-public classes supporting the public methods /** * 运行给定任务并返回给定结果的可调用文件 */ static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125; &#125; /** * 在已建立的访问控制设置下运行的可调用文件 */ static final class PrivilegedCallable&lt;T&gt; implements Callable&lt;T&gt; &#123; private final Callable&lt;T&gt; task; private final AccessControlContext acc; PrivilegedCallable(Callable&lt;T&gt; task) &#123; this.task = task; this.acc = AccessController.getContext(); &#125; public T call() throws Exception &#123; try &#123; return AccessController.doPrivileged( new PrivilegedExceptionAction&lt;T&gt;() &#123; public T run() throws Exception &#123; return task.call(); &#125; &#125;, acc); &#125; catch (PrivilegedActionException e) &#123; throw e.getException(); &#125; &#125; &#125; /** * 在已建立的访问控制设置和当前类加载器下运行的可调用文件。 */ static final class PrivilegedCallableUsingCurrentClassLoader&lt;T&gt; implements Callable&lt;T&gt; &#123; private final Callable&lt;T&gt; task; private final AccessControlContext acc; private final ClassLoader ccl; PrivilegedCallableUsingCurrentClassLoader(Callable&lt;T&gt; task) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // Calls to getContextClassLoader from this class // never trigger a security check, but we check // whether our callers have this permission anyways. sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); // Whether setContextClassLoader turns out to be necessary // or not, we fail fast if permission is not available. sm.checkPermission(new RuntimePermission(\"setContextClassLoader\")); &#125; this.task = task; this.acc = AccessController.getContext(); this.ccl = Thread.currentThread().getContextClassLoader(); &#125; public T call() throws Exception &#123; try &#123; return AccessController.doPrivileged( new PrivilegedExceptionAction&lt;T&gt;() &#123; public T run() throws Exception &#123; Thread t = Thread.currentThread(); ClassLoader cl = t.getContextClassLoader(); if (ccl == cl) &#123; return task.call(); &#125; else &#123; t.setContextClassLoader(ccl); try &#123; return task.call(); &#125; finally &#123; t.setContextClassLoader(cl); &#125; &#125; &#125; &#125;, acc); &#125; catch (PrivilegedActionException e) &#123; throw e.getException(); &#125; &#125; &#125; /** * 默认线程工厂 */ static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; /** * 线程工厂捕获访问控制上下文和类加载器 */ static class PrivilegedThreadFactory extends DefaultThreadFactory &#123; private final AccessControlContext acc; private final ClassLoader ccl; PrivilegedThreadFactory() &#123; super(); SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // Calls to getContextClassLoader from this class // never trigger a security check, but we check // whether our callers have this permission anyways. sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); // Fail fast sm.checkPermission(new RuntimePermission(\"setContextClassLoader\")); &#125; this.acc = AccessController.getContext(); this.ccl = Thread.currentThread().getContextClassLoader(); &#125; public Thread newThread(final Runnable r) &#123; return super.newThread(new Runnable() &#123; public void run() &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; Thread.currentThread().setContextClassLoader(ccl); r.run(); return null; &#125; &#125;, acc); &#125; &#125;); &#125; &#125; /** * 仅公开ExecutorService方法的包装类 * 执行器服务的实现类 */ static class DelegatedExecutorService extends AbstractExecutorService &#123; private final ExecutorService e; DelegatedExecutorService(ExecutorService executor) &#123; e = executor; &#125; public void execute(Runnable command) &#123; e.execute(command); &#125; public void shutdown() &#123; e.shutdown(); &#125; public List&lt;Runnable&gt; shutdownNow() &#123; return e.shutdownNow(); &#125; public boolean isShutdown() &#123; return e.isShutdown(); &#125; public boolean isTerminated() &#123; return e.isTerminated(); &#125; public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; return e.awaitTermination(timeout, unit); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; return e.submit(task); &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; return e.submit(task); &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; return e.submit(task, result); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; return e.invokeAll(tasks); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; return e.invokeAll(tasks, timeout, unit); &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; return e.invokeAny(tasks); &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return e.invokeAny(tasks, timeout, unit); &#125; &#125; static class FinalizableDelegatedExecutorService extends DelegatedExecutorService &#123; FinalizableDelegatedExecutorService(ExecutorService executor) &#123; super(executor); &#125; protected void finalize() &#123; super.shutdown(); &#125; &#125; /** * 仅公开ScheduledExecutorService的包装类 * ScheduledExecutorService实现的方法 */ static class DelegatedScheduledExecutorService extends DelegatedExecutorService implements ScheduledExecutorService &#123; private final ScheduledExecutorService e; DelegatedScheduledExecutorService(ScheduledExecutorService executor) &#123; super(executor); e = executor; &#125; public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; return e.schedule(command, delay, unit); &#125; public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; return e.schedule(callable, delay, unit); &#125; public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; return e.scheduleAtFixedRate(command, initialDelay, period, unit); &#125; public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) &#123; return e.scheduleWithFixedDelay(command, initialDelay, delay, unit); &#125; &#125; /** 不允许实例化 */ private Executors() &#123;&#125;&#125; 常用方法FixedThreadPoolFixedThreadPool，可重用固定线程数的线程池。 corePoolSize 和 maximumPoolSize都设置为创建FixedThreadPool时指定的参数nThreads，意味着当线程池满时且阻塞队列也已经满时，如果继续提交任务，则会直接走拒绝策略，该线程池不会再新建线程来执行任务，而是直接走拒绝策略。FixedThreadPool使用的是默认的拒绝策略，即AbortPolicy，则直接抛出异常。 keepAliveTime设置为0L，表示空闲的线程会立刻终止。 workQueue则是使用LinkedBlockingQueue，但是没有设置范围，那么则是最大值（Integer.MAX_VALUE），这基本就相当于一个无界队列了。使用该“无界队列”则会带来哪些影响呢？当线程池中的线程数量等于corePoolSize 时，如果继续提交任务，该任务会被添加到阻塞队列workQueue中，当阻塞队列也满了之后，则线程池会新建线程执行任务直到maximumPoolSize。由于FixedThreadPool使用的是“无界队列”LinkedBlockingQueue，那么maximumPoolSize参数无效，同时指定的拒绝策略AbortPolicy也将无效。而且该线程池也不会拒绝提交的任务，如果客户端提交任务的速度快于任务的执行，那么keepAliveTime也是一个无效参数。 SingleThreadExecutorSingleThreadExecutor是使用单个worker线程的Executor，即单线程工作模式。 作为单一worker线程的线程池，SingleThreadExecutor把corePool和maximumPoolSize均被设置为1，和FixedThreadPool一样使用的是无界队列LinkedBlockingQueue,所以带来的影响和FixedThreadPool一样。 CachedThreadPoolCachedThreadPool是一个会根据需要创建新线程的线程池 。 CachedThreadPool的corePool为0，maximumPoolSize为Integer.MAX_VALUE，这就意味着所有的任务一提交就会加入到阻塞队列中。keepAliveTime这是为60L，unit设置为TimeUnit.SECONDS，意味着空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。阻塞队列采用的SynchronousQueue，我们了解到SynchronousQueue是一个没有元素的阻塞队列(概念上的无界，其实是有界的)，加上corePool = 0 ，maximumPoolSize = Integer.MAX_VALUE，这样就会存在一个问题，如果主线程提交任务的速度远远大于CachedThreadPool的处理速度，则CachedThreadPool会不断地创建新线程来执行任务，这样有可能会导致系统耗尽CPU和内存资源，所以在使用该线程池是，一定要注意控制并发的任务数，否则创建大量的线程可能导致严重的性能问题。 ScheduledThreadPoolScheduledThreadPool，创建一个可延迟调度的线程池。 ScheduledThreadPool的线程池处理类为ScheduledThreadPoolExecutor，通过构造我们可以得出corePool是可以自定义的，maximumPoolSize为Integer.MAX_VALUE，这就意味着所有的任务一提交就会加入到阻塞队列中。keepAliveTime为0，unit设置为TimeUnit.NANOSECONDS，意味着执行完延迟任务后会立马回收线程。阻塞队列采用DelayedWorkQueue(专为延迟队列而生),DelayedWorkQueue基于堆的数据结构，默认初始化容量为16。 我们知道Timer与TimerTask虽然可以实现线程的周期和延迟调度，但是Timer与TimerTask存在一些缺陷，所以对于这种定期、周期执行任务的调度策略，我们一般都是推荐ScheduledThreadPoolExecutor来实现。 具体分析请阅读大牛博文: ScheduledThreadPoolExecutor详解一 ScheduledThreadPoolExecutor详解二 WorkStealingPoolWorkStealingPool是个特殊的线程池，但不长用，面试有时候可能会问到，内部实现原理其实是基于JDK1.7的ForkJoinPool框架，具体构造实现细节如下： 1234567891011121314151617181920212223242526272829303132333435/** * Creates a &#123;@code ForkJoinPool&#125; with the given parameters. * * @param parallelism the parallelism level. For default value, * use &#123;@link java.lang.Runtime#availableProcessors&#125;. * @param factory the factory for creating new threads. For default value, * use &#123;@link #defaultForkJoinWorkerThreadFactory&#125;. * @param handler the handler for internal worker threads that * terminate due to unrecoverable errors encountered while executing * tasks. For default value, use &#123;@code null&#125;. * @param asyncMode if true, * establishes local first-in-first-out scheduling mode for forked * tasks that are never joined. This mode may be more appropriate * than default locally stack-based mode in applications in which * worker threads only process event-style asynchronous tasks. * For default value, use &#123;@code false&#125;. * @throws IllegalArgumentException if parallelism less than or * equal to zero, or greater than implementation limit * @throws NullPointerException if the factory is null * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold &#123;@link * java.lang.RuntimePermission&#125;&#123;@code (\"modifyThread\")&#125; */public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) &#123; this(checkParallelism(parallelism), checkFactory(factory), handler, asyncMode ? FIFO_QUEUE : LIFO_QUEUE, \"ForkJoinPool-\" + nextPoolId() + \"-worker-\"); checkPermission();&#125; ForkJoinPool框架是个并行框架，在多核CPU中有着高效的性能体验。Java7 提供了ForkJoinPool来支持将一个任务拆分成多个“小任务”并行计算，再把多个“小任务”的结果合并成总的计算结果。有关于ForkJoinPool知识，我们后续讲解。 参考资料 阿里巴巴Java开发手册 唯品会Java开发手册 《Java并发编程的艺术》","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"【Java并发编程实战】-深入ThreadPoolExecutor工作机制","slug":"【Java并发编程实战】-深入ThreadPoolExecutor工作机制","date":"2018-06-09T10:45:21.000Z","updated":"2019-11-20T15:08:55.367Z","comments":true,"path":"2018/06/09/【Java并发编程实战】-深入ThreadPoolExecutor工作机制/","link":"","permalink":"http://ltyeamin.github.io/2018/06/09/【Java并发编程实战】-深入ThreadPoolExecutor工作机制/","excerpt":"","text":"为了高效的管理线程，JDK1.5版本的Doug Lea大神为我们设计了大名鼎鼎的ThreadPoolExecutor。 作为Executor框架中最核心的类-ThreadPoolExecutor，我们可以认为它是一个调度工具，为了高效执行或调度任务，我们非常有必要对该类的工作原理以及内部机制了解一番。线程池的每一个参数配置都有一定的设计合理性，各个参数配置协同聚合，让资源合理运用才是我们最关注的。 线程池的生命周期线程有五种状态：新建，就绪，运行，阻塞，死亡。线程池同样有五种状态：Running, SHUTDOWN, STOP, TIDYING, TERMINATED。 我们翻开ThreadPoolExecutor源码可以看到线程池生命周期的定义： 1234567891011121314151617181920private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bits// 对应的高3位值是111private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;// 对应的高3位值是000private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 对应的高3位值是001private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 对应的高3位值是010private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 对应的高3位值是011private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY;&#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 变量ctl定义为AtomicInteger ，其功能非常强大，记录了“线程池中的任务数量”和“线程池的状态”两个信息。共32位，其中高3位表示”线程池状态(runState)”，低29位表示”线程池中的任务数量(workerCnt)”。 线程池是有状态的，不同状态下线程池的行为是不一样的。具体运转流程如下: 状态 含义 RUNNING 运行状态，该状态下线程池可以接受新的任务，也可以处理阻塞队列中的任务执行, shutdown 方法可进入 SHUTDOWN 状态;执行 shutdownNow 方法可进入 STOP 状态 SHUTDOWN 待关闭状态，不再接受新的任务，继续处理阻塞队列中的任务;当阻塞队列中的任务为空，并且工作线程数为0时，进入 TIDYING 状态 STOP 停止状态，不接收新任务，也不处理阻塞队列中的任务，并且会尝试结束执行中的任务;当工作线程数为0时，进入 TIDYING 状态 TIDYING 整理状态，此时任务都已经执行完毕（ctl记录的”任务数量”为0），并且也没有工作线程; 执行 terminated 方法后进入 TERMINATED 状态 TERMINATED 终止状态，此时线程池完全终止了，并完成了所有资源的释放 线程池的内部构造123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 上述源码是摘自JDK1.8中ThreadPoolExecutor的构造源码，构造器有7个重要参数，这七个参数意义重大，我们有必要深入学习。 前文讲到有了标志工作线程的个数的变量ctl，那么不同硬件配置的机器，到底应该配置多少个线程才合适呢？线程池配置的核心线程数少了，发挥不了线程池的特性，线程池配置的核心线程数多了，又造成资源耗费。 现在我们有一个疑问，既然已经有了标识工作线程的个数的变量了，为什么还要有核心线程数、最大线程数呢？ 其实你这样想就能够理解了，创建线程是有代价的，不能每次要执行一个任务时就创建一个线程，但是也不能在任务非常多的时候，只有少量的线程在执行，这样任务是来不及处理的，而是应该创建合适的足够多的线程来及时的处理任务。随着任务数量的变化，当任务数明显很小时，原本创建的多余的线程就没有必要再存活着了，因为这时使用少量的线程就能够处理的过来了，所以说真正工作的线程的数量，是随着任务的变化而变化的。 那核心线程数和最大线程数与工作线程个数的关系是什么呢？ 工作线程的个数可能从0到最大线程数之间变化，当执行一段时间之后可能维持在 corePoolSize，但也不是绝对的，取决于核心线程是否允许被超时回收。 corePoolSize核心线程数corePoolSize 用来表示线程池中的核心线程的数量，也可以称为可闲置的线程数量。当提交一个任务时，线程池会新建一个线程来执行任务，直到当前线程数等于corePoolSize。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。 maximumPoolSize最大线程数maximumPoolSize 用来表示线程池中最多能够创建的线程数量。线程池的阻塞队列满了之后，如果还有任务提交，如果当前的线程数小于maximumPoolSize，则会新建线程来执行任务。注意，如果使用的是无界队列，该参数也就没有什么效果了。 keepAliveTime线程空闲时间线程的创建和销毁是需要代价的。线程执行完任务后不会立即销毁，而是继续存活一段时间：keepAliveTime。默认情况下，该参数只有在线程数大于corePoolSize时才会生效。 当工作线程数达到 corePoolSize 时，线程池会将新接收到的任务存放在阻塞队列中，而阻塞队列又两种情况：一种是有界的队列，一种是无界的队列。 如果是无界队列，那么当核心线程都在忙的时候，所有新提交的任务都会被存放在该无界队列中，这时最大线程数将变得没有意义，因为阻塞队列不会存在被装满的情况。 如果是有界队列，那么当阻塞队列中装满了等待执行的任务，这时再有新任务提交时，线程池就需要创建新的“临时”线程来处理，相当于增派人手来处理任务。 但是创建的“临时”线程是有存活时间的，不可能让他们一直都存活着，当阻塞队列中的任务被执行完毕，并且又没有那么多新任务被提交时，“临时”线程就需要被回收销毁，在被回收销毁之前等待的这段时间，就是非核心线程的存活时间，也就是 keepAliveTime 属性。 那么什么是“非核心线程”呢？是不是先创建的线程就是核心线程，后创建的就是非核心线程呢？ 其实核心线程跟创建的先后没有关系，而是跟工作线程的个数有关，如果当前工作线程的个数大于核心线程数，那么所有的线程都可能是“非核心线程”，都有被回收的可能。 一个线程执行完了一个任务后，会去阻塞队列里面取新的任务，在取到任务之前它就是一个闲置的线程。 取任务的方法有两种，一种是通过 take() 方法一直阻塞直到取出任务，另一种是通过 poll(keepAliveTime，timeUnit) 方法在一定时间内取出任务或者超时，如果超时这个线程就会被回收，请注意核心线程一般不会被回收。 那么怎么保证核心线程不会被回收呢？还是跟工作线程的个数有关，每一个线程在取任务的时候，线程池会比较当前的工作线程个数与核心线程数： 如果工作线程数小于当前的核心线程数，则使用第一种方法取任务，也就是没有超时回收，这时所有的工作线程都是“核心线程”，他们不会被回收； 如果大于核心线程数，则使用第二种方法取任务，一旦超时就回收，所以并没有绝对的核心线程，只要这个线程没有在存活时间内取到任务去执行就会被回收。 所以每个线程想要保住自己“核心线程”的身份，必须充分努力，尽可能快的获取到任务去执行，这样才能逃避被回收的命运。 核心线程一般不会被回收，但是也不是绝对的，如果我们设置了允许核心线程超时被回收的话，那么就没有核心线程这种说法了，所有的线程都会通过 poll(keepAliveTime, timeUnit) 来获取任务，一旦超时获取不到任务，就会被回收，一般很少会这样来使用，除非该线程池需要处理的任务非常少，并且频率也不高，不需要将核心线程一直维持着。 unit线程空闲时间单位keepAliveTime的单位。TimeUnit，可设置时分秒毫秒 workQueue任务队列workQueue用来保存等待执行的任务的阻塞队列，等待的任务必须实现Runnable接口。我们可以选择如下几种： ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。 LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。 SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作，反之亦然。 PriorityBlockingQueue：具有优先界别的阻塞队列。 上面我们说了核心线程数和最大线程数，并且也介绍了工作线程的个数是在0和最大线程数之间变化的。但是不可能一下子就创建了所有线程，把线程池装满，而是有一个过程，这个过程是这样的： 当线程池接收到一个任务时，如果工作线程数没有达到corePoolSize，那么就会新建一个线程，并绑定该任务，直到工作线程的数量达到 corePoolSize 前都不会重用之前的线程。 当工作线程数达到 corePoolSize 了，这时又接收到新任务时，会将任务存放在一个阻塞队列中等待核心线程去执行。为什么不直接创建更多的线程来执行新任务呢，原因是核心线程中很可能已经有线程执行完自己的任务了，或者有其他线程马上就能处理完当前的任务，并且接下来就能投入到新的任务中去，所以阻塞队列是一种缓冲的机制，给核心线程一个机会让他们充分发挥自己的能力。另外一个值得考虑的原因是，创建线程毕竟是比较昂贵的，不可能一有任务要执行就去创建一个新的线程。 所以我们需要为线程池配备一个阻塞队列，即任务列表，用来临时缓存任务，这些任务将等待工作线程来执行。 threadFactory线程工厂既然是线程池，那自然少不了线程，线程该如何来创建呢？这个任务就交给了线程工厂 ThreadFactory 来完成。 该对象可以通过Executors.defaultThreadFactory()，如下： 123public static ThreadFactory defaultThreadFactory() &#123; return new DefaultThreadFactory();&#125; 返回的DefaultThreadFactory对象，源码如下： 1234567891011121314151617181920212223242526static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; ThreadFactory的默认实现DefaultThreadFactory就是提供创建线程功能的线程工厂。他是通过newThread()方法提供创建线程的功能，newThread()方法创建的线程都是“非守护线程”而且“线程优先级都是Thread.NORM_PRIORITY”。 handler拒绝策略虽然我们有了阻塞队列来对任务进行缓存，这从一定程度上为线程池的执行提供了缓冲期，但是如果是有界的阻塞队列，那就存在队列满的情况，也存在工作线程的数据已经达到最大线程数的时候。如果这时候再有新的任务提交时，显然线程池已经心有余而力不足了，因为既没有空余的队列空间来存放该任务，也无法创建新的线程来执行该任务了，所以这时我们就需要有一种拒绝策略，即 handler。 RejectedExecutionHandler，线程池的拒绝策略。所谓拒绝策略，是指将任务添加到线程池中时，线程池拒绝该任务所采取的相应策略。当向线程池中提交任务时，如果此时线程池中的线程已经饱和了，而且阻塞队列也已经满了，则线程池会选择一种拒绝策略来处理该任务。 线程池提供了四种拒绝策略： AbortPolicy：直接抛出异常，默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； 当然我们也可以实现自己的拒绝策略，例如记录日志等等，实现RejectedExecutionHandler接口即可。 线程池的工作流程了解了线程池中所有的重要属性之后，现在我们需要来了解下线程池的工作流程了。 上图是一张线程池工作的精简图，实际的过程比这个要复杂的多，不过这些应该能够完全覆盖到线程池的整个工作流程了。 整个过程可以拆分成以下几个部分： 提交任务 当向线程池提交一个新的任务时，线程池有三种处理情况，分别是：创建一个工作线程来执行该任务、将任务加入阻塞队列、拒绝该任务。 提交任务的过程也可以拆分成以下几个部分： 当工作线程数小于核心线程数时，直接创建新的核心工作线程 当工作线程数不小于核心线程数时，就需要尝试将任务添加到阻塞队列中去 如果能够加入成功，说明队列还没有满，那么需要做以下的二次验证来保证添加进去的任务能够成功被执行 验证当前线程池的运行状态，如果是非RUNNING状态，则需要将任务从阻塞队列中移除，然后拒绝该任务 验证当前线程池中的工作线程的个数，如果为0，则需要主动添加一个空工作线程来执行刚刚添加到阻塞队列中的任务 如果加入失败，则说明队列已经满了，那么这时就需要创建新的“临时”工作线程来执行任务 如果创建成功，则直接执行该任务 如果创建失败，则说明工作线程数已经等于最大线程数了，则只能拒绝该任务了 整个过程可以用下面这张图来表示： 创建工作线程创建工作线程需要做一系列的判断，需要确保当前线程池可以创建新的线程之后，才能创建。 首先，当线程池的状态是 SHUTDOWN 或者 STOP 时，则不能创建新的线程。 另外，当线程工厂创建线程失败时，也不能创建新的线程。 还有就是当前工作线程的数量与核心线程数、最大线程数进行比较，如果前者大于后者的话，也不允许创建。 除此之外，会尝试通过 CAS 来自增工作线程的个数，如果自增成功了，则会创建新的工作线程，即 Worker 对象。 然后加锁进行二次验证是否能够创建工作线程，最后如果创建成功，则会启动该工作线程。 启动工作线程当工作线程创建成功后，也就是 Worker 对象已经创建好了，这时就需要启动该工作线程，让线程开始干活了，Worker 对象中关联着一个 Thread，所以要启动工作线程的话，只要通过 worker.thread.start() 来启动该线程即可。 启动完了之后，就会执行 Worker 对象的 run 方法，因为 Worker 实现了 Runnable 接口，所以本质上 Worker 也是一个线程。 通过线程 start 开启之后就会调用到 Runnable 的 run 方法，在 worker 对象的 run 方法中，调用了 runWorker(this) 方法，也就是把当前对象传递给了 runWorker 方法，让他来执行。 获取任务并执行在 runWorker 方法被调用之后，就是执行具体的任务了，首先需要拿到一个可以执行的任务，而 Worker 对象中默认绑定了一个任务，如果该任务不为空的话，那么就是直接执行。 执行完了之后，就会去阻塞队列中获取任务来执行，而获取任务的过程，需要考虑当前工作线程的个数。 如果工作线程数大于核心线程数，那么就需要通过 poll 来获取，因为这时需要对闲置的线程进行回收； 如果工作线程数小于等于核心线程数，那么就可以通过 take 来获取了，因此这时所有的线程都是核心线程，不需要进行回收，前提是没有设置 allowCoreThreadTimeOut 本篇基本笔者都是对线程池的基本模型以及内部概念进行分析，说实话，写完之后读了一遍，比较抽象难理解，下篇我将以JDK源码进行导读，继续探究线程池的工作原理，敬请期待。。。 参考资料 【死磕Java并发】—–J.U.C之线程池：ThreadPoolExecutor","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"【Java并发编程实战】-Java线程池基础","slug":"【Java并发编程实战】-Java线程池基础","date":"2018-06-08T14:45:07.000Z","updated":"2019-11-20T15:08:57.568Z","comments":true,"path":"2018/06/08/【Java并发编程实战】-Java线程池基础/","link":"","permalink":"http://ltyeamin.github.io/2018/06/08/【Java并发编程实战】-Java线程池基础/","excerpt":"","text":"线程池是限制系统中执行线程的数量，并能够根据一定的策略回收线程并重复使用。JDK1.5之后加入了java.util.concurrent包，我们日常称之为J.U.C并发包，这个包对我们日常解决并发提供了非常大的帮助。 根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池中有等待的工作线程，就可以开始运行了；否则进入等待队列。 专业解释:线程池管理一个工作者线程的同构池，线程池是与工作队列紧密绑定。所谓工作队列，其作用是持有所有等待执行的任务。工作者线程的生活从此轻松起来:它从工作队列中获取下一个任务，执行它，然后回来继续等待另一个线程。 显示创建线程弊端在日常开发过程中，如果每次显示的new Thread().start()，会存在很大的性能缺陷: 线程生命周期的开销比较大。线程的创建与关闭都很耗时，对于计算机来讲，是个不容易的事情。 活动线程会很消耗系统资源，尤其是内存。如果可运行的线程数多于可用的处理器内核数量。如果大量线程空闲，会占用更多的内存，给垃圾回收带来压力。如果大量线程繁忙，导致大量线程同时竞争CPU资源，性能开销多，造成程序假死，计算机死机等危害。 稳定性和可维护性差。分散的线程多了无法集中式管理，从而导致意想不到的BUG，比如一直创建线程造成的OOM问题。 Executor框架作为线程池的一部分，JDK1.5为我们提供了一个使用有界队列防止应用程序过载而耗尽内存的Executor框架，该线程池实现细节在java.util.comcurrent包下（简称并发包/J.U.C包）。在Java类库中，任务执行的首要抽象不是Thread，而是Executor，如下图所示的是简单Executor框架抽象依赖: Executor只是简单的接口，这个框架可以用于异步任务执行，而且支持多种类型的任务执行策略。它为任务提交和任务执行之间的解耦提供了标准的方法，为使用Runnable描述任务提供了通用方式。Executor的实现还提供了对生命周期的支持以及钩子函数，可以添加诸如统计收集、应用程序管理机制和监视器等扩展。 Executor基于生产者-消费者模式。提交任务的执行者是生产者(产生待完成的工作单元)，执行任务的线程是消费者(消耗掉这些工作单元)。Executor，任务的执行者，线程池框架中几乎所有类都直接或者间接实现Executor接口，它是线程池框架的基础。Executor提供了一种将“任务提交”与“任务执行”分离开来的机制，它仅提供了一个Execute()方法用来执行已经提交的Runnable任务。 Executor接口概述12345678package java.util.concurrent;public interface Executor &#123; /** * 方法描述：抽象出来的任务执行方法，方便后续不同类型的线程池的执行 * 参数描述：Runnable线程任务对象 */ void execute(Runnable command);&#125; ExcutorService接口概述继承Executor，它是“执行者服务”接口，它是为”执行者接口Executor”服务而存在的。准确的地说，ExecutorService提供了”将任务提交给执行者的接口(submit方法)”，”让执行者执行任务(invokeAll, invokeAny方法)”的接口等等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package java.util.concurrent;import java.util.List;import java.util.Collection;public interface ExecutorService extends Executor &#123; /** * 启动一次顺序关闭，执行以前提交的任务，但不接受新任务 */ void shutdown(); /** * 试图停止所有正在执行的活动任务，暂停处理正在等待的任务，并返回等待执行的任务列表 */ List&lt;Runnable&gt; shutdownNow(); /** * 如果此执行程序已关闭，则返回 true。 */ boolean isShutdown(); /** * 如果关闭后所有任务都已完成，则返回 true */ boolean isTerminated(); /** * 请求关闭、发生超时或者当前线程中断，无论哪一个首先发生之后，都将导致阻塞，直到所有任务完成执行 */ boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; /** * 提交一个返回值的任务用于执行，返回一个表示任务的未决结果的 Future */ &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); /** * 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future */ &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); /** * 提交可运行的任务以供执行，并返回未来的结果，并返回给给定结果 */ &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); /** * 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future */ Future&lt;?&gt; submit(Runnable task); /** * 执行给定的任务，当所有任务完成时，返回保持任务状态和结果的 Future 列表 */ &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; /** * 执行给定的任务，当所有任务完成或超时期满时（无论哪个首先发生），返回保持任务状态和结果的 Future 列表 */ &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; /** * 执行给定的任务，如果某个任务已成功完成（也就是未抛出异常），则返回其结果 */ &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; /** * 执行给定的任务，如果在给定的超时期满前某个任务已成功完成（也就是未抛出异常），则返回其结果 */ &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService接口概述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package java.util.concurrent;import java.util.List;import java.util.Collection;public interface ExecutorService extends Executor &#123;/** * 启动一次顺序关闭，执行以前提交的任务，但不接受新任务 */void shutdown();/** * 试图停止所有正在执行的活动任务，暂停处理正在等待的任务，并返回等待执行的任务列表 */List&lt;Runnable&gt; shutdownNow();/** * 如果此执行程序已关闭，则返回 true。 */boolean isShutdown();/** * 如果关闭后所有任务都已完成，则返回 true. */boolean isTerminated();/** * 请求关闭、发生超时或者当前线程中断，无论哪一个首先发生之后，都将导致阻塞，直到所有任务完成执行 */boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;/** * 提交一个返回值的任务用于执行，返回一个表示任务的未决结果的 Future */&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);/** * 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future */&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);/** * 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future */Future&lt;?&gt; submit(Runnable task);/** * 执行给定的任务，当所有任务完成时，返回保持任务状态和结果的 Future 列表 */&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;/** * 执行给定的任务，当所有任务完成或超时期满时（无论哪个首先发生），返回保持任务状态和结果的 Future 列表 */&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;/** * 执行给定的任务，如果某个任务已成功完成（也就是未抛出异常），则返回其结果 */&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;/** * 执行给定的任务，如果在给定的超时期满前某个任务已成功完成（也就是未抛出异常），则返回其结果 */&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; AbstractExecutorService类概述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196package java.util.concurrent;import java.util.*;public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); try &#123; // Record exceptions so that if we fail to obtain any // result, we can throw the last exception we got. ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // Start one task for sure; the rest incrementally futures.add(ecs.submit(it.next())); --ntasks; int active = 1; for (;;) &#123; Future&lt;T&gt; f = ecs.poll(); if (f == null) &#123; if (ntasks &gt; 0) &#123; --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; else if (active == 0) break; else if (timed) &#123; f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); &#125; else f = ecs.take(); &#125; if (f != null) &#123; --active; try &#123; return f.get(); &#125; catch (ExecutionException eex) &#123; ee = eex; &#125; catch (RuntimeException rex) &#123; ee = new ExecutionException(rex); &#125; &#125; &#125; if (ee == null) ee = new ExecutionException(); throw ee; &#125; finally &#123; for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout)); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; RunnableFuture&lt;T&gt; f = newTaskFor(t); futures.add(f); execute(f); &#125; for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; try &#123; f.get(); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; &#125; &#125; done = true; return futures; &#125; finally &#123; if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); final long deadline = System.nanoTime() + nanos; final int size = futures.size(); // Interleave time checks and calls to execute in case // executor doesn't have any/much parallelism. for (int i = 0; i &lt; size; i++) &#123; execute((Runnable)futures.get(i)); nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) return futures; &#125; for (int i = 0; i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; if (nanos &lt;= 0L) return futures; try &#123; f.get(nanos, TimeUnit.NANOSECONDS); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; catch (TimeoutException toe) &#123; return futures; &#125; nanos = deadline - System.nanoTime(); &#125; &#125; done = true; return futures; &#125; finally &#123; if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125;&#125; 抽象类，实现ExecutorService接口，为其提供默认实现。AbstractExecutorService除了实现ExecutorService接口外，还提供了两个newTaskFor()重载方法，一个支持Runnable任务，一个支持带有执行结果的Callable任务，执行后返回一个RunnableFuture，在运行的时候，它将调用底层可调用任务，作为 Future 任务，它将生成可调用的结果作为其结果，并为底层任务提供取消操作。 同时该抽象类也提供了两个submit()方法，一个只提交Runnable任务，一个提交Runnable的任务并将返回的未来的默认值封装到第二个返回参数中。 ScheduledExecutorService接口概述1234567891011121314151617181920212223242526package java.util.concurrent;public interface ScheduledExecutorService extends ExecutorService &#123; /** * 创建并执行在给定延迟后启用的 ScheduledFuture。 */ public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); /** * 创建并执行在给定延迟后启用的一次性操作。 */ public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable,long delay, TimeUnit unit); /** * 创建并执行一个在给定初始延迟后首次启用的定期操作，后续操作具有给定的周期； * 也就是将在 initialDelay 后开始执行，然后在 initialDelay+period 后执行，接着在 initialDelay+2* period 后执行，依此类推。 */ public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,long initialDelay, long period,TimeUnit unit); /** * 创建并执行一个在给定初始延迟后首次启用的定期操作，随后，在每一次执行终止和下一次执行开始之间都存在给定的延迟。 */ public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command,long initialDelay,long delay, TimeUnit unit);&#125; ThreadPoolExecutor类概述我们Java线程池主要是围绕ThreadPoolExecutor类展开的，后续会对ThreadPoolExecutor详解。 Executors类概述和ThreadPoolExecutor一样后续会详解，该类是线程池的静态工厂类，提供了Executor、ExecutorService、ScheduledExecutorService、ThreadFactory 、Callable 等类的静态工厂方法，通过这些工厂方法我们可以得到相对应的对象。 创建并返回设置有常用配置字符串的 ExecutorService 的方法。 创建并返回设置有常用配置字符串的 ScheduledExecutorService 的方法。 创建并返回“包装的”ExecutorService 方法，它通过使特定于实现的方法不可访问来禁用重新配置。 创建并返回 ThreadFactory 的方法，它可将新创建的线程设置为已知的状态。 创建并返回非闭包形式的 Callable 的方法，这样可将其用于需要 Callable 的执行方法中。 Future接口Future接口和实现Future接口的FutureTask代表了线程池的异步计算结果。 AbstractExecutorService提供了newTaskFor()方法返回一个RunnableFuture，除此之外当我们把一个Runnable或者Callable提交给（submit()）ThreadPoolExecutor或者ScheduledThreadPoolExecutor时，他们则会向我们返回一个FutureTask对象。如下： 1234567891011protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125;&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) Future&lt;&gt; submit(Runnable task) Future接口概述作为异步计算的顶层接口，Future对具体的Runnable或者Callable任务提供了三种操作：执行任务的取消、查询任务是否完成、获取任务的执行结果。其接口定义如下： 123456789101112131415161718192021222324252627282930313233package java.util.concurrent;public interface Future&lt;V&gt; &#123; /** * 试图取消对此任务的执行 * 如果任务已完成、或已取消，或者由于某些其他原因而无法取消，则此尝试将失败。 * 当调用 cancel 时，如果调用成功，而此任务尚未启动，则此任务将永不运行。 * 如果任务已经启动，则 mayInterruptIfRunning 参数确定是否应该以试图停止任务的方式来中断执行此任务的线程 */ boolean cancel(boolean mayInterruptIfRunning); /** * 如果在任务正常完成前将其取消，则返回 true */ boolean isCancelled(); /** * 如果任务已完成，则返回 true */ boolean isDone(); /** * 如有必要，等待计算完成，然后获取其结果 */ V get() throws InterruptedException, ExecutionException; /** * 如有必要，最多等待为使计算完成所给定的时间之后，获取其结果（如果结果可用） */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; RunnableFuture接口概述继承Future、Runnable两个接口，为两者的合体，即所谓的Runnable的Future。提供了一个run()方法可以完成Future并允许访问其结果，其源码如下： 123456package java.util.concurrent;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; //在未被取消的情况下，将此 Future 设置为计算的结果 void run();&#125; FutureTask接口概述实现RunnableFuture接口，既可以作为Runnable被执行，也可以作为Future得到Callable的返回值。 参考资料 《Java并发编程实战》 电子工业出版社 J.U.C之线程池：线程池的基础架构","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"【Java并发编程实战】-浅谈volatile内存可见性","slug":"【Java并发编程实战】-浅谈volatile内存可见性","date":"2018-06-03T02:11:44.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/06/03/【Java并发编程实战】-浅谈volatile内存可见性/","link":"","permalink":"http://ltyeamin.github.io/2018/06/03/【Java并发编程实战】-浅谈volatile内存可见性/","excerpt":"","text":"volatile这个关键字大家都听过，看过许多源码也用过，这个关键字备受争议，很多人基于表面理解而导致在实际开发过生中大肆误用，暴露出各式各样的问题，让人摸不着头脑，今天我们来好好理解一下volatile。 百度百科:volatile是一个类型修饰符.volatile的作用是作为指令关键字，确保本条指令不会因编译器的优化而省略，且要求每次直接读值; volatile是Java虚拟机提供的轻量级同步机制的关键字，使被修饰的变量在多个线程可见； volatile变量具有 synchronized 的可见性特性，与synchronize有相似的同步功能，但不具备原子特性，在多线程并发下是不安全的。 两种特性特性归纳当一个变量被定义成volatile之后，它将具备如下两种特性: 保证此变量对所有线程的可见性。即指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即感知的，而相比之下，普通变量不能做到这点，变量值在线程间传递均需要通过主内存来完成。比如线程1修改a的值，然后向主内存进行回写，另外一条线程2在线程1回写完成了之后再从主内存进行读取操作，新变量的值才会对线程2可见。 禁止指令重排序优化。普通变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这就是所谓的“线程内表现为串行的语义”(Within-Thread As-If-Serial Semantics)。 代码示例多线程并发安全12345678910111213141516171819202122232425262728293031323334353637383940/** * @author tong.li * @description: volatile只保证内存间线程可见性,并不保证线程安全性 * @date 2018-06-12 11:11:23 */public class VolatileTest &#123; //共享变量 public volatile int num = 0; //线程数量 public static final int THREAD_COUNT = 20; public void add() &#123; //num进行非原子操作 num++; &#125; public static void main(String[] args) &#123; final VolatileTest test = new VolatileTest(); //创建20个线程 Thread[] threads = new Thread[THREAD_COUNT]; for (int i = 0; i &lt; THREAD_COUNT ; i++) &#123; threads[i] = new Thread(() -&gt; &#123; //当前线程操作10000次对共享变量num进行自加操作 for (int j = 0; j &lt; 10000; j++) &#123; test.add(); &#125; &#125;); //启动当前线程 threads[i].start(); &#125; //活动线程的当前线程的线程组中的数量大于1时,执行线程让步,让活动的线程尽可能执行完 // while (Thread.activeCount() &gt; 1) &#123; // Thread.yield(); //&#125; //打印最终结果,结果多数小于200000,为什么呢? System.out.println(\"num = \" + test.num); &#125;&#125; 运行结果如下: 第1次 1num = 132203 第2次 1num = 160740 第3次 1num = 187482 上述代码创建20个线程，每个线程对num进行10000次自增操作，如果上述代码正确并发（不考虑线程安全问题）的情况下，最后的结果应该是200000，但是为实际三次运行结果令人匪夷所思，多次的运行结果大部分情况下都是小于200000，这是为什么呢？ 我们都知道num++是非原子性操作，我们可以尝试进行javap反编译上述代码一探究竟： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137Yeamin:java mac$ javap -c VolatileTestCompiled from \"VolatileTest.java\"public class VolatileTest &#123; public volatile int num; public static final int THREAD_COUNT; public VolatileTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: iconst_0 6: putfield #2 // Field num:I 9: return public void add(); Code: 0: aload_0 1: dup 2: getfield #2 // Field num:I 5: iconst_1 6: iadd 7: putfield #2 // Field num:I 10: return public static void main(java.lang.String[]); Code: 0: new #3 // class VolatileTest 3: dup 4: invokespecial #4 // Method \"&lt;init&gt;\":()V 7: astore_1 8: bipush 20 10: anewarray #5 // class java/lang/Thread 13: astore_2 14: iconst_0 15: istore_3 16: iload_3 17: bipush 20 19: if_icmpge 52 22: aload_2 23: iload_3 24: new #5 // class java/lang/Thread 27: dup 28: new #6 // class VolatileTest$1 31: dup 32: aload_1 33: invokespecial #7 // Method VolatileTest$1.\"&lt;init&gt;\":(LVolatileTest;)V 36: invokespecial #8 // Method java/lang/Thread.\"&lt;init&gt;\":(Ljava/lang/Runnable;)V 39: aastore 40: aload_2 41: iload_3 42: aaload 43: invokevirtual #9 // Method java/lang/Thread.start:()V 46: iinc 3, 1 49: goto 16 52: invokestatic #10 // Method java/lang/Thread.activeCount:()I 55: iconst_1 56: if_icmple 65 59: invokestatic #11 // Method java/lang/Thread.yield:()V 62: goto 52 65: getstatic #12 // Field java/lang/System.out:Ljava/io/PrintStream; 68: new #13 // class java/lang/StringBuilder 71: dup 72: invokespecial #14 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 75: ldc #15 // String num = 77: invokevirtual #16 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 80: aload_1 81: getfield #2 // Field num:I 84: invokevirtual #17 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 87: invokevirtual #18 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 90: invokevirtual #19 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 93: return&#125; 在上述反编译的字节码分析得知，num++不是一个原子操作，即线程不安全，可以将num++简单分解成以下几个步骤: 从内存中取出num的值； 计算num的值； 将num的值刷新到主内存中 add()方法有6条指令（每个指令可能含有多个底层指令操作，只为研究，并不准确，要想准确研究建议使用-XX:+PrintAssembly参数输出反汇编），其中return指令可以忽略不计，因为不是num++产生的。 aload_0：在非静态方法中，aload_0 表示对this的操作，在static 方法中，aload_0表示对方法的第一参数的操作； dup：复制操作数栈顶值，并将其压入栈顶，在这里是将当前VolatileTest下new对象压入栈顶； getfield/getstatic：将栈顶的对象第二个实例字段压入栈顶，即将num的值压入栈顶，此时num的值是最新的； iconst_1：将int型(1)推送至栈顶，即把常量1压入栈顶； iadd：把操作数栈中的前两个int值出栈并相加,操作过后只在stack中保留结果，即使num当前值+1保留在栈中，这里多线程时候可能出现问题，其他线程相加的结果会覆盖当前栈顶的结果，因而返回较小的结果。 putfield：将最终的栈顶结果的值刷新到主内存中； return：栈中的数据返回后，结束方法 禁止指令重排序volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 举个实例，请看下面的代码: 1234567//x、y为非volatile变量//flag为volatile变量int x = 2; //语句1int y = 0; //语句2volatile boolean flag = true; //语句3int x = 4; //语句4int y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 我们在看看一个例子: 12345678//线程1:ApplicationConext context = loadContext(); //语句1boolean inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上述代码有可能语句2会在语句1之前执行，因为语句2并不依赖依赖语句2，可能会重排序优化，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 对变量特殊的定义规则假设T表示一个线程，V和W表示两个volatile变量，那么在进行read、load、use、assign、store和write操作时需要满足如下的规则: 只有一个当线程T对变量V执行的前一个动作是load的时候，T才能对变量V执行use动作，并且当对V的后一个执行是use动作时，T才能对V执行load动作。T对V的use动作其实是衔接T对V的load和read动作，load、read必须一起连续出现（这条规则要求在工作内存每次使用V前都必须先从主内存刷新最新值，使得保证能看见其他线程对变量V的最新更改）。 只有一个当线程T对变量V执行的前一个动作是assign的时候，T才能对变量V执行store动作，并且当对V的后一个执行是store动作时，T才能对V执行assign动作。T对V的assign动作其实是衔接T对V的store和write动作，store、write必须一起连续出现（这条规则要求在工作内存每次修改V后都必须先必须同步到主内中，使得保证其他线程能看见TT对变量V的最新更改）。 假设动作A是线程T对变量VV实施的use或assign动作，假定动作F是与动作A相关联的load和store动作，假定动作PP是与动作FF相应的对V的read和load动作；类似地，假定动作B是线程TT对变量W实施的use和assign动作，假定动作GG是和动作BB相关联的load或store动作，假定动作Q是与动作G相应的对变量W的read和write动作。如果A先于B，那么P先于Q（这条规则要求volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同），即是Happen-before原则。 内存屏障其volatile原理内存屏障定义在研究volatile原理时候，我们来谈谈内存屏障或者内存栅栏。 内存屏障/内存栅栏(Memory Barrier或Menory Fence):重排序时不能把后面的指令重排序到内存屏障之前的位置，指令重排序无法越过内存屏障，单例模式的DCL双锁检查可以体现出来。 只有一个CPU访问内存时，并不需要内存屏障，但如果有多个CPU访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致。 从硬件架构上讲，指令重排序是指CPU采取可允许将多条指令不按程序规定的顺序分开发送给各相应单路处理单元。但并不是指令任意重排，CPU需要能正确处理指令依赖情况以保障程序能够得出正确的执行结果。 由于现代的操作系统都是多处理器.而每一个处理器都有自己的缓存,并且这些缓存并不是实时都与内存发生信息交换.这样就可能出现一个cpu上的缓存数据与另一个cpu上的缓存数据不一致的问题。而这样在多线程开发中，就有可能导致出现一些异常行为。而操作系统底层为了这些问题，提供了一些内存屏障用以解决这样的问题，目前有4种屏障： LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。 内存屏障JAVA应用 通过 Synchronized关键字包住的代码区域,当线程进入到该区域读取变量信息时，保证读到的是最新的值。这是因为在同步区内对变量的写入操作，在离开同步区时就将当前线程内的数据刷新到内存中,而对数据的读取也不能从缓存读取,只能从内存中读取,保证了数据的读有效性，这就是插入了StoreStore屏障。 使用了volatile修饰变量,则对变量的写操作，会插入StoreLoad屏障。 其余的操作,则需要通过Unsafe这个类来执行。UNSAFE.putOrderedObject类似这样的方法,会插入StoreStore内存屏障，Unsafe.putVolatiObject 则是插入了StoreLoad屏障 适用场景 由于volatile变量只保证可见性,在不符合以下两点，我们仍然要通过加锁(使用同步锁synchronize或java.util.concurrent中的原子类)来保证原子性。 运算结果以及对变量的写操作并不依赖变量的当前值，或能够确保只有单一的线程修改变量的值； 变量不需要与其他的状态变量共享参与不变约束； 适用于读多写少的场景; 可用作状态标志。 JDK中volatie应用：JDK中ConcurrentHashMap的Node的val和next被声明为volatile，AtomicInteger等原子类中的value被声明为volatile。AtomicInteger通过CAS原理(暂可理解为乐观锁)保证了原子性。这些应用后文讲解。 volatile与synchronized上述说到的volatile的语义问题，其实volatile变量读操作的性能与普通变量几乎没有什么差别，但是写操作会稍慢点，因为volatile需要在执行中插入许多内存屏障指令来保证处理器不发生乱序执行。 在某些情况下volatile的同步机制的性能的确要优于锁(synchronize同步锁或J.U.C包的锁)，但是JDK1.6以后对锁实行了许多消除和优化，使得我们很难量化认为volatile比锁快多少。 多线程访问volatile不会发生阻塞，而synchronized会阻塞； volatile只能保证数据的可见性，不能保证原子性，而synchronized两者都可以保证，因为它会将私有内存和公共内存中的数据做同步 对long和double型变量的特殊规则内存的八个操作虽然说都是原子性的，但是对于64位的数据类型：long和double来讲，允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，这就是所谓的long和double的非原子性协定。虽然规定为规定，但是目前大部分商业虚拟机将这两种数据类型作64位的原子性操作对待，因为我们不需要将long和double类型的变量专门什么为volatile变量。 参考资料 《深入理解Java虚拟机（第2版）》周志明著 《Java多线程编程核心技术》高洪岩著","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"【Java并发编程实战】-Java内存模型","slug":"【Java并发编程实战】-Java内存模型","date":"2018-06-01T10:09:51.000Z","updated":"2019-11-20T15:08:57.693Z","comments":true,"path":"2018/06/01/【Java并发编程实战】-Java内存模型/","link":"","permalink":"http://ltyeamin.github.io/2018/06/01/【Java并发编程实战】-Java内存模型/","excerpt":"","text":"硬件的效率与一致性计算机内部运算流程 计算机执行若干个运算任务，所有的计算任务不可能仅仅靠处理器“计算”来完成，计算器存储设备与处理器的运算速度有几个数量级的差距； 至少要与内存进行交互，如读取运算数据、存储运算结果，不能仅仅靠CPU寄存器来完成 随着计算机硬件的快速发展，任何设备的读写速度要尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲； 运算时先从内存读取，然后将数据缓存到高速缓存区，让CPU能够高效运算，当运算结束后，将运算结果从缓存中同步到内存中。 缓存一致性高速缓存很好的解决了处理器与内存的速度矛盾，如图1,但是存在问题:缓存一致性问题 多处理器中，每个处理器都有自己的高速缓存，但是又共享一个主内存，可能存在缓存数据不一致，同步到主内存不知道以哪个缓存数据为准； 为了解决一致性问题，各个处理器访问要遵循某些协议，在读写时要根据协议来进行操作，常见协议有:MSI、MESI、MOSI、Synapse、Firefly及Dragon Protocol等； 除了增加高速缓存之外，为了使得处理器内部的运算单元尽量被充分利用，处理器会在不影响执行结果的条件下对输入的代码进行乱序执行，Java虚拟机定义为指令重排序。 Java内存模型Java内存模型（JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现Java程序在各种下都能达到一致的并发效果，在JDK1.5（实现了JSR-133）发布后，JMM已经成熟和完善起来。 Java内存的主要目标是定义程序中的各个变量的访问规则，即虚拟机中将变量存储到内存和从内存中取出变量主要的底层实现，需要注意的是此变量非彼变量，这里的变量包括实例字段、静态字段、构成数组对象的元素，不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然不存在竞争问题。 主内存与工作内存 主内存: JMM规定所有的变量都存储在主内存中； 工作内存：每条线程都有自己的工作内存，线程的工作内存保存了被该线程使用到的变量的主内存副本拷贝； 工作内存：线程对变量的所以操作都必须在工作内存中进行，不能直接读写到主内存中； 工作内存：线程间各自的工作内存不可见，数据传递操作在主内存来完成，如图2，线程、主内存、工作内存三者之间的交互关系。 内存间原子操作 锁定（lock）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态； 解锁（unlock）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定； 读取（read）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用； 载入（load）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中； 使用（use）：作用于工作内存的变量，它把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作； 赋值（assign）：作用于工作内存的变量，它把从执行引擎接受到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作； 存储（store）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用； 写入（write）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 如果要把一个变量从主内存复制到工作内存，那就要按照顺序地执行read和load操作，如果要把变量从工作内存同步回主存，就要按顺序地执行store和write操作。需要注意的是，JMM只要求上述两个操作必须按顺序执行，而没有保证必须是连续执行的。也就说说read与load之间、store和write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，很可能出现read a、read b、load b、load a，除此之外，JMM还规定在执行上述八种操作时必须满足如下规则： 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写但主内存不接受的情况出现； 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化的结果回写到主内存中； 不允许任何一个线程无原因地（没有发生过任何的assign操作）把数据从线程的工作内存同步回主内存中； 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即对一个变量实施use和store操作之前，必须先执行过assign和load操作； 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会解锁； 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值； 如果一个变量事先没有被lock锁定操作，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁住的变量； 对一个变量执行unlock之前，必须先把此变量同步回主内存中（执行store和write操作）； happens-before 原则这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地 解决并发环境下两个操作之间是否可能存在冲突的所有问题。 现在就来看看“先行发生”原则指的是什么。先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 123456//以下操作在线程A中执行int i=1;//以下操作在线程B中执行 int j=i;//以下操作在线程C中执行int i=2; 通过上述代码分析:假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原 则，“i=1”的结果可以被观察到；二是线程C还没“登场”，线程A操作结束之后没有其他线程会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关 系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。 Java 内存模型定义基于一些操作，比如读写字段、 Monitor 同步等。这些操作可以按照 happens-before 关系进行排序。这种关系可用来推断一个线程何时看到另一个线程的操作结果，以及构成一个程序同步后的所有信息。 天然的先行发生关系: 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序， 因为要考虑分支、循环等结构。 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock 操作。即在获取 Monitor 前，释放该 Monitor。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。 volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，即在读取 volatile 变量前，对该变量执行一次写操作，这里的“后面”同样是指时间上的先后顺序。 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。即在线程开始所有操作前调用 Thread#start。 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有 中断发生。 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发 生于它的finalize()方法的开始。 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 总结:：时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准。 原子性、可见性和有序性原子性（Atomicity）：我们大致可以认为基本数据类型的访问读写是具备原子性的（例外就是long和double的非原子性协定）。原子操作的特点是要么全部操作成功要么全部操作失败，不允许部分成功，部分失败。尽管虚拟机未把lock和unlock操作直接开放给用户使用， 但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字，因此在synchronized块之间的操作也具备原子性。 可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即 得知这个修改。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的。简单说就是一个线程看到另一个线程发生更改所需的条件，即synchronized和final实现了可见性的条件。 有序性（Ordering）：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表 现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象 和“工作内存与主内存同步延迟”现象。 参考资料 《深入理解Java虚拟机（第2版）》周志明著","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"JVM及并发编程","slug":"JVM及并发编程","permalink":"http://ltyeamin.github.io/tags/JVM及并发编程/"}]},{"title":"项目团队协作流程","slug":"项目团队协作流程","date":"2018-05-24T12:41:18.000Z","updated":"2019-11-20T15:08:58.973Z","comments":true,"path":"2018/05/24/项目团队协作流程/","link":"","permalink":"http://ltyeamin.github.io/2018/05/24/项目团队协作流程/","excerpt":"","text":"在公司IT部门里,各个团队(产品设计团队-UI/UE设计师-前端工程师-移动端工程师-后端工程师-测试工程师-运维工程师)互相协作,共同达到项目上线的目的.如果一个公司的IT部门人员管理以及项目开发流程不太完善,就会导致一些问题,比如扯皮无界和沟通低效等问题,这些严重影响到工作效率,打破了项目的生命周期.那么真正的团队协作应该是怎么样的呢?我们不妨看下图:针对上述的流程图,读者可根据自己公司的实际情况,来发表留言评论,笔者很高兴与各位小伙伴来探讨此事.","categories":[{"name":"pm","slug":"pm","permalink":"http://ltyeamin.github.io/categories/pm/"}],"tags":[{"name":"Team Building","slug":"Team-Building","permalink":"http://ltyeamin.github.io/tags/Team-Building/"}]},{"title":"Spring Cloud-Zuul核心过滤器及异常处理","slug":"Spring Cloud-Zuul核心过滤器及异常处理","date":"2018-05-24T02:18:00.000Z","updated":"2019-11-20T15:08:57.398Z","comments":true,"path":"2018/05/24/Spring Cloud-Zuul核心过滤器及异常处理/","link":"","permalink":"http://ltyeamin.github.io/2018/05/24/Spring Cloud-Zuul核心过滤器及异常处理/","excerpt":"","text":"百家技术,谈笑古今.今天我们不讲三国,我们讲一讲微服务网关中的一些细节:Zuul过滤器. Zuul过滤器Spring Cloud中的Zuul为我们提供了统一对外,路由转发和过滤拦截的强大功能.在Spring Cloud Zuul中实现的过滤器必须包含4个基本特征:过滤类型,执行顺序,执行条件,具体操作.这些特征就是ZuulFilter抽象类中的4个抽象方法.话不多说,直接用ZuulFilter源码说事:12345678public abstract class ZuulFilter implements IZuulFilter, Comparable&amp;lt;ZuulFilter&amp;gt; &#123; abstract public String filterType(); abstract public int filterOrder(); /**IZuulFilter接口中的方法*/ boolean shouldFilter(); /**IZuulFilter接口中的方法*/ Object run();&#125; 以上方法与功能解说: filterType: 过滤器类型,就是特殊的字符串(可在FilterConstants接口常量中找到).Zuul中定义了4个不同生命周期的过滤器类型,具体如下: pre: 可以在请求被路由之前调用 routing: 在路由请求时候被调用 post: 在routing和error过滤器之后被调用 error: 处理请求时发生错误时被调用 filterOrder: 通过int值来定义过滤器的执行顺序,数值越小优先级越高 shouldFilter: 返回一个boolean类型来判断该过滤器是否要执行,我们可以通过此方法来指定过滤器的有效范围. run: 过滤器的具体逻辑,在该函数中,我们可以实现自定义的过滤逻辑,来确定是否要拦截当前的请求,不对其进行后续的路由,或是在请求路由返回结果之后,对处理结果做一些加工等.请求生命周期Zuul默认定义了四个不同的过滤器类型,它们覆盖了一个外部HTTP请求到达API网关,直到返回请求结果的全部生命周期.下图源自Zuul的官方WIKI中关于请求生命周期的图解,它描述了一个HTTP请求到达API网关之后,在不同类型过滤器之间的处理过程. 当外部HTTP请求到达API网关服务时,会进入第一个阶段pre,此时执行pre类型的过滤器,该类型的过滤器主要进行前置加工,比如请求校验等. 当pre阶段执行完毕后进入routing请求转发阶段,此时执行routing类型的过滤器,该类型的过滤器主要处理将外部的请求转发到具体服务实例的过程,当服务将请求结果都返回后,routing阶段才算完成. 当routing阶段执行完毕后进入post阶段,此时执行post类型的过滤器,该类型的过滤器不仅可以获取到请求信息,也可以获取服务实例返回的响应信息,这样我们可以对结果进行加工转化. 当以上3个过滤器中发生异常时才触发,最后还是流向post类型的过滤器,因为它需要将最终结果返回给客户端. 核心过滤器在Spring Cloud Zuul中,为了我们方便,它在请求过程中给我们默认实现了一大堆不同类型的核心过滤器,它在GateWay服务启动的时候自动加载启用.从spring-cloud-netflix-core-1.3.1模块下的org.springframework.cloud.netflix.zuul.filters包下:如上图,官方提供了三个不同生命周期的过滤器,理解这些过滤器处理流程有助于我们更加深入地定制自身系统过滤器. pre过滤器 ServletDetectionFilter: 它的执行顺序为-3,是最先被执行的过滤器.该过滤器总是会被执行,主要用来检测当前请求是通过Spring的DispatcherServlet处理运行,还是通过ZuulServlet来处理运行的.它的检测结果会以布尔类型保存在当前请求上下文的isDispatcherServletRequest参数中,这样在后续的过滤器中,我们就可以通过RequestUtils.isDispatcherServletRequest()和RequestUtils.isZuulServletRequest()方法判断它以实现做不同的处理.一般情况下,发送到API网关的外部请求都会被Spring的DispatcherServlet处理,除了通过/zuul/路径访问的请求会绕过DispatcherServlet,被ZuulServlet处理,主要用来应对处理大文件上传的情况.另外,对于ZuulServlet的访问路径/zuul/,我们可以通过zuul.servletPath参数来进行修改. Servlet30WrapperFilter: 它的执行顺序为-2,是第二个执行的过滤器.目前的实现会对所有请求生效,主要为了将原始的HttpServletRequest包装成Servlet30RequestWrapper对象. FormBodyWrapperFilter: 它的执行顺序为-1,是第三个执行的过滤器.该过滤器仅对两种类请求生效,第一类是Content-Type为application/x-www-form-urlencoded的请求,第二类是Content-Type为multipart/form-data并且是由Spring的DispatcherServlet处理的请求(用到了ServletDetectionFilter的处理结果).而该过滤器的主要目的是将符合要求的请求体包装成FormBodyRequestWrapper对象. DebugFilter: 它的执行顺序为1,是第四个执行的过滤器.该过滤器会根据配置参数zuul.debug.request和请求中的debug参数来决定是否执行过滤器中的操作.而它的具体操作内容则是将当前的请求上下文中的debugRouting和debugRequest参数设置为true.由于在同一个请求的不同生命周期中,都可以访问到这两个值,所以我们在后续的各个过滤器中可以利用这两值来定义一些debug信息,这样当线上环境出现问题的时候,可以通过请求参数的方式来激活这些debug信息以帮助分析问题.另外,对于请求参数中的debug参数,我们也可以通过zuul.debug.parameter来进行自定义. PreDecorationFilter: 它的执行顺序为5,是pre阶段最后被执行的过滤器.该过滤器会判断当前请求上下文中是否存在forward.to和serviceId参数,如果都不存在,那么它就会执行具体过滤器的操作(如果有一个存在的话,说明当前请求已经被处理过了,因为这两个信息就是根据当前请求的路由信息加载进来的).而它的具体操作内容就是为当前请求做一些预处理,比如: 进行路由规则的匹配,在请求上下文中设置该请求的基本信息以及将路由匹配结果等一些设置信息等,这些信息将是后续过滤器进行处理的重要依据,我们可以通过RequestContext.getCurrentContext()来访问这些信息.另外,我们还可以在该实现中找到一些对HTTP头请求进行处理的逻辑,其中包含了一些耳熟能详的头域,比如: X-Forwarded-Host,X-Forwarded-Port.另外,对于这些头域的记录是通过zuul.addProxyHeaders参数进行控制的,而这个参数默认值为true,所以Zuul在请求跳转时默认地会为请求增加X-Forwarded-*头域,包括: X-Forwarded-Host,X-Forwarded-Port,X-Forwarded-For,X-Forwarded-Prefix,X-Forwarded-Proto.我们也可以通过设置zuul.addProxyHeaders=false关闭对这些头域的添加动作. route过滤器 RibbonRoutingFilter：它的执行顺序为10,是route阶段第一个执行的过滤器.该过滤器只对请求上下文中存在serviceId参数的请求进行处理,即只对通过serviceId配置路由规则的请求生效.而该过滤器的执行逻辑就是面向服务路由的核心,它通过使用Ribbon和Hystrix来向服务实例发起请求,并将服务实例的请求结果返回. SimpleHostRoutingFilter：它的执行顺序为100,是route阶段第二个执行的过滤器.该过滤器只对请求上下文中存在routeHost参数的请求进行处理,即只对通过url配置路由规则的请求生效.而该过滤器的执行逻辑就是直接向routeHost参数的物理地址发起请求,从源码中我们可以知道该请求是直接通过httpclient包实现的,而没有使用Hystrix命令进行包装,所以这类请求并没有线程隔离和断路器的保护. SendForwardFilter：它的执行顺序为500,是route阶段第三个执行的过滤器.该过滤器只对请求上下文中存在forward.to参数的请求进行处理,即用来处理路由规则中的forward本地跳转配置. post过滤器 SendErrorFilter：它的执行顺序为0,是post阶段第一个执行的过滤器.该过滤器仅在请求上下文中包含error.status_code参数(由之前执行的过滤器设置的错误编码)并且还没有被该过滤器处理过的时候执行.而该过滤器的具体逻辑就是利用请求上下文中的错误信息来组织成一个forward到API网关/error错误端点的请求来产生错误响应. SendResponseFilter：它的执行顺序为1000,是post阶段最后执行的过滤器.该过滤器会检查请求上下文中是否包含请求响应相关的头信息,响应数据流或是响应体,只有在包含它们其中一个的时候就会执行处理逻辑.而该过滤器的处理逻辑就是利用请求上下文的响应信息来组织需要发送回客户端的响应内容. 自定义filter及异常处理1234567891011121314151617181920212223242526272829303132package cn.yeamin.gateway.filter;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants;import org.springframework.stereotype.Component;import com.netflix.zuul.ZuulFilter;@Componentpublic class ThrowExceptionFilter extends ZuulFilter &#123; private static final Logger log = LoggerFactory.getLogger(ThrowExceptionFilter.class); @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; log.info(\"我在这就是要为难你,给你抛出一个异常,看你能拿我能怎么样,哈哈......\"); doSomething(); return null; &#125; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return 0; &#125; private void doSomething() &#123; throw new RuntimeException(\"伙计,对不住了,给你制造一些麻烦......\"); &#125;&#125; 注释掉run()方法中的doSomething();这一行,进行请求,以前正常1234567891011Administrator@EZ-20161212OKBJ MINGW64 ~/Desktop$ curl -i http://127.0.0.1:9005/item-service/item/2 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 91 0 91 0 0 91 0 --:--:-- --:--:-- --:--:-- 91000HTTP/1.1 200X-Application-Context: api-gateway:9005date: Thu, 24 May 2018 06:16:41 GMTContent-Type: application/json;charset=UTF-8Transfer-Encoding: chunked&#123;&quot;id&quot;:2,&quot;title&quot;:&quot;商品标题2&quot;,&quot;pic&quot;:&quot;http://图片2&quot;,&quot;desc&quot;:&quot;商品描述2&quot;,&quot;price&quot;:2000&#125; 打开注释后,进行请求,返回500错误,如下结果:12345678Administrator@EZ-20161212OKBJ MINGW64 ~/Desktop$ curl -v http://127.0.0.1:9005/item-service/item/2* Trying 127.0.0.1...* TCP_NODELAY set % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Connected to 127.0.0.1 (127.0.0.1) port 9005 (#0)&#123;&quot;timestamp&quot;:1527143000184,&quot;status&quot;:500,&quot;error&quot;:&quot;Internal Server Error&quot;,&quot;exception&quot;:&quot;com.netflix.zuul.exception.ZuulException&quot;,&quot;message&quot;:&quot;pre:ThrowExceptionFilter&quot;&#125; 由上可见,我们虽然能够清晰看到status为500,error的描述,exception的class信息,message信息,但是作为我们开发人员并不知道为什么而异常,准确来说,异常信息不够准确.针对以上方案有两种方案:严格的try-catch处理和ErrorFilter处理1.方式一: 严格的try-catch处理回想一下,我们有一个post过滤器SendErrorFilter,它是用来处理异常信息的.根据正常流程,该过滤器会处理异常信息,那么在这里没有出现较为明确的异常信息很有可能是这个过滤器没有执行.所以我们不妨来看看SendErrorFilter的源码:12345678910public class SendErrorFilter extends ZuulFilter &#123; @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); // only forward to errorPath if it hasn't been forwarded to already return ctx.getThrowable() != null &amp;&amp; !ctx.getBoolean(SEND_ERROR_FILTER_RAN, false); &#125;&#125; 从上面源码分析,shouldFilter()方法中,可得知:ctx.getThrowable() != null说明请求上下文必须有个Throwable子类的异常对象,我们自己实现的时候并没有将异常对象放入上下文,SendErrorFilter自然不会执行.分析过后我们就明白了,具体怎么解决可以参考RibbonRoutingFilter中run方法异常处理逻辑实现:1234567891011121314151617@Overridepublic Object run() &#123; RequestContext context = RequestContext.getCurrentContext(); this.helper.addIgnoredHeaders(); try &#123; RibbonCommandContext commandContext = buildCommandContext(context); ClientHttpResponse response = forward(commandContext); setResponse(response); return response; &#125; catch (ZuulException ex) &#123; throw new ZuulRuntimeException(ex); &#125; catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125;&#125; 参考之后,我们也可以仿照以上代码解决我们的问题:12345678910@Overridepublic Object run() &#123; try &#123; log.info(\"我在这就是要为难你,给你抛出一个异常,看你能拿我能怎么样,哈哈......\"); doSomething(); &#125;catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125; return null;&#125; 改好代码我们访问一下,就有了详细的异常信息:12345678Administrator@EZ-20161212OKBJ MINGW64 ~/Desktop$ curl -v http://127.0.0.1:9005/item-service/item/2* Trying 127.0.0.1...* TCP_NODELAY set % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Connected to 127.0.0.1 (127.0.0.1) port 9005 (#0)&#123;&quot;timestamp&quot;:1527145922072,&quot;status&quot;:500,&quot;error&quot;:&quot;Internal Server Error&quot;,&quot;exception&quot;:&quot;com.netflix.zuul.exception.ZuulException&quot;,&quot;message&quot;:&quot;伙计,对不住了,给你制造一些麻烦......&quot;&#125; 2.方式二: ErrorFilter处理12345678910111213141516171819202122232425262728293031323334353637383940package cn.yeamin.gateway.filter;import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants;import org.springframework.stereotype.Component;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;/** * Zuul过滤器统一异常处理 * * @author tong.li * */@Componentpublic class ErrorFilter extends ZuulFilter &#123; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); Throwable throwable = ctx.getThrowable(); Throwable ex = throwable.getCause(); ctx.setThrowable(ex); return null; &#125; @Override public String filterType() &#123; return FilterConstants.ERROR_TYPE; &#125; @Override public int filterOrder() &#123; return -1; &#125;&#125; 注释掉之前的try-catch的处理方式,然后我们再访问:123456Administrator@EZ-20161212OKBJ MINGW64 ~/Desktop$ curl http://127.0.0.1:9005/item-service/item/2 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 190 0 190 0 0 63 0 --:--:-- 0:00:03 --:--:-- 57&#123;&quot;timestamp&quot;:1527148417550,&quot;status&quot;:500,&quot;error&quot;:&quot;Internal Server Error&quot;,&quot;exception&quot;:&quot;com.netflix.zuul.exception.ZuulException&quot;,&quot;message&quot;:&quot;伙计,对不住了,给你制造一些麻烦......&quot;&#125;","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ltyeamin.github.io/tags/Spring-Cloud/"}]},{"title":"Linux基础-正则表达式之三剑客","slug":"Linux基础-正则表达式之三剑客","date":"2018-05-22T13:27:23.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/05/22/Linux基础-正则表达式之三剑客/","link":"","permalink":"http://ltyeamin.github.io/2018/05/22/Linux基础-正则表达式之三剑客/","excerpt":"","text":"Linux的世界里一切皆文件,对Linux的操作就是对文件的处理.被业界称为”三剑客”的awk,sed,grep就能够帮助我们更方便更高效的处理文件.“三剑客”中grep擅长查找功能,sed擅长取行和替换,awk擅长取列.“三剑客”就是普通的Linux命令,而正则表达式好比一个模板,两者结合使用,能够发挥巨大的作用,尤其是在Shell脚本中,使我们的代码短小精悍.总之就是一句话:提高工作效率. 正则表达式字符串:”abcaxc”,正则表达式为:ab.*c 贪婪模式: 编程中默认模式,正则表达式一般趋向于最大长度[匹配.如正则ab.*c最大匹配为:abcaxc 非贪婪模式: 正则匹配到结果就好,说白了就是最少匹配.如正则ab.*c最大匹配为:abc grep命令grep命令是一种强大的文本搜索工具,它能使用特定模式匹配(包括正则表达式)搜索文本,并默认输出匹配行.unix的grep家族包括grep,egrep和fgrep,笔者在这不一一列举了,读者可自行研究.常用选项 -c : 计算找到’搜寻字符串’的次数 -i : 忽略大小写进行搜索 -n : 顺便输出行号 -v : 反向选择,取反搜索 -color=auto : 可以找到的搜索关键字加上颜色显示 实战示例1.通过管道查找配置文件里的字符12[root@litong ~]# cat server.conf | grep portport : 9001 2.通过管道查找以*.conf结尾的文件12[root@litong ~]# ll | grep *.conf-rw-r--r-- 1 root root 22 May 18 14:51 server.conf 3.根据关键字查找进程信息123[root@litong ~]# ps -ef | grep pptpdroot 29510 1 0 14:55 ? 00:00:00 /usr/sbin/pptpd -froot 30061 25475 0 14:58 pts/2 00:00:00 grep --color=auto pptpd sed命令sed是一项Linux指令,功能同awk类似,差别在于,sed简单,擅长取行和替换,对列处理的功能要差一些,awk的功能复杂,对列处理的功能比较强大. 命令格式 sed [options] ‘command’ file(s) sed [options] -f scriptfile file(s)取行选项 a\\ 在当前行下面插入文本. i\\ 在当前行上面插入文本. c\\ 把选定的行改为新的文本. d 删除,删除选择的行. D 删除模板块的第一行. s 替换指定字符 h 拷贝模板块的内容到内存中的缓冲区. H 追加模板块的内容到内存中的缓冲区. g 获得内存缓冲区的内容,并替代当前模板块中的文本. G 获得内存缓冲区的内容,并追加到当前模板块文本的后面. l 列表不能打印字符的清单. n 读取下一个输入行,用下一个命令处理新的行而不是用第一个命令. N 追加下一个输入行到模板块后面并在二者间嵌入一个新行,改变当前行号码. p 打印模板块的行. P(大写) 打印模板块的第一行. q 退出Sed. b lable 分支到脚本中带有标记的地方,如果分支不存在则分支到脚本的末尾. r file 从file中读行. t label if分支,从最后一行开始,条件一旦满足或者T,t命令,将导致分支到带有标号的命令处,或者到脚本的末尾. T label 错误分支,从最后一行开始,一旦发生错误或者T,t命令,将导致分支到带有标号的命令处,或者到脚本的末尾. w file 写并追加模板块到file末尾. W file 写并追加模板块的第一行到file末尾. ! 表示后面的命令对所有没有被选定的行发生作用. = 打印当前行号码. # 把注释扩展到下一个换行符以前. 替换选项 g 表示行内全面替换. p 表示打印行. w 表示把行写入一个文件. x 表示互换模板块中的文本和缓冲区中的文本. y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \\1 子串匹配标记 &amp; 已匹配字符串标记实战示例 获取文件的行内容123456789[root@litong ~]# sed -n 2p /etc/passwd # 获取/ect/passwd第二行bin:x:1:1:bin:/bin:/sbin/nologin[root@litong ~]# sed -n 2,7p /etc/passwd # 获取/ect/passwd第二行到第七行bin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 2.替换文本123456[root@litong ~]# sed -i &apos;s/port/pp/g&apos; server.conf # 文件中含有port为全局替换pp,,并不会真正进行文件替换,而只是把操作后的文本返回[root@litong ~]# cat server.conf serverserver pp : 9001 pp : 9001 3.删除文本12345[root@litong ~]# sed &apos;2d&apos; server.conf # 删除文件的第二行,并不会真正删除文件行,而只是把操作后的文本返回server pp : 9001 pp : 9001[root@litong ~]# sed &apos;1,$d&apos; server.conf #文件清空,,并不会真正删除文件行,而只是把操作后的文本返回 awk命令awk是一个优良的文本处理工具,Linux及Unix环境中现有的功能最强大的数据处理引擎之一.这个命令擅长取列.awk经过改进生成新的版本nawk和gawk,现在默认linux系统下日常使用gawk. 命令格式 awk [选项参数] ‘script’ var=value file(s) awk [选项参数] -f scriptfile var=value file(s) 选项参数 -F fs or –field-separator fs :指定输入文件折分隔符,fs是一个字符串或者是一个正则表达式,如-F:. -v var=value or –asign var=value赋值一个用户定义变量. -f scripfile or –file scriptfile,从脚本文件中读取awk命令. -mf nnn and -mr nnn,对nnn值设置内在限制,-mf选项限制分配给nnn的最大块数目;-mr选项限制记录的最大数目.这两个功能是Bell实验室版awk的扩展功能,在标准awk中不适用. -W compact or –compat, -W traditional or –traditional,在兼容模式下运行awk.所以gawk的行为和标准的awk完全一样,所有的awk扩展都被忽略. -W copyleft or –copyleft, -W copyright or –copyright,打印简短的版权信息. -W help or –help, -W usage or –usage,打印全部awk选项和每个选项的简短说明. -W lint or –lint,打印不能向传统unix平台移植的结构的警告. -W lint-old or –lint-old,打印关于不能向传统unix平台移植的结构的警告. -W posix,打开兼容模式.但有以下限制,不识别：/x,函数关键字,func,换码序列以及当fs是一个空格时,将新行作为一个域分隔符;操作符和=不能代替^和^=;fflush无效. -W re-interval or –re-inerval,允许间隔正则表达式的使用,参考(grep中的Posix字符类),如括号表达式[[:alpha:]]. -W source program-text or –source program-text,使用program-text作为源代码,可与-f命令混用. -W version or –version,打印bug报告信息的版本. 实战示例1.按照指定的分隔符取列 1234567891011121314151617181920[root@litong ~]# cut -d: -f 1 /etc/passwd # cut命令也可以取列rootbindaemonadmlpsyncshutdownhaltmail[root@litong ~]# awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd # awk命令取列rootbindaemonadmlpsyncshutdownhaltmail 企业实战-用三剑客取IP1234567891011121314151617181920[root@litong ~]# ifconfig eth0 #查看eth0这块网卡的ipeth0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.21.205.254 netmask 255.255.240.0 broadcast 172.21.207.255 ether 00:16:3e:00:a1:e1 txqueuelen 1000 (Ethernet) RX packets 599643 bytes 144572651 (137.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 590688 bytes 161445142 (153.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@litong ~]# ifconfig eth0 | grep -Po '(?&amp;lt;=inet )\\S+' # grep取IP方式一172.21.205.254[root@litong ~]# ifconfig eth0 | grep -o \"inet [0-9.]*\" | grep -o \"[0-9.]*\" # grep取IP方式二172.21.205.254[root@litong ~]# ifconfig eth0 | awk -F \"[ ]+\" 'NR==2 &#123;print $3&#125;' # awk取IP172.21.205.254[root@litong ~]# ifconfig eth0 | sed -nr '2s#^[^0-9]*([0-9.]*).*$#\\1#gp' # sed取IP方式一172.21.205.254[root@litong ~]# ifconfig eth0 | sed -nr '2s#^.*inet (.*) net.*$#\\1#gp' # sed取IP方式二172.21.205.254 [root@litong ~]# ifconfig eth0 | sed -n '2p' | sed 's#^.*inet ##g' | sed 's# netmask.*$##g' # sed取IP方式三172.21.205.254 相关文档菜鸟教程三剑客取IP","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ltyeamin.github.io/tags/Linux/"}]},{"title":"Linux基础-wget与curl命令","slug":"Linux基础-wget与curl命令","date":"2018-05-22T09:21:31.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2018/05/22/Linux基础-wget与curl命令/","link":"","permalink":"http://ltyeamin.github.io/2018/05/22/Linux基础-wget与curl命令/","excerpt":"","text":"Linux系统下的下载工具wget 是一个从网络上自动下载文件的自由工具,支持通过 HTTP,HTTPS,FTP 三个最常见的 TCP/IP协议 下载,并可以使用 HTTP 代理.”wget” 这个名称来源于 “World Wide Web” 与 “get” 的结合.所谓自动下载,是指 wget 可以在用户退出系统的之后在继续后台执行,直到下载任务完成. 命令选项 -a&lt;日志文件&gt;:在指定的日志文件中记录资料的执行过程; -A&lt;后缀名&gt;:指定要下载文件的后缀名,多个后缀名之间使用逗号进行分隔; -b:进行后台的方式运行wget; -B&lt;连接地址&gt;:设置参考的连接地址的基地地址; -c:继续执行上次终端的任务,断点续传; -C&lt;标志&gt;:设置服务器数据块功能标志on为激活,off为关闭,默认值为on; -d:调试模式运行指令; -D&lt;域名列表&gt;:设置顺着的域名列表,域名之间用”,”分隔; -e&lt;指令&gt;:作为文件”.wgetrc”中的一部分执行指定的指令; -h:显示指令帮助信息; -i&lt;文件&gt;:从指定文件获取要下载的URL地址; -l&lt;目录列表&gt;:设置顺着的目录列表,多个目录用”,”分隔; -L:仅顺着关联的连接; -O: 将要下载的文件进行重命名 -r:递归下载方式; -nc:文件存在时,下载文件不覆盖原有文件; -nv:下载时只显示更新和出错信息,不显示指令的详细执行过程; -q:不显示指令执行过程; -nh:不查询主机名称; -v:显示详细执行过程; -V:显示版本信息; –passive-ftp:使用被动模式PASV连接FTP服务器; –follow-ftp:从HTML文件中下载FTP连接文件. 参考示例1234567891011121314151.下载网络资源[root@litong ~]# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz #使用wget下载Python安装包--2018-05-22 16:57:49-- https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgzResolving www.python.org (www.python.org)... 151.101.8.223, 2a04:4e42:2::223Connecting to www.python.org (www.python.org)|151.101.8.223|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 22994617 (22M) [application/octet-stream]Saving to: ‘Python-3.6.5.tgz’100%[=============================================================================================================&amp;gt;] 22,994,617 27.6MB/s in 0.8s 2018-05-22 16:57:50 (27.6 MB/s) - ‘Python-3.6.5.tgz’ saved [22994617/22994617][root@litong ~]# ll | grep Python-rw-r--r-- 1 root root 22994617 Mar 28 18:24 Python-3.6.5.tgz 2.断点续传123456789101112131415161718[root@litong ~]# wget -c http://d1.music.126.net/dmusic/netease-cloud-music_1.1.0_amd64_ubuntu.deb #下载Linux版本的网易云音乐--2018-05-22 17:04:04-- http://d1.music.126.net/dmusic/netease-cloud-music_1.1.0_amd64_ubuntu.debResolving d1.music.126.net (d1.music.126.net)... 157.185.168.24Connecting to d1.music.126.net (d1.music.126.net)|157.185.168.24|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 68515076 (65M) [application/octet-stream]Saving to: ‘netease-cloud-music_1.1.0_amd64_ubuntu.deb’46% [====================================================================&amp;gt; ] 31,560,638 15.2MB/s ^C #按下Ctrl+C终止下载[root@litong ~]# wget -c http://d1.music.126.net/dmusic/netease-cloud-music_1.1.0_amd64_ubuntu.deb #端点续传,继续下载,不会重新下载--2018-05-22 17:04:09-- http://d1.music.126.net/dmusic/netease-cloud-music_1.1.0_amd64_ubuntu.debResolving d1.music.126.net (d1.music.126.net)... 157.185.168.24Connecting to d1.music.126.net (d1.music.126.net)|157.185.168.24|:80... connected.HTTP request sent, awaiting response... 206 Partial ContentLength: 68515076 (65M), 33805218 (32M) remaining [application/octet-stream]Saving to: ‘netease-cloud-music_1.1.0_amd64_ubuntu.deb’100%[+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++==========================================================================&amp;gt;] 68,515,076 14.7MB/s in 2.2s Last-modified header invalid -- time-stamp ignored.2018-05-22 17:04:12 (14.7 MB/s) - ‘netease-cloud-music_1.1.0_amd64_ubuntu.deb’ saved [68515076/68515076] 3.后台下载12345678910111213141516171819202122[root@litong ~]# wget -b https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz &amp;&amp; tail -50f wget-log #后台下载并查看下载日志.下载并不阻塞Shell交互Continuing in background, pid 301.Output will be written to ‘wget-log’.--2018-05-22 17:14:55-- https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgzResolving www.python.org (www.python.org)... 151.101.8.223, 2a04:4e42:2::223Connecting to www.python.org (www.python.org)|151.101.8.223|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 22994617 (22M) [application/octet-stream]Saving to: ‘Python-3.6.5.tgz’0K .......... .......... .......... .......... .......... 0% 17.2M 1s50K .......... .......... .......... .......... .......... 0% 23.7M 1s100K .......... .......... .......... .......... .......... 0% 33.3M 1s150K .......... .......... .......... .......... .......... 0% 22.4M 1s200K .......... .......... .......... .......... .......... 1% 34.5M 1s250K .......... .......... .......... .......... .......... 1% 32.9M 1s .......... .......... .......... .......... ..........22250K .......... .......... .......... .......... .......... 99% 13.2M 0s22300K .......... .......... .......... .......... .......... 99% 10.7M 0s22350K .......... .......... .......... .......... .......... 99% 12.4M 0s22400K .......... .......... .......... .......... .......... 99% 14.3M 0s22450K ..... 100% 129M=0.8s2018-05-22 17:14:56 (27.7 MB/s) - ‘Python-3.6.5.tgz’ saved [22994617/22994617] 测试接口常用的curlcurl是利用URL语法在命令行方式下工作的开源文件传输工具.它支持文件的上传和下载,所以是综合传输工具.curl支持包括HTTP,HTTPS,ftp等众多协议,还支持POST,cookies认证,从指定偏移处下载部分文件,用户代理字符串,限速,文件大小,进度条等特征.做网页处理流程和数据检索自动化,curl可以祝一臂之力. 参考示例1.简单请求1234[root@litong ~]# curl https://www.baidu.com #简单GET请求请求百度&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;!--STATUS OK--&amp;gt;&amp;lt;html&amp;gt; &amp;lt;head&amp;gt;&amp;lt;meta http-equiv=content-type content=text/html;charset=utf-8&amp;gt;&amp;lt;meta http-equiv=X-UA-Compatible content=IE=Edge&amp;gt;&amp;lt;meta content=always name=referrer&amp;gt;&amp;lt;link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css&amp;gt;&amp;lt;title&amp;gt;百度一下,你就知道&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt; &amp;lt;body link=#0000cc&amp;gt; &amp;lt;div id=wrapper&amp;gt; &amp;lt;div id=head&amp;gt; &amp;lt;div class=head_wrapper&amp;gt; &amp;lt;div class=s_form&amp;gt; &amp;lt;div class=s_form_wrapper&amp;gt; &amp;lt;div id=lg&amp;gt; &amp;lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;form id=form name=f action=//www.baidu.com/s class=fm&amp;gt; &amp;lt;input type=hidden name=bdorz_come value=1&amp;gt; &amp;lt;input type=hidden name=ie value=utf-8&amp;gt; &amp;lt;input type=hidden name=f value=8&amp;gt; &amp;lt;input type=hidden name=rsv_bp value=1&amp;gt; &amp;lt;input type=hidden name=rsv_idx value=1&amp;gt; &amp;lt;input type=hidden name=tn value=baidu&amp;gt;&amp;lt;span class=\"bg s_ipt_wr\"&amp;gt;&amp;lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span class=\"bg s_btn_wr\"&amp;gt;&amp;lt;input type=submit id=su value=百度一下 class=\"bg s_btn\" autofocus&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;/form&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div id=u1&amp;gt; &amp;lt;a href=http://news.baidu.com name=tj_trnews class=mnav&amp;gt;新闻&amp;lt;/a&amp;gt; &amp;lt;a href=https://www.hao123.com name=tj_trhao123 class=mnav&amp;gt;hao123&amp;lt;/a&amp;gt; &amp;lt;a href=http://map.baidu.com name=tj_trmap class=mnav&amp;gt;地图&amp;lt;/a&amp;gt; &amp;lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&amp;gt;视频&amp;lt;/a&amp;gt; &amp;lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&amp;gt;贴吧&amp;lt;/a&amp;gt; &amp;lt;noscript&amp;gt; &amp;lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&amp;gt;登录&amp;lt;/a&amp;gt; &amp;lt;/noscript&amp;gt; &amp;lt;script&amp;gt;document.write('&amp;lt;a href=\"http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === \"\" ? \"?\" : \"&amp;\")+ \"bdorz_come=1\")+ '\" name=\"tj_login\" class=\"lb\"&amp;gt;登录&amp;lt;/a&amp;gt;'); &amp;lt;/script&amp;gt; &amp;lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=\"display: block;\"&amp;gt;更多产品&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div id=ftCon&amp;gt; &amp;lt;div id=ftConw&amp;gt; &amp;lt;p id=lh&amp;gt; &amp;lt;a href=http://home.baidu.com&amp;gt;关于百度&amp;lt;/a&amp;gt; &amp;lt;a href=http://ir.baidu.com&amp;gt;About Baidu&amp;lt;/a&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;p id=cp&amp;gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&amp;lt;a href=http://www.baidu.com/duty/&amp;gt;使用百度前必读&amp;lt;/a&amp;gt;&amp;nbsp; &amp;lt;a href=http://jianyi.baidu.com/ class=cp-feedback&amp;gt;意见反馈&amp;lt;/a&amp;gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &amp;lt;img src=//www.baidu.com/img/gs.gif&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 2.缓存(下载)1234567891011121314[root@litong ~]# curl -o baidu.html https://www.baidu.com #将百度首页保存成html本地文件 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 10319 0 --:--:-- --:--:-- --:--:-- 10351[root@litong ~]# cat baidu.html &amp;lt;!DOCTYPE html&amp;gt;&amp;lt;!--STATUS OK--&amp;gt;&amp;lt;html&amp;gt; &amp;lt;head&amp;gt;&amp;lt;meta http-equiv=content-type content=text/html;charset=utf-8&amp;gt;&amp;lt;meta http-equiv=X-UA-Compatible content=IE=Edge&amp;gt;&amp;lt;meta content=always name=referrer&amp;gt;&amp;lt;link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css&amp;gt;&amp;lt;title&amp;gt;百度一下,你就知道&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt; &amp;lt;body link=#0000cc&amp;gt; &amp;lt;div id=wrapper&amp;gt; &amp;lt;div id=head&amp;gt; &amp;lt;div class=head_wrapper&amp;gt; &amp;lt;div class=s_form&amp;gt; &amp;lt;div class=s_form_wrapper&amp;gt; &amp;lt;div id=lg&amp;gt; &amp;lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&amp;gt; &amp;lt;/div&amp;gt; ... #省略片段[root@litong ~]# curl -o Python-3.5.5.tgz https://www.python.org/ftp/python/3.5.5/Python-3.5.5.tgz #替换wget命令下载Python,断点续传-C % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 19.8M 100 19.8M 0 0 29.0M 0 --:--:-- --:--:-- --:--:-- 29.0M[root@litong ~]# ll | grep Python-rw-r--r-- 1 root root 20766931 May 22 17:38 Python-3.5.5.tgz 3.请求方式设置12345[root@litong ~]# curl -H &quot;Content-Type:application/json&quot; -X POST -d &apos;&#123; &quot;arg&quot;: 125086 &#125;&apos; http://47.67.44.121:9130/learning-path/tree/queryPhaseAndSubject #以json的方式进行请求% Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 231 0 214 100 17 214 17 0:00:01 --:--:-- 0:00:01 14437&#123;&quot;message&quot;:null,&quot;result&quot;:&quot;success&quot;,&quot;data&quot;:[&#123;&quot;subjectId&quot;:&quot;4267aa39-6ecb-40b7-8e10-7b309d022aec&quot;,&quot;subjectName&quot;:&quot;语文&quot;,&quot;phaseId&quot;:&quot;c7241629-1ec4-4035-b04c-ef17f7866688&quot;,&quot;phaseName&quot;:&quot;高中&quot;&#125;],&quot;code&quot;:0,&quot;success&quot;:true&#125; 4.设置referer1[root@litong ~]# curl --referer http://www.google.com http://www.baidu.com 5.设置User-Agent1[root@litong ~]# curl -A \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Safari/537.36\" http://www.baidu.com 6.设置cookie1[root@litong ~]# curl --cookie \"user=litong\" http://www.baidu.com 7.设置请求头1[root@litong ~]# curl -H \"accept-language:zh-cn\" http://www.baidu.com 8.进行认证12345678910111213[root@litong ~]# curl -u litong:0517108 http://www.gitlab.com/users/sign_in % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0&amp;lt;! DOCTYPE html&amp;gt;&amp;lt;html class=\"devise-layout-html\"&amp;gt;&amp;lt;head prefix=\"og: http://ogp.me/ns#\"&amp;gt;&amp;lt;meta charset=\"utf-8\"&amp;gt;&amp;lt;meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"&amp;gt;&amp;lt;meta content=\"object\" property=\"og:type\"&amp;gt;&amp;lt;meta content=\"GitLab\" property=\"og:site_name\"&amp;gt;&amp;lt;meta content=\"Sign in\" property=\"og:title\"&amp;gt;&amp;lt;meta content=\"GitLab Community Edition\" property=\"og:description\"&amp;gt;...省略片段 9.上传文件1234 [root@litong ~]# curl http://127.0.0.1/up -F \"file=@logo.png\" % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 4616 0 76 100 4540 76 4540 0:00:01 --:--:-- 0:00:01 8213&#123;\"hash\":\"FmP639IPMcunQpiXidRPNisi2lDp\",\"key\":\"FmP639IPMcunQpiXidRPNisi2lDp\"&#125;","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ltyeamin.github.io/tags/Linux/"}]},{"title":"自定义一个Spring Boot Starter","slug":"自定义一个Spring Boot Starter","date":"2018-05-18T08:58:10.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/05/18/自定义一个Spring Boot Starter/","link":"","permalink":"http://ltyeamin.github.io/2018/05/18/自定义一个Spring Boot Starter/","excerpt":"","text":"我们可以模仿之前http编码自动配置的例子也协议一个starter,目的是为了降低耦合性.虽说可以降低程序依赖之间的耦合性,但是我们不建议自己定义starter,因为Spring Boot或其他社区已经提供了大部分的starter,可以满足我们日常的需求.本篇博文主要为了让大家更好的理解Spring Boot的自动配置原理而写的,总之,遵循”不要重复造轮子”的宗旨.动起来自己造轮子,让我们从现在开始: 1.新建一个Maven项目,pom文件中导入依赖1234567891011121314151617181920212223242526272829&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yeamin.boot&lt;/groupId&gt; &lt;artifactId&gt;yeamin-boot-start&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;description&gt;自定义的start&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 自动配置依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.安全的配置类1234567891011121314151617181920212223package cn.yeamin.boot.conf;import org.springframework.boot.context.properties.ConfigurationProperties;/** * 安全的配置类 * @author Administrator */@ConfigurationProperties(prefix = \"yeamin.boot\")public class HelloServiceProperties &#123; private static final String MSG = \"world\"; private String msg = MSG; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; &#125; 3.判断依据类123456789101112131415161718192021/** * 判断依据类:可根据此类的存在与否判断是否创建这个类的Bean * @author Administrator */public class HelloService &#123; private String msg; public String sayHello() &#123; return \"Hello: \" + msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; &#125; 4.自动配置类12345678910111213141516171819202122232425262728293031package cn.yeamin.boot.conf;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import cn.yeamin.boot.service.HelloService;@Configuration@EnableConfigurationProperties(HelloServiceProperties.class)@ConditionalOnClass(&#123;HelloService.class&#125;)@ConditionalOnProperty(prefix = \"yeamin.boot\", value = \"enable\", matchIfMissing = true)public class HelloAutoConfiguration &#123; @Autowired private HelloServiceProperties properties; @Bean //判断HelloService是否在classpath存在 @ConditionalOnMissingBean(HelloService.class) public HelloService helloService() &#123; HelloService helloService = new HelloService(); helloService.setMsg(properties.getMsg()); return helloService; &#125;&#125; 5.注册配置在src/main/resource文件夹下创建META-INF/spring.factories文件123# Auto Configure 若有多个自动配置,则用&quot;,&quot;隔开,此处&quot;\\&quot;是为了换行后还能够读取到valueorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.yeamin.boot.conf.HelloAutoConfiguration 6.新建一个Spring Boot项目,使用starter,导入pom配置12345&lt;dependency&gt; &lt;groupId&gt;com.yeamin.boot&lt;/groupId&gt; &lt;artifactId&gt;yeamin-boot-start&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 7.编写controller123456789101112@RestControllerpublic class HelloController &#123; @Autowired private HelloService helloService; @GetMapping(&quot;/hello&quot;) public String index() &#123; return helloService.sayHello(); &#125;&#125; 8.进行yml配置12345server: port: 80yeamin: boot: msg: litong 9.浏览器请求http://localhost/hello,查看结果1litong","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://ltyeamin.github.io/tags/Spring-Boot/"}]},{"title":"Spring Boot自动配置原理剖析","slug":"Spring Boot自动原理剖析","date":"2018-05-17T08:01:40.000Z","updated":"2019-11-20T15:08:58.637Z","comments":true,"path":"2018/05/17/Spring Boot自动原理剖析/","link":"","permalink":"http://ltyeamin.github.io/2018/05/17/Spring Boot自动原理剖析/","excerpt":"","text":"神奇魔法-自动配置前篇文章讲述了Spring 4 条件注解,其实Spring Boot自动配置神奇实现也是基于这一原理的.若想知道Spring Boot为我们做了哪些的自动配置,可以查看这里的源码.可以通过以下三种方式查看项目中已启用和未启用的自动配置报告. 运行jar时增加–debug参数: java -jar xxx.jar –debug 在application.properties中设置属性: debug=true 运行项目时通过IDE设置JVM参数: -Ddebug 启动后,可在控制台输出相关自动配置报告.已启用的自动配置为:123456789101112131415161718192021222324============================CONDITIONS EVALUATION REPORT============================Positive matches:----------------- CodecsAutoConfiguration matched: - @ConditionalOnClass found required class &apos;org.springframework.http.codec.CodecConfigurer&apos;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) CodecsAutoConfiguration.JacksonCodecConfiguration matched: - @ConditionalOnClass found required class &apos;com.fasterxml.jackson.databind.ObjectMapper&apos;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) CodecsAutoConfiguration.JacksonCodecConfiguration#jacksonCodecCustomizer matched: - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean &apos;jacksonObjectMapper&apos; (OnBeanCondition) DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class &apos;org.springframework.web.servlet.DispatcherServlet&apos;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - found ConfigurableWebEnvironment (OnWebApplicationCondition) ...... ...... ...... 未启用的自动配置为:123456789101112131415161718Negative matches:----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes &apos;javax.jms.ConnectionFactory&apos;, &apos;org.apache.activemq.ActiveMQConnectionFactory&apos; (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes &apos;org.aspectj.lang.annotation.Aspect&apos;, &apos;org.aspectj.lang.reflect.Advice&apos;, &apos;org.aspectj.weaver.AnnotatedElement&apos; (OnClassCondition) ArtemisAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes &apos;javax.jms.ConnectionFactory&apos;, &apos;org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory&apos; (OnClassCondition) ...... ...... ...... Spring Boot关于自动配置的源码也是在spring-boot-autoconfigure-1.5.9.RELEASE.jar内,包含的模块配置,如下图: Spring Boot条件注解在spring-boot-autoconfigure-1.5.9.RELEASE.jar的org.springframework.boot.autoconfigure.condition包下,有许多注解组合了@Conditional的元注解,只是使用了不同的条件,形成了新的条件注解: @ConditionalOnBean: 当容器里有指定的Bean的条件下. @ConditionalOnClass: 当classpath下有指定的类的条件下. @ConditionalOnExpression: 基于SpEL表达式作为判断条件. @ConditionalOnJava: 基于JVM版本作为判断条件. @ConditionalOnJndi: 在JNDI村长的条件下查找指定的位置. @ConditionalOnMissingBean:当容器里没有指定的Bean的条件下. @ConditionalOnMissingClass: 当classpath下没有指定的类的条件下. @ConditionalOnNotWebApplication: 当前项目不是Web项目的条件下. @ConditionalOnProperty: 指定的属性是否有指定值的情况下. @ConditionalOnResource: classpath下是否有指定资源的情况下. @ConditionalOnSingleCandidate: 当指定的Bean在容器中只有一个,或虽然有多个但是有指定的首选(@Primary)的Bean @ConditionalOnWebApplication: 当前项目是Web项目的条件下. @Enable*注解的工作原理在Spring体系中,有大量的@Enable*的注解: @EnableAspectAutoProxy:用于开启对Aspect自动代理的支持. @EnableAsync:用于开启异步方法的支持. @EnableScheduling:用于开启定时任务的支持. @EnableWebMvc:用于开启WebMvc配置的支持. @EnableConfigurationProperties:用于开启对@ConfigurationProperties注解配置Bean的的支持. @EnableJpaRepositories:用于开启对Spring Data Jpa的的支持. @EnableTransactionManagement:用于开启对注解式事务的的支持. @EnableCaching:用于开启对注解式缓存的的支持. 这些注解用于开启某项功能的支持,从而避免自己配置大量的代码.那么这个神奇的功能的上线原理是什么呢?我们来看看. 通过观察这些@Enable*注解的源码,我们发现所有的注解都有一个@import注解,@import是用来导入配置类的,这也就意味着这些自动开启的实现是导入了一些自动配置的Bean.这些导入的配置方式主要分为以下三种类型. 第一类:直接导入配置类 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(SchedulingConfiguration.class)@Documentedpublic @interface EnableScheduling &#123;&#125; 直接导入配置类SchedulingConfiguration.class,这个类注解了@Condition,且注册了一个ScheduledAnnotationBeanPostProcessor的Bean,源码如下:1234567891011@Configuration@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class SchedulingConfiguration &#123; @Bean(name = TaskManagementConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() &#123; return new ScheduledAnnotationBeanPostProcessor(); &#125;&#125; 第二类:依据条件选择配置类12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123; Class&lt;? extends Annotation&gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; AsyncConfigurationSelector通过条件来选择需要导入的配置类,AsyncConfigurationSelector的根接口为ImportSelector1234567891011121314151617public class AsyncConfigurationSelector extends AdviceModeImportSelector&lt;EnableAsync&gt; &#123; private static final String ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME = \"org.springframework.scheduling.aspectj.AspectJAsyncConfiguration\"; @Override public String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123; ProxyAsyncConfiguration.class.getName() &#125;; case ASPECTJ: return new String[] &#123; ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME &#125;; default: return null; &#125; &#125;&#125; 自动配置原理关于Spring Boot的运作原理,我们还是回归到@SpringBootApplication注解上,改注解是一个组合注解.它是由@SpringBootConfiguration,@EnableAutoConfiguration和@ComponentScan组成的.@SpringBootConfiguration也是组合了@Configuration注解,@ComponentScan是组件扫描,而@EnableAutoConfiguration是自动配置功能的核心注解.我们来看看@EnableAutoConfiguration注解源码:123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 这里的关键功能是@Import注解导入的配置功能,EnableAutoConfigurationImportSelector使用SpringFactoriesLoader.loadFactoryNames()方法来扫描具有META-INF/spring.factories文件的jar包.而我们的spring-boot-autoconfigure-1.5.9.RELEASE.jar就有一个spring.factories文件.此文件中声明了有哪些自动配置,如下图: 实例分析在了解Spring Boot的运作原理和主要条件注解后,现在我们来分析一个简单的Spring Boot内置的自动配置功能:http的编码配置.在常规web的war项目中,我们要解决http编码的时候是在web.xml里配置一个filter,如:1234567891011121314151617&lt;!-- 编码Filter 加载配置 Start --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 自动配置要满足两个条件: 能配置CharacterEncodingFilter这个Bean; 能配置encoding和forceEncoding这两个参数. 源码中定义的HttpEncodingProperties配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package org.springframework.boot.autoconfigure.http;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;import java.util.Locale;import java.util.Map;import org.springframework.boot.context.properties.ConfigurationProperties; // 在application.properties或application.ynl文件配置时前缀必须是spring.http.encoding@ConfigurationProperties(prefix = \"spring.http.encoding\")public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = StandardCharsets.UTF_8; /** 默认编码方式为UTF-8,若修改可使用spring.http.encoding.charset=编码 */ private Charset charset = DEFAULT_CHARSET; private Boolean force; private Boolean forceRequest; private Boolean forceResponse; private Map&lt;Locale, Charset&gt; mapping; public Charset getCharset() &#123; return this.charset; &#125; public void setCharset(Charset charset) &#123; this.charset = charset; &#125; public boolean isForce() &#123; return Boolean.TRUE.equals(this.force); &#125; public void setForce(boolean force) &#123; this.force = force; &#125; public boolean isForceRequest() &#123; return Boolean.TRUE.equals(this.forceRequest); &#125; public void setForceRequest(boolean forceRequest) &#123; this.forceRequest = forceRequest; &#125; public boolean isForceResponse() &#123; return Boolean.TRUE.equals(this.forceResponse); &#125; public void setForceResponse(boolean forceResponse) &#123; this.forceResponse = forceResponse; &#125; public Map&lt;Locale, Charset&gt; getMapping() &#123; return this.mapping; &#125; public void setMapping(Map&lt;Locale, Charset&gt; mapping) &#123; this.mapping = mapping; &#125; public boolean shouldForce(Type type) &#123; Boolean force = (type == Type.REQUEST ? this.forceRequest : this.forceResponse); if (force == null) &#123; force = this.force; &#125; if (force == null) &#123; force = (type == Type.REQUEST); &#125; return force; &#125; public enum Type &#123; REQUEST, RESPONSE &#125;&#125; 源码:HttpEncodingAutoConfiguration自动配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package org.springframework.boot.autoconfigure.web;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.autoconfigure.web.HttpEncodingProperties.Type;import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer;import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.boot.web.filter.OrderedCharacterEncodingFilter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.Ordered;import org.springframework.web.filter.CharacterEncodingFilter;@Configuration@EnableConfigurationProperties(HttpEncodingProperties.class) //开启属性注入@ConditionalOnWebApplication //当前项目是Web应用触发@ConditionalOnClass(CharacterEncodingFilter.class) //当classpath下存在CharacterEncodingFilter.class时加载该类@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) //当spring.http.encoding=enable的情况下,如果没有设置则默认为true,即条件符合public class HttpEncodingAutoConfiguration &#123; private final HttpEncodingProperties properties; /** 通过构造方法注入 */ public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //使用Java的方式声明Bean @ConditionalOnMissingBean(CharacterEncodingFilter.class) //当Spring容器中没有这个Bean的时候新建Bean. public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); //设置编码 filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; @Bean public LocaleCharsetMappingsCustomizer localeCharsetMappingsCustomizer() &#123; return new LocaleCharsetMappingsCustomizer(this.properties); &#125; private static class LocaleCharsetMappingsCustomizer implements EmbeddedServletContainerCustomizer, Ordered &#123; private final HttpEncodingProperties properties; LocaleCharsetMappingsCustomizer(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; if (this.properties.getMapping() != null) &#123; container.setLocaleCharsetMappings(this.properties.getMapping()); &#125; &#125; @Override public int getOrder() &#123; return 0; &#125; &#125;&#125;","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://ltyeamin.github.io/tags/Spring-Boot/"}]},{"title":"Spring条件注解@Conditional","slug":"Spring条件注解@Conditional","date":"2018-05-17T06:20:15.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2018/05/17/Spring条件注解@Conditional/","link":"","permalink":"http://ltyeamin.github.io/2018/05/17/Spring条件注解@Conditional/","excerpt":"","text":"@Conditional注解Spring 4提供了一个基于条件的Bean的创建,即使用@Conditional注解.@Conditional根据满足某一个特定条件创建一个特定的Bean.比如说,当某一个jar包在一个类路径下的时候,自动配置一个或多个Bean;或者只有某个Bean被创建才会创建另外一个Bean.总的来说,就是根据特定条件来控制Bean的创建行为,这样我们可以利用这个特性来进行一些自动的配置. Condition接口设置给 @Conditional注解的类可以是任意实现了Condition接口的类型.可以看出,这些接口实现起来简单直接.只需要提供matches()方法的实现即可.如果matches()方法返回true,那么就会创建带有@Conditional注解的bean.反之则不会创建Bean.matches()方法有两个参数:ConditionContext类型和AnnotatedTypeMetadata类型: ConditionContext接口能提供应用上下文信息: getRegistry()返回BeanDefinitionRegistry注册表,可以判断Bean的定义 getBeanFactory()返回ConfigurableListableBeanFactory,可以检查Bean是否已经存在,甚至探查Bean的属性. getEnvironment()返回Environment,可以获取当前应用环境变量,也可以检测当前环境变量是否存在. getResourceLoader()返回ResourceLoader,用于读取或探查所加载的资源. getClassLoader()返回ClassLoader,用于检查类是否存在. AnnotatedTypeMetadata接口能够让我们检查带有@Bean注解的方法上还有没有其他注解: isAnnotated()可以判断除@Bean注解外是否还有其他注解. getAllAnnotationAttributes()获取其他所有的注解属性下面我们来做一个以不同的操作系统来作为条件,通过实现Condition接口,并重写其matches方法来构造判断条件.若在Windows系统下运行程序,则输出列表命令为dir；若在Linux操作系统下运行程序,则输出列表命令为ls。代码演示1.导入POM依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt; 2.定义判断条件1234567891011121314151617181920package cn.yeamin.spring.constant;/** * OS常量 * @author tong.li * */public final class Constants &#123; /** * 私有构造,不让外部创建本类的实例对象 */ private Constants() &#123;&#125; public final static String OS_KEY = \"os.name\"; public final static String OS_TYPE_WINDOWS = \"Windows\"; public final static String OS_TYPE_LINUX = \"Linux\";&#125; 123456789101112131415161718package cn.yeamin.spring.condition;import org.springframework.context.annotation.Condition;import org.springframework.context.annotation.ConditionContext;import org.springframework.core.type.AnnotatedTypeMetadata;import cn.yeamin.spring.constant.Constants;/*** * 判断Linux的条件类 * @author tong.li */public class LinuxCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; return context.getEnvironment().getProperty(Constants.OS_KEY).contains(Constants.OS_TYPE_LINUX); &#125;&#125; 1234567891011121314151617181920package cn.yeamin.spring.condition;import org.springframework.context.annotation.Condition;import org.springframework.context.annotation.ConditionContext;import org.springframework.core.type.AnnotatedTypeMetadata;import cn.yeamin.spring.constant.Constants;/*** * 判断Windows的条件类 * @author tong.li */public class WindowsCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; return context.getEnvironment().getProperty(Constants.OS_KEY).contains(Constants.OS_TYPE_WINDOWS); &#125;&#125; 3.业务实现:不同系统下不同的命令1234567891011121314package cn.yeamin.spring.service;/** * 命令服务接口 * @author tong.li */public interface CommandService &#123; /** * 抽象方法,显示操作系统的showList命令 * @return cmd */ String showListCommand();&#125; 1234567891011package cn.yeamin.spring.service.impl;import cn.yeamin.spring.service.CommandService;public class LinuxCommandService implements CommandService &#123; @Override public String showListCommand() &#123; return \"ls\"; &#125;&#125; 123456789101112package cn.yeamin.spring.service.impl;import cn.yeamin.spring.service.CommandService;public class WindowsCommandService implements CommandService &#123; @Override public String showListCommand() &#123; return \"dir\"; &#125;&#125; 4.定义配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445package cn.yeamin.spring.conf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Conditional;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import cn.yeamin.spring.condition.LinuxCondition;import cn.yeamin.spring.condition.WindowsCondition;import cn.yeamin.spring.service.CommandService;import cn.yeamin.spring.service.impl.LinuxCommandService;import cn.yeamin.spring.service.impl.WindowsCommandService;/** * 配置类 * @author tong.li * */@Configurationpublic class ConditionConfig &#123; /** * 声明一个Bean,并交给Spring容器去管理 * 通过@Conditional注解,操作系统为Windows则输出Windows下的dir命令 * @return */ @Bean @Conditional(WindowsCondition.class) public CommandService windowsCMD() &#123; return new WindowsCommandService(); &#125; /** * 声明一个Bean,并交给Spring容器去管理 * 通过@Conditional注解,操作系统为Windows则输出Windows下的ls命令 * @return */ @Bean @Conditional(LinuxCondition.class) public CommandService linuxCMD() &#123; return new LinuxCommandService(); &#125;&#125; 5.执行测试123456789101112131415161718192021222324252627package cn.yeamin.spring;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import cn.yeamin.spring.conf.ConditionConfig;import cn.yeamin.spring.constant.Constants;import cn.yeamin.spring.service.CommandService;/** * 启动类 * @author tong.li * */@SuppressWarnings(\"all\")public class Bootstrap &#123; /** * 执行测试基于不同操作系统显示不同的命令 * @param args */ public static void main(String[] args) &#123; // 加载配置类,创建基于注解式的应用上下文 AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ConditionConfig.class); //获取Bean CommandService commandService = context.getBean(CommandService.class); System.out.println(context.getEnvironment().getProperty(Constants.OS_KEY) + \"系统下的显示列表命令为: \" + commandService.showListCommand()); &#125;&#125; 6.执行结果1Windows 7系统下的显示列表命令为: dir 1linux系统下的显示列表命令为: ls","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://ltyeamin.github.io/tags/Spring/"}]},{"title":"Spring容器以及Bean的生命周期","slug":"Spring容器以及Bean的生命周期","date":"2018-05-15T03:51:07.000Z","updated":"2019-11-20T15:08:53.568Z","comments":true,"path":"2018/05/15/Spring容器以及Bean的生命周期/","link":"","permalink":"http://ltyeamin.github.io/2018/05/15/Spring容器以及Bean的生命周期/","excerpt":"","text":"Spring容器容器是Spring框架的核心.Spring容器使用DI管理构成应用的组件,他会创建相互协作的组件之间的关联.Spring容器并不是只有一个.Spring自带多个容器实现,可归纳为两种不同的类型: Bean工厂(由BeanFactory接口定义)是最简单的同期,提供基本的DI支持. 应用上下文(由ApplicationContext接口定义)基于BeanFactory构建,并提供应用框架级别的服务. 虽然我们可以在Bean工厂和应用上下文任选一种作为我们的容器,但BeanFactory是ApplicationContext的顶层接口,功能比较少,不能满足我们日常应用的需求.因此应用上下文更受大家的欢迎. Spring自带了多种类型的应用上下文,下面罗列几个常用的: AnnotationConfigApplicationContext:从一个或多个基于Java的配置类中加载Spring应用上下文.Spring4之后推荐使用,Spring Boot,Spring Cloud等自动配置都是基于Java Config. AnnotationConfigWebApplicationContext:从一个或多个基于Java的配置类中加载Spring Web上下文. ClassPathXmlApplicationContext: 从classpath路径下的一个或多个XML配置加载上下文.Spring 4之前常常以classpath下文件方式进行加载. FileSystemXmlApplicationContext: 从文件系统下的一个或多个XML配置文件中加载上下文定义.一般不用 XmlWebApplicationContext: 从Web应用下的一个或多个XML配置加载上下文.以前老的Web项目常用的加载方式. Bean的生命周期在传统的Java编程模式中,使用Java对象关键字new或者利用反射机制进行对象实例化,这些”Bean”实例化后方可使用.到了某个时期这些对象不再被使用了,则JVM会自动进行垃圾回收. 相比传统Java对象的生命周期,Spring容器中Bean的生命周期就显得相对复杂多了.正确理解Spring Bean的生命周期非常重要,因为你或许要利用Spring提供的扩展点来自动鬼Bean的创建过程. 如上图,Bean在Spring容器中从创建到销毁经历了若干阶段: Spring通过反射机制对Bean进行实例化; Spring将值和Bean的引用注入到Bean对应的属性中. 如果Bean实现了BeanNameAware接口,Spring将Bean的id传递给setBeanName()方法. 如果Bean实现了BeanFactoryAware接口,Spring将调用setBeanFactory()方法,将BeanFactory容器实例传入. 如果Bean实现了ApplicationContextAware接口,Spring将调用setApplicationContext()方法,将Bean所在的应用上下文的引用传入进来. 如果Bean实现了BeanPostProcessor接口,Spring将调用postProcessBeforeInitialization()方法. 如果Bean实现了InitializingBean接口,Spring将调用afterPropertiesSet()方法.类似在xml使用了init-method的方法,该方法也会被调用. 如果Bean实现了BeanPostProcessor接口,Spring将调用postProcessAfterInitialization()方法. Bean已经准备就绪,可以被应用程序使用了,它们一直驻留在应用上下文中,直到该应用上下文被销毁. 如果Bean实现了DisposableBean接口,Spring将调用它的destroy()方法.类似地,如果在xml使用了destroy-method声明了销毁方法,该方法也会被调用.","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://ltyeamin.github.io/tags/Spring/"}]},{"title":"数据结构之排序","slug":"数据结构之排序","date":"2018-05-10T02:36:55.000Z","updated":"2019-05-29T14:03:47.000Z","comments":true,"path":"2018/05/10/数据结构之排序/","link":"","permalink":"http://ltyeamin.github.io/2018/05/10/数据结构之排序/","excerpt":"","text":"数据结构和算法是整个计算机科学与技术领域永远逃避不了的话题,博主大学有过数据结构这门学科,不过特别后悔当时没有好好学习.仅学的那么点东西现在几乎忘得一干二净.虽说学的浅薄,但对整个编程思想还是很有帮助的. 十种常见排序算法十种常见排序算法可分为两大类: 非线性时间比较类排序：通过比较来决定元素间的相对次序,由于其时间复杂度不能突破O(nlogn),因此称为非线性时间比较类排序. 线性时间非比较类排序：不通过比较来决定元素间的相对次序,它可以突破基于比较排序的时间下界,以线性时间运行,因此称为线性时间非比较类排序. 冒泡排序冒泡排序(Bubble Sort),是一种计算机科学领域的较简单的排序算法.它重复地走访过要排序的数列,一次比较两个元素,如果他们的顺序错误就把他们交换过来.走访数列的工作是重复地进行直到没有再需要交换,也就是说该数列已经排序完成.这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端,故名“冒泡排序”. 算法描述 比较相邻的元素。如果第一个比第二个大,就交换它们两个; 对每一对相邻元素作同样的工作,从开始第一对到结尾的最后一对,这样在最后的元素应该会是最大的数; 针对所有的元素重复以上的步骤,除了最后一个;动图演示代码演示1234567891011121314151617181920212223242526272829303132/** * * 冒泡排序 * * @author tong.li * @param arr = &#123;6,3,8,2,9,1&#125; * * 第0趟比较5次: 3,6,8,2,9,1 =&gt; 3,6,8,2,9,1 =&gt; 3,6,2,8,9,1 =&gt; 3,6,2,8,9,1 =&gt; 3,6,2,8,1,9 * 第1趟比较4次: 3,6,2,8,1,9 =&gt; 3,2,6,8,1,9 =&gt; 3,2,6,8,1,9 =&gt; 3,2,6,1,8,9 * 第2趟比较3次: 2,3,6,1,8,9 =&gt; 2,3,6,1,8,9 =&gt; 2,3,1,6,8,9 * 第3趟比较2次: 2,3,1,6,8,9 =&gt; 2,1,3,6,8,9 * 第4趟比较1次: 1,2,3,6,8,9 */public static void bubbleSort(int ... arr) &#123; if ( arr==null || arr.length &lt;= 0) &#123; return; &#125; // 外循环控制趟数 for (int i = 0; i &lt; arr.length; i++) &#123; // 内循环控制次数 // for(int j=1;j&lt;arr.length-i;j++)&#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; //相邻两个元素进行比较 if( arr[j] &gt; arr[j + 1]) &#123; // 采用异或方式进行变量互换 arr[j] = arr[j] ^ arr[j + 1]; arr[j + 1] = arr[j] ^ arr[j + 1]; arr[j] = arr[j] ^ arr[j + 1]; &#125; &#125; &#125;&#125; 快速排序(面试官最爱问的排序算法)快速排序(Quicksort)是对冒泡排序的一种改进.快速排序由C.A.R.Hoare在1962年提出.基本思想是:通过一趟排序将要排序的数据分割成独立的两部分,其中一部分的所有数据都比另外一部分的所有数据都要小,然后再按此方法对这两部分数据分别进行快速排序,整个排序过程可以递归进行,以此达到整个数据变成有序序列.最坏情况的时间复杂度为O(n^2).最好情况时间复杂度为O(nlog2n). 算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下: 从数列中挑出一个元素.称为”基准”（pivot）; 重新排序数列.所有元素比基准值小的摆放在基准前面.所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后.该基准就处于数列的中间位置。这个称为分区（partition）操作; 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。动图演示代码演示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * * 快速排序 * * @param arr = &#123;6,3,8,2,9,1&#125; * @author tong.li * * 分析: * a. 一般以首元素或尾元素为基准,这里以首元素6为基准,有比基准数大的数放在6的右边,比基准数小的数放在6的左边,我们的目标是将6挪到序列中间的某个位置. * b. 假设这个位置是k,现在需要寻找这个k的位置.分别从数组的两端开始探测,先从右往左找一个小于6的数(总是如此),再从左到右找一个大于6的数,两端停下来后交换它们. * c. 这里可以用两个变量i和j,分布指向数组最左边和最右边.这两个变量有个好听的名字:哨兵i和哨兵j,哨兵i初始指向索引为0的6,哨兵j初始指向索引为5的1 * 步骤: * 1. 先让哨兵j动起来向左(j--)找小于6的值,第一次找到为1停下来. * 2. 紧接着哨兵i向右移动(i++)找大于6的值,第一次找到为8停下来. * 3. 进行交换停下来的值,即1和8进行交换.交换后的数组为:6,3,1,2,9,8 * 4. 在3交换后的基础上继续1,2步骤,哨兵j一直往左移遇到2,哨兵i一直往右移遇到9,两个哨兵在2已经相遇了,我们应该将基准6与和2进行交换,即交换后的数组为:2,3,1,6,9,8,此时第一轮探测真正结束 * 此时旧基准数6已经归位,新基准数为2,以6位分界点把数组拆成了两个小数组,左数组为小于6的,右边数组都是大于6的,目前两个数组的顺序都是混乱的,不过不要紧,继续按1,2,3步骤分别对两个数组耐心处理 * 5. 先处理6左边的小数组2,3,1,以2为基准数,找到1和3,交换后2,1,3,继续找在1相遇,交换后为1,2,3 * 6. 再来处理6右边的小数组9,8,以9为基准数,两者在8相遇,交换后为8,9 * 7. 到此完全结束,排序后为1,2,3,6,8,9.快速排序的每一轮处理其实就是将这一轮的基准数归位,直到所有的数都归位为止,排序就结束了. * */public static void quickSort(int[] arr, int low, int high) &#123; int i, j, temp, t; if (low &gt; high) &#123; return; &#125; i = low; j = high; // temp就是基准位 temp = arr[low]; while (i &lt; j) &#123; // 先看右边.依次往左递减 while (temp &lt;= arr[j] &amp;&amp; i &lt; j) &#123; j--; &#125; // 再看左边.依次往右递增 while (temp &gt;= arr[i] &amp;&amp; i &lt; j) &#123; i++; &#125; // 如果满足条件则交换 if (i &lt; j) &#123; t = arr[j]; arr[j] = arr[i]; arr[i] = t; &#125; &#125; // 最后将基准为与i和j相等位置的数字交换 arr[low] = arr[i]; arr[i] = temp; // 递归调用左半数组 quickSort(arr, low, j - 1); // 递归调用右半数组 quickSort(arr, j + 1, high);&#125; 选择排序选择排序(Selection sort)是一种简单直观的排序算法.它的工作原理是每一次从待排序的数据元素中选出最小(或最大)的一个元素,存放在序列的起始位置,直到全部待排序的数据元素排完. 算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下: 初始状态：无序区为R[1..n],有序区为空; 第i趟排序(i=1,2,3…n-1)开始时,当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k],将它与无序区的第1个记录R交换,使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区; n-1趟结束,数组有序化了;动图演示代码演示12345678910111213141516171819202122232425262728293031/** * * 选择排序 * * @author tong.li * @param arr = &#123;6,3,8,2,9,1&#125; * *第0趟比较5次: 3,6,8,2,9,1 =&gt; 3,6,8,2,9,1 =&gt; 2,6,8,3,9,1 =&gt; 2,6,8,3,9,1 =&gt; 1,6,8,3,9,2 *第1趟比较4次: 1,6,8,3,9,2 =&gt; 1,3,8,6,9,2 =&gt; 1,3,8,6,9,2 =&gt; 1,2,8,6,9,3 *第2趟比较3次: 1,2,6,8,9,3 =&gt; 1,2,6,8,9,3 =&gt; 1,2,3,8,9,6 *第3趟比较2次: 1,2,3,8,9,6 =&gt; 1,2,3,6,9,8 *第4趟比较1次: 1,2,3,6,8,9 */public static void selectionSort(int... arr) &#123; if ( arr==null || arr.length &lt;= 0) &#123; return; &#125; // 外循环控制趟数 for (int i = 0; i &lt; arr.length - 1; i++) &#123; // 内循环控制次数 for (int j = i + 1; j &lt; arr.length; j++) &#123; // 相邻两个元素进行比较 if (arr[i] &gt; arr[j]) &#123; // 采用异或方式进行变量互换 arr[i] = arr[i] ^ arr[j]; arr[j] = arr[i] ^ arr[j]; arr[i] = arr[i] ^ arr[j]; &#125; &#125; &#125;&#125; 其他排序算法后续更新,请读者持续关注. 参考文献:十大经典排序算法-动图演示 堆排序,归并排序,快排-排序王者之争一 堆排序,归并排序,快排-排序王者之争二","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://ltyeamin.github.io/categories/algorithm/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://ltyeamin.github.io/tags/排序算法/"}]},{"title":"内网穿透神器-Ngrok","slug":"内网穿透神器-Ngrok","date":"2018-04-04T01:27:55.000Z","updated":"2019-11-20T15:08:53.128Z","comments":true,"path":"2018/04/04/内网穿透神器-Ngrok/","link":"","permalink":"http://ltyeamin.github.io/2018/04/04/内网穿透神器-Ngrok/","excerpt":"","text":"作为一个Web开发者,我们有时候会需要临时地将一个本地的Web网站部署到外网,以供他人体验评价或协助调试等等,通常我们会这么做: 找到一台运行于外网的Web服务器; 服务器上搭建网站运行时的环境; 部署网站 调试结束后,再将网站从服务器上删除 我们部署静态的网站仅仅只是需要展示给朋友,何必那么麻烦???除此之外,笔者最近进行微信机器人开发,经常在本地开发和微信服务端进行联调.由于微信端口和网络的限制(微信公众平台开发对接必须以http://或https://开头,分别支持80端口和443端口),我不得不将我的内网映射到公网地址做映射调试.有了Ngrok之后,世界是如此的美好,所以开始学习之旅吧! Ngrok介绍与使用Ngrok是一个反向代理,通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道.Ngrok可捕获和分析所有通道上的流量,便于后期分析和重放. 下载地址: https://ngrok.com/download我是下载Windows版本的,读者可根据自己的系统选择进行下载. Windows版本使用方法 双击打开ngrok.exe,会出现如下帮助信息. 启动本地项目,我的是Java的Spring Boot项目,项目端口为80,读者可根据技术栈选择不同的Web项目. 通过查看上述帮助文档后进行端口本地映射到公网,输入命令:ngrok 协议名 本地要映射的端口号,如输入ngrok http 80命令可进入如下通道连接. 从上图可知映射的信息,要想进行可视化浏览,可在浏览器输入:http://127.0.0.1:4040 上面有两个映射到公网的地址,通过外网(手机流量)进行访问看是否成功. 访问成功后,可查看请求与相应信息.","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"实用工具及技巧","slug":"实用工具及技巧","permalink":"http://ltyeamin.github.io/tags/实用工具及技巧/"}]},{"title":"单例模式-Spring单例实现原理分析","slug":"单例模式-Spring单例实现原理分析","date":"2018-03-27T02:01:55.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/03/27/单例模式-Spring单例实现原理分析/","link":"","permalink":"http://ltyeamin.github.io/2018/03/27/单例模式-Spring单例实现原理分析/","excerpt":"","text":"在Spring中,被@Scope注解修饰Bean默认是单例模式的,即只有一个实例对象,多次获取Bean会拿到同一个对象. 单例注册表Spring采用单例注册表的特殊方式实现单例模式.首先自己写个单例注册表.我们可以通过Map缓存单例对象,实现单例注册表.值得注意的是,采用ConcurrentHashMap是出于线程安全的考虑. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * @author tong.li * @Description: 一个简单的单例实现,设计单例注册表 * @packagename: com.yimi.yts.learningpath * @date 2018-03-27 10:04 */public class SingletonReg &#123; //构建采用ConcurrentHashMap,用于充当缓存注册表 private final static Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(16); // 静态代码块只加载执行一次 static &#123; // 实例化Bean SingletonReg singletonReg = new SingletonReg(); //并注册到注册表中,key为类的完全限定名,value为实例化对象 singletonObjects.put(singletonReg.getClass().getName(),singletonReg); &#125; /** * 私有化构造方法,避免外部创建本类实例 */ private SingletonReg() &#123;&#125; /** * 对外暴露获得该bean的方法,Spring框架一般会返回Object * @return */ public static SingletonReg getInstance(String className) &#123; if (StringUtils.isEmpty(className)) &#123; return null; &#125; //从注册表获取,如果没有直接创建 if (singletonObjects.get(className) == null) &#123; try &#123; //如果为空,通过反射进行实例化 singletonObjects.put(className, Class.forName(className).newInstance()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; //从缓存表中回去,如果缓存命中直接返回 return (SingletonReg)singletonObjects.get(className); &#125; &#125; 同过以上单例实现,getInstance()方法通过传入类名进行判断,如果参数为null,那就无法获取bean,如果参数不为空,先从缓存注册表命中,如果命中就return掉,没有命中通过反射机制实例化一个return.这样多次获得调用getInstance()方法都是获得同一个对象.测试如下:123456789 public static void main(String[] args) &#123; /* * 返回的都是同一个对象 * com.yimi.yts.learningpath.SingletonReg@3d82c5f3 * com.yimi.yts.learningpath.SingletonReg@3d82c5f3 */ System.out.println( SingletonReg.getInstance(&quot;com.yimi.yts.learningpath.SingletonReg&quot;)); System.out.println( SingletonReg.getInstance(&quot;com.yimi.yts.learningpath.SingletonReg&quot;));&#125; Spring源码分析通过上述实现,Spring就是采用了这种单例注册表的特殊方式实现单例模式的.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport implements ConfigurableBeanFactory &#123; @SuppressWarnings(&quot;unchecked&quot;) protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; //对Bean的name进行处理,防止非法字符 final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. //从单例注册表中检查是否存在单例缓存 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; //省略部分代码... // 返回缓存实例 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; //省略代码... try &#123; // ...忽略代码 // 单例模式,实例化bean,处理分支 // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; //原型魔兽,处理分支 else if (mbd.isPrototype()) &#123; //省略代码 &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(&quot;No Scope registered for scope name &apos;&quot; + scopeName + &quot;&apos;&quot;); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, &quot;Scope &apos;&quot; + scopeName + &quot;&apos; is not active for the current thread; consider &quot; + &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Failed to convert bean &apos;&quot; + name + &quot;&apos; to required type &apos;&quot; + ClassUtils.getQualifiedName(requiredType) + &quot;&apos;&quot;, ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean; &#125;&#125; 其中中重要的代码是getSingleton()方法,下面深入分析该方法:1234567891011121314151617181920212223242526272829303132333435public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // 通过 Map 实现单例注册表 private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(64); public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, &quot;&apos;beanName&apos; must not be null&quot;); synchronized (this.singletonObjects) &#123; // 检查缓存中是否存在实例 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // ...忽略代码 try &#123; singletonObject = singletonFactory.getObject(); &#125; catch (BeanCreationException ex) &#123; // ...忽略代码 &#125; finally &#123; // ...忽略代码 &#125; // 如果实例对象在不存在，我们注册到单例注册表中。 addSingleton(beanName, singletonObject); &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125; &#125; protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, (singletonObject != null ? singletonObject : NULL_OBJECT)); &#125; &#125;&#125; 总结综上述分析.我们可以得出:Spring对Bean实例的创建是采用单例注册表的方式进行实现的，而这个注册表的缓存是 ConcurrentHashMap对象。","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://ltyeamin.github.io/tags/Spring/"}]},{"title":"线程切换导致ThreadLocal数据丢失分析","slug":"线程切换导致ThreadLocal数据丢失分析","date":"2018-03-15T12:51:07.000Z","updated":"2019-05-29T14:03:51.000Z","comments":true,"path":"2018/03/15/线程切换导致ThreadLocal数据丢失分析/","link":"","permalink":"http://ltyeamin.github.io/2018/03/15/线程切换导致ThreadLocal数据丢失分析/","excerpt":"","text":"最近在使用Spring Cloud过程中,经常会遇见线程隔离(切换).导致ThreadLocal数据丢失.例如调用其他服务获取不到Threadlocal没有数据,服务之间传递请求头传递失败.通过查阅相关文档才发现:用Hystrix实现断路器,Zuul中默认使用的是信号量,其他默认都是线程隔离.具体文档如下(可参考Hystrix WIKI)： Thread or Semaphore The default, and the recommended setting, is to run HystrixCommands using thread isolation (THREAD) and HystrixObservableCommands using semaphore isolation (SEMAPHORE). Commands executed in threads have an extra layer of protection against latencies beyond what network timeouts can offer. Generally the only time you should use semaphore isolation for HystrixCommands is when the call is so high volume (hundreds per second, per instance) that the overhead of separate threads is too high; this typically only applies to non-network calls. 在使用线程隔离的时候，有个问题是必须要解决的，那就是在某些业务场景下通过ThreadLocal来在线程里传递数据，用信号量是没问题的，从请求进来，但后续的流程都是通一个线程。当隔离模式为线程时，Hystrix会将请求放入Hystrix的线程池中去执行，这个时候某个请求就有A线程变成B线程了，ThreadLocal必然消失了. 模拟实现 123456789101112131415161718192021222324252627282930313233public class CustomThreadLocal &#123; static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; CustomThreadLocal.threadLocal.set(&quot;彤哥哥&quot;); new Service().call(); &#125; &#125;).start(); &#125;&#125;class Service &#123; public void call() &#123; System.out.println(&quot;Service:&quot; + Thread.currentThread().getName()); System.out.println(&quot;Service:&quot; + CustomThreadLocal.threadLocal.get()); new Dao().call(); &#125;&#125;class Dao &#123; public void call() &#123; System.out.println(&quot;==========================&quot;); System.out.println(&quot;Dao:&quot; + Thread.currentThread().getName()); System.out.println(&quot;Dao:&quot; + CustomThreadLocal.threadLocal.get()); &#125;&#125; 我们在主类中定义了一个ThreadLocal用来传递数据，然后起了一个线程，在线程中调用Service中的call方法，并且往Threadlocal中设置了一个值，在Service中获取ThreadLocal中的值，然后再调用Dao中的call方法，也是获取ThreadLocal中的值，我们运行下看效果：12345Service:Thread-0Service:彤哥哥==========================Dao:Thread-0Dao:彤哥哥 从运行结果来看,同一个线程中能够获得ThreadLocal的值.这个没错,接下来,将Serice类中的call()方法稍微改造一下:1234567891011public void call() &#123; System.out.println(&quot;Service:&quot; + Thread.currentThread().getName()); System.out.println(&quot;Service:&quot; + CustomThreadLocal.threadLocal.get()); //new Dao().call(); new Thread(new Runnable() &#123; @Override public void run() &#123; new Dao().call(); &#125; &#125;).start();&#125; 再次运行结果如下:12345Service:Thread-0Service:彤哥哥==========================Dao:Thread-1Dao:null 由此可见是两个不同的线程,在运行Dao中的call()方法进行了线程切换,所以ThreadLocal获取到的数据未null. InheritableThreadLocal引入既然遇到问题就该解决,那么如何解决呢?其实解决起来很简单,只需要改一行代码即可.1static ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); 将Threadlocal改成子类InheritableThreadLocal后运行结果:12345Service:Thread-0Service:彤哥哥==========================Dao:Thread-1Dao:彤哥哥 非常完美的解决了线程切换导致ThreadLocal拿不到值而产生的问题. 深入InheritableThreadLocal原理要先了解InheritableThreadLocal原理,首先清楚ThreadLocal的原理.话不多说,先分析一下ThreadLocal的原理: 每个线程都有一个ThreadLocalMap类型的threadLocals属性,ThreadLocalMap类相当于一个Map,key 是 ThreadLocal本身,value就是我们设置的值. 123public class Thread implements Runnable &#123; ThreadLocal.ThreadLocalMap threadLocals = null;&#125; 当我们通过threadLocal.set(“彤哥哥”)的时候,就是在这个线程中的threadLocals属性中放入一个键值对,key是 当前线程,value就是你设置的值。 当我们通过 threadlocal.get()方法的时候,就是根据当前线程作为key来获取这个线程设置的值.12345678910111213141516171819202122232425262728293031public class ThreadLocal&lt;T&gt; &#123; public void set(T value) &#123; //获取当前的线程对象 Thread t = Thread.currentThread(); //获取当前线程对象中的threadLocals属性 ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125;&#125; 通过上面的介绍我们可以了解到threadlocal能够传递数据是用Thread.currentThread()当前线程来获取,也就是只要在相同的线程中就可以获取到前面设置进去的值.如果在threadlocal设置完值之后,下步的操作重新创建了一个线程,这个时候Thread.currentThread()就已经变了,那么肯定是拿不到之前设置的值.具体的问题复现可以参考上面我的代码.那为什么InheritableThreadLocal就可以呢?InheritableThreadLocal这个类继承了ThreadLocal,重写了3个方法,在当前线程上创建一个新的线程实例Thread时,会把这些线程变量从当前线程传递给新的线程实例.12345678910111213141516public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; 通过上面的代码我们可以看到InheritableThreadLocal 重写了childValue, getMap,createMap三个方法,我们往里面set值的时候,值保存到了inheritableThreadLocals里面,而不是之前的threadLocals那么关键的点来了,为什么当创建新的线程池,可以获取到上个线程里的threadLocal中的值呢?原因就是在新创建线程的时候,会把之前线程的inheritableThreadLocals赋值给新线程的inheritableThreadLocals,通过这种方式实现了数据的传递.源码最开始在Thread的init()方法中,如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344publicclass Thread implements Runnable &#123; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; //代码省略...... if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) //创建新的ThreadLocalMap并复制给当前线程的inheritableThreadLocals对象 this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); //代码省略...... &#125; static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap); &#125; /** * 赋值代码 */ private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125;&#125; 到此为止,通过inheritableThreadLocals我们可以在父线程创建子线程的时候将Local中的值传递给子线程,这个特性已经能够满足大部分的需求了.但是还有一个很严重的问题是如果是在线程复用的情况下就会出问题,比如线程池中去使用inheritableThreadLocals进行传值,因为inheritableThreadLocals 只是会再新创建线程的时候进行传值,线程复用并不会做这个操作,那么要解决这个问题就得自己去扩展线程类实现这个功能. 阿里解决之道开源的世界应有尽有,为了解决上述遗留的问题,阿里开源了一款Java框架: transmittable-thread-local其主要功能就是解决在使用线程池等会缓存线程的组件情况下,提供ThreadLocal值的传递功能,解决异步执行时上下文传递的问题.JDK的InheritableThreadLocal类可以完成父线程到子线程的值传递.但对于使用线程池等会缓存线程的组件的情况,线程由线程池创建好,并且线程是缓存起来反复使用的;这时父子线程关系的ThreadLocal值传递已经没有意义,应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时.transmittable-thread-local使用方式分为三种:修饰Runnable和Callable,修饰线程池,Java Agent来修饰JDK线程池实现类.接下来给大家演示下线程池的修饰方式,首先来一个非正常的案例,代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041public class CustomThreadLocal &#123; static ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); /** * 创建一个固定大小为2的线程池 */ static ExecutorService pool = Executors.newFixedThreadPool(2); public static void main(String[] args) &#123; for(int i=0;i&lt;100;i++) &#123; int j = i; pool.execute(new Thread(new Runnable() &#123; @Override public void run() &#123; CustomThreadLocal.threadLocal.set(&quot;彤哥哥&quot;+j); new Service().call(); &#125; &#125;)); &#125; &#125;&#125;class Service &#123; public void call() &#123; CustomThreadLocal.pool.execute(new Runnable() &#123; @Override public void run() &#123; new Dao().call(); &#125; &#125;); &#125;&#125;class Dao &#123; public void call() &#123; System.out.println(&quot;Dao:&quot; + CustomThreadLocal.threadLocal.get()); &#125;&#125; 运行上面的代码,出现的结果是不正确的,输出结果如下:12345678910111213Dao:彤哥哥99Dao:彤哥哥99Dao:彤哥哥62Dao:彤哥哥99Dao:彤哥哥62Dao:彤哥哥99Dao:彤哥哥99Dao:彤哥哥62Dao:彤哥哥99Dao:彤哥哥62Dao:彤哥哥62Dao:彤哥哥99省略之后的结果... 正确的应该是从0-99不能有重复,由于线程的复用,值被替换掉了才会出现不正确的结果.接下来使用transmittable-thread-local来改造有问题的代码,添加transmittable-thread-local的Maven依赖：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;transmittable-thread-local&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 只需要修改2个地方,修饰线程池和替换InheritableThreadLocal:12static TransmittableThreadLocal&lt;String&gt; threadLocal = new TransmittableThreadLocal&lt;&gt;();static ExecutorService pool = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(2)); 正确结果如下:123456789101112Dao:彤哥哥1Dao:彤哥哥2Dao:彤哥哥4Dao:彤哥哥5Dao:彤哥哥3Dao:彤哥哥6Dao:彤哥哥7Dao:彤哥哥8Dao:彤哥哥9Dao:彤哥哥10Dao:彤哥哥11省略之后的结果... 到这里我们就已经可以完美的解决线程中,线程池中ThreadLocal数据的传递了,题主趁着中午喝茶的时间,无意间找到其他解决方案,下节继续用其他方式进行解决.","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ltyeamin.github.io/tags/Java/"}]},{"title":"使用Jenkins进行持续集成","slug":"使用Jenkins进行持续集成","date":"2018-02-07T12:18:53.000Z","updated":"2019-11-20T15:08:57.032Z","comments":true,"path":"2018/02/07/使用Jenkins进行持续集成/","link":"","permalink":"http://ltyeamin.github.io/2018/02/07/使用Jenkins进行持续集成/","excerpt":"","text":"Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。 安装Jenkins首先我们去Jenkins官方网站下载最新的部署包(.war):Jenkins.因为我是在Linux平台部署,需要注意的是Jenkins是基于Java构建的,所以我们必须安装好JDK系列的依赖才行.Linux安装JDK时候先卸载本身自带的OpenJDK再进行安装,并配置好环境变量.JDK安装我不在累述,读者可自行百度. 12# 通过wget方式下载Tomcat和Jenkins安装包[root@localhost bin]# wget http://mirrors.jenkins.io/war/latest/jenkins.war 下载完成后会在当前目录出现jenkins.war,因为Jenkins内嵌Jetty服务器(也可以部署在Tomcat容器里),可以执行如下命令启动.1[root@localhost bin]# java -jar jenkins.war 执行以下命令,会打印出如下日志信息:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182Running from: /usr/local/bin/jenkins.warwebroot: $user.home/.jenkins二月 06, 2018 11:19:44 上午 Main deleteWinstoneTempContents警告: Failed to delete the temporary Winstone file /tmp/winstone/jenkins.war二月 06, 2018 11:19:44 上午 org.eclipse.jetty.util.log.Log initialized信息: Logging initialized @1303ms to org.eclipse.jetty.util.log.JavaUtilLog二月 06, 2018 11:19:44 上午 winstone.Logger logInternal信息: Beginning extraction from war file二月 06, 2018 11:19:47 上午 org.eclipse.jetty.server.handler.ContextHandler setContextPath警告: Empty contextPath二月 06, 2018 11:19:47 上午 org.eclipse.jetty.server.Server doStart信息: jetty-9.4.z-SNAPSHOT二月 06, 2018 11:19:47 上午 org.eclipse.jetty.webapp.StandardDescriptorProcessor visitServlet信息: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet二月 06, 2018 11:19:48 上午 org.eclipse.jetty.server.session.DefaultSessionIdManager doStart信息: DefaultSessionIdManager workerName=node0二月 06, 2018 11:19:48 上午 org.eclipse.jetty.server.session.DefaultSessionIdManager doStart信息: No SessionScavenger set, using defaults二月 06, 2018 11:19:48 上午 org.eclipse.jetty.server.session.HouseKeeper startScavenging信息: Scavenging every 600000msJenkins home directory: /root/.jenkins found at: $user.home/.jenkins二月 06, 2018 11:19:49 上午 org.eclipse.jetty.server.handler.ContextHandler doStart信息: Started w.@f9b7332&#123;/,file:///root/.jenkins/war/,AVAILABLE&#125;&#123;/root/.jenkins/war&#125;二月 06, 2018 11:19:49 上午 org.eclipse.jetty.server.AbstractConnector doStart信息: Started ServerConnector@2baa8d82&#123;HTTP/1.1,[http/1.1]&#125;&#123;0.0.0.0:8080&#125;二月 06, 2018 11:19:49 上午 org.eclipse.jetty.server.Server doStart信息: Started @6419ms二月 06, 2018 11:19:49 上午 winstone.Logger logInternal信息: Winstone Servlet Engine v4.0 running: controlPort=disabled二月 06, 2018 11:19:52 上午 jenkins.InitReactorRunner$1 onAttained信息: Started initialization二月 06, 2018 11:19:52 上午 jenkins.InitReactorRunner$1 onAttained信息: Listed all plugins二月 06, 2018 11:19:56 上午 jenkins.InitReactorRunner$1 onAttained信息: Prepared all plugins二月 06, 2018 11:19:56 上午 jenkins.InitReactorRunner$1 onAttained信息: Started all plugins二月 06, 2018 11:19:56 上午 jenkins.InitReactorRunner$1 onAttained信息: Augmented all extensions二月 06, 2018 11:19:59 上午 jenkins.InitReactorRunner$1 onAttained信息: Loaded all jobs二月 06, 2018 11:19:59 上午 hudson.eureka1-server.AsyncPeriodicWork$1 run信息: Started Download metadata二月 06, 2018 11:20:00 上午 jenkins.InitReactorRunner$1 onAttained信息: Completed initialization二月 06, 2018 11:20:02 上午 org.springframework.context.support.AbstractApplicationContext prepareRefresh信息: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@fabd330: display name [Root WebApplicationContext]; startup date [Tue Feb 06 11:20:02 CST 2018]; root of context hierarchy二月 06, 2018 11:20:02 上午 org.springframework.context.support.AbstractApplicationContext obtainFreshBeanFactory信息: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@fabd330]: org.springframework.beans.factory.support.DefaultListableBeanFactory@1452b2bc二月 06, 2018 11:20:02 上午 org.springframework.beans.factory.support.DefaultListableBeanFactory preInstantiateSingletons信息: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@1452b2bc: defining beans [authenticationManager]; root of factory hierarchy二月 06, 2018 11:20:02 上午 org.springframework.context.support.AbstractApplicationContext prepareRefresh信息: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@1a724d6e: display name [Root WebApplicationContext]; startup date [Tue Feb 06 11:20:02 CST 2018]; root of context hierarchy二月 06, 2018 11:20:02 上午 org.springframework.context.support.AbstractApplicationContext obtainFreshBeanFactory信息: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@1a724d6e]: org.springframework.beans.factory.support.DefaultListableBeanFactory@7be61840二月 06, 2018 11:20:02 上午 org.springframework.beans.factory.support.DefaultListableBeanFactory preInstantiateSingletons信息: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@7be61840: defining beans [filter,legacy]; root of factory hierarchy二月 06, 2018 11:20:03 上午 jenkins.install.SetupWizard init信息: ***************************************************************************************************************************************************************************************Jenkins initial setup is required. An admin user has been created and a password generated.Please use the following password to proceed to installation:00caaea4ac874d4db11cb31c27e5c7ceThis may also be found at: /root/.jenkins/secrets/initialAdminPassword***************************************************************************************************************************************************************************************二月 06, 2018 11:21:34 上午 hudson.eureka1-server.UpdateSite updateData信息: Obtained the latest update center data file for UpdateSource default二月 06, 2018 11:21:37 上午 hudson.eureka1-server.UpdateSite updateData信息: Obtained the latest update center data file for UpdateSource default二月 06, 2018 11:21:37 上午 hudson.WebAppMain$3 run信息: Jenkins is fully up and running二月 06, 2018 11:21:37 上午 hudson.eureka1-server.DownloadService$Downloadable load信息: Obtained the updated data file for hudson.tasks.Maven.MavenInstaller 启动成功后,浏览器输入http://192.168.64.128:8080,则会进入以下界面:获取口令有好几种方式: 上述启动日志里,这里口令为:00caaea4ac874d4db11cb31c27e5c7ce /root/.jenkins/secrets/initialAdminPassword复制口令填充进去并点击继续则进入下列界面:这里我们选择安装推荐的默认安装方式,Jenkins就自动配置好了一些常用插件.最后,创建一个admin用户,完成安装.Jenkins配置安装完成后,我们需要手动配置一些插件.如JDK,Maven,Git,Gradle等常用插件. 首页——&gt;系统管理—-&gt; 全局工具管理1234567891011# 下载maven-Dmaven.test.skip=truevi seting&lt;localRepository&gt;/usr/local/bin/apache-maven-3.5.2/repository&lt;/localRepository&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; Git我们选择默认安装,JDK手动去配置. 首页——&gt;系统管理—-&gt; 管理插件—–&gt;可选插件—-&gt;过滤——&gt;输入:Maven Integration plugin或者Git plugin—–&gt;选择性安装插件 构建自动化部署Git项目地址: https://gitee.com/ltalex/GitCeShi.git在Jenkins首页选择新建任务,如下 以下配置表示maven构建结束后执行的脚本(Execute shell)1234/usr/local/eureka/stop.sh/usr/local/eureka/replace.sh# 理论来说可以这样写nohup java -jar xxx.jar &amp;,但是这种配置在jenkis是无效的BUILD_ID=dontKillMe nohup /usr/local/eureka/startup.sh &amp; 停止脚本123456789# 将应用停止#stop.sh#!/bin/bashecho &quot;Stopping SpringBoot Application&quot;pid=`ps -ef | grep eureka1-server.jar | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`if [ -n &quot;$pid&quot; ]then kill -9 $pidfi 备份脚本123456789#replace.sh 用于将上次构建的结果备份，然后将新的构建结果移动到合适的位置#!/bin/bash# 先判断文件是否存在，如果存在，则备份file=&quot;/usr/local/eureka/eureka1-server.jar&quot;if [ -f &quot;$file&quot; ]then mv /usr/local/eureka/eureka1-server.jar /usr/local/eureka/backup/eureka1-server.jar.`date +%Y%m%d%H%M%S`fimv /root/.jenkins/workspace/Test/target/eureka1-server.jar /usr/local/eureka/eureka1-server.jar 启动脚本123456# startup.sh 启动项目#!/bin/shecho &quot;授予当前用户权限&quot;chmod 777 /usr/local/eureka/eureka1-server.jarecho &quot;执行.....&quot;java -jar /usr/local/eureka/eureka1-server.jar 点击立即构建,Console会出现如下信息: 部署成功后,访问http://192.168.64.128:8099/,如下图: 遇到的问题 在部署的时候会出现java -jar出现没有主清单属性的问题,那是因为项目中Pom文件没有配置SpringBoot插件,导致在jar包中MANIFEST.MF文件没有启动信息12java -jar eureka1-server.jareureka1-server.jar中没有主清单属性 解决方案:1234567891011&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 构建成功后的脚本,即Execute shell尽量执行远程的shell脚本,不要直接在里面启动项目,因为项目启动后会一直停留,Jenkins就是构建成功也不会停止当前项目的构建状态. 可以定制构建出发器,当我们希望push一些东西能够立马构建项目时,可在构建触发器中勾选Poll SCM日程表表填写表达式:* * * * *","categories":[{"name":"ops","slug":"ops","permalink":"http://ltyeamin.github.io/categories/ops/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://ltyeamin.github.io/tags/Jenkins/"}]},{"title":"浅谈匿名函数,Lambda和闭包(Closure)","slug":"浅谈匿名函数,Lambda,闭包(Closure)","date":"2018-01-30T09:46:04.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2018/01/30/浅谈匿名函数,Lambda,闭包(Closure)/","link":"","permalink":"http://ltyeamin.github.io/2018/01/30/浅谈匿名函数,Lambda,闭包(Closure)/","excerpt":"","text":"几乎所有的主流编程语言都对函数式编程有支持,我所用过的比如Java8的Lambda表达式,JavaScript和Groovy语言的闭包(Closure)等,其他的类似于Object-C的block,python的Lambda和C++11,看到这些,我都有点眩晕想吐的感觉. 匿名函数,Lambda,闭包(Closure)区别从表象上说Lambda和Closure是一个东西,只是语言不同罢了,它们都可以去替代匿名函数用于简化书写,匿名函数内部可以访问到外部变量.从而形成一个”闭包”.记住,这只是表象.下面就让你怀疑人生?真的是一样吗? Java中Lambda表达式浅谈其实Java在很早的版本就支持闭包,只是因为应用场景太少了,所以这个概念才从Java8推广.话不多说,先上代码: 12345678910111213141516171819202122public static Supplier&lt;Integer&gt; testClosure()&#123; final int i = 1; return new Supplier&lt;Integer&gt;() &#123; @Override public Integer get() &#123; return i; &#125; &#125;;&#125;public interface Supplier&lt;T&gt; &#123; T get();&#125; 上述代码中,变量i是testClosure()的局部变量,但是最终返回里的匿名对象里,仍然返回了i.我们知道，函数的局部变量，其作用域仅限于函数内部，在函数结束时，局部变量i从栈内存消失了,就应该是不可见状态，而闭包则将i的生存周期延长了，并且使得变量可以被外部函数所引用。在JDK8之前,如果访问i,变量i必须加final关键字修饰,让i成为变为常量池中的常量以延迟i的生命周期.而在JDK8中以Lambda表达式方式写,i则不需要加,这里只是个语法糖,因为底层.class文件会自动推断加上.在Java的经典著作《Effective Java》、《Java Concurrency in Practice》里，大神们都提到：匿名函数里的变量引用，也叫做变量引用泄露，会导致线程安全问题，因此在Java8之前，如果在匿名类内部引用函数局部变量，必须将其声明为final，即不可变对象。(Python和Javascript从一开始就是为单线程而生的语言，一般也不会考虑这样的问题，所以它的外部变量是可以任意修改的)。如果用Java8的Lambda改写上述代码,则为:1234567891011public static Supplier&lt;Integer&gt; testClosure() &#123; int i = 1; return () -&gt; &#123; //单个语句,可以省略&#123;&#125; return i; &#125;;&#125; Wow,突然感觉改写后的代码简洁明了,高端大气上档次.","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ltyeamin.github.io/tags/Java/"}]},{"title":"Spring Cloud-使用高性能的OkHttp库","slug":"Spring Cloud-使用高性能的OkHttp库","date":"2018-01-30T01:27:55.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2018/01/30/Spring Cloud-使用高性能的OkHttp库/","link":"","permalink":"http://ltyeamin.github.io/2018/01/30/Spring Cloud-使用高性能的OkHttp库/","excerpt":"","text":"最近在做项目优化,研究了Spring Cloud底层源码,Http请求库默认是Apache HttpClient或者JDK自带的HttpURLConnection库.Java标准库提供了HttpURLConnection类来支持HTTP通讯。不过HttpURLConnection本身的API不够友好，所提供的功能也有限。大部分Java程序都选择使用Apache的开源项目HttpClient作为HTTP客户端。ApacheHttpClient库的功能强大，使用率也很高，基本上是Java平台中事实上的标准HTTP客户端,但是做Android的小伙伴早已经淘汰该库了,就是因为其API数量过多过于繁重,使得我们很难在不破坏兼容性的情况下对它进行升级和扩展,因而团队不愿意去维护该库.本章介绍的是由 Square 公司开发的OkHttp，是一个专注于性能和易用性的 HTTP 客户端。OkHttp 库的设计和实现的首要目标是高效.支持SPDY,,可以合并多个到同一个主机的请求, 使用连接池技术减少请求的延迟(如果SPDY是可用的话),使用GZIP压缩减少传输的数据量,缓存响应避免重复的网络请求,当网络出现问题时，OkHttp 会自动重试一个主机的多个IP地址。 OkHttp在Zuul中的应用话说至此,有些人可能又疑问?我怎么知道默认底层用的是的Apache Client?我在公司负责Zuul网关模块,Zuul的动态路由转发用Ribbon调用.查看官方文档,如下: 19.3 Zuul Http ClientThe default HTTP client used by zuul is now backed by the Apache HTTP Client instead of the deprecated Ribbon RestClient. To use RestClient or to use the okhttp3.OkHttpClient set ribbon.restclient.enabled=true or ribbon.okhttp.enabled=true respectively. If you would like to customize the Apache HTTP client or the OK HTTP client provide a bean of type ClosableHttpClient or OkHttpClient.1234567参照上述官方文档说明,解决方案已经明了,具体实施如下:1.确保你的项目有okhttp依赖:&lt;!-- OkHttp --&gt;&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; application.yml添加ribbon配置 12345ribbon: httpclient: enabled: false # 默认开启需要禁用 okhttp: enabled: true 测试替换是否成功a,将GateWay服务日志设置为DEBUG模式进行调用,查看日志会有许多有关OkHttp的东西,但日志打印太多,不易捕获,不易观察 12345678910111213141516RibbonCommandFactoryConfiguration.HttpClientRibbonConfiguration matched:- AnyNestedCondition 1 matched 1 did not; NestedCondition on RibbonCommandFactoryConfiguration.OnRibbonHttpClientCondition.RibbonProperty@ConditionalOnProperty (ribbon.httpclient.enabled) found different value in property &apos;ribbon.httpclient.enabled&apos;; NestedCondition on RibbonCommandFactoryConfiguration.OnRibbonHttpClientCondition.ZuulProperty @ConditionalOnProperty (zuul.ribbon.httpclient.enabled) matched (RibbonCommandFactoryConfiguration.OnRibbonHttpClientCondition)RibbonCommandFactoryConfiguration.OkHttpRibbonConfigurationmatched:-@ConditionalOnClass found required class &apos;okhttp3.OkHttpClient&apos;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition)- AnyNestedCondition 1 matched 1 did not; NestedCondition on RibbonCommandFactoryConfiguration.OnRibbonOkHttpClientCondition.RibbonProperty@ConditionalOnProperty (ribbon.okhttp.enabled) matched; NestedCondition on RibbonCommandFactoryConfiguration.OnRibbonOkHttpClientCondition.ZuulProperty @ConditionalOnProperty (zuul.ribbon.okhttp.enabled) did not find property &apos;zuul.ribbon.okhttp.enabled&apos; (RibbonCommandFactoryConfiguration.OnRibbonOkHttpClientCondition) b,Debug启动GateWay服务,通过源码方式查看RibbonCommandFactoryConfiguration实际配置的Http客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package org.springframework.cloud.netflix.zuul;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import java.util.Collections;import java.util.Set;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.AnyNestedCondition;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.cloud.netflix.ribbon.SpringClientFactory;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.cloud.netflix.zuul.filters.route.RestClientRibbonCommandFactory;import org.springframework.cloud.netflix.zuul.filters.route.RibbonCommandFactory;import org.springframework.cloud.netflix.zuul.filters.route.ZuulFallbackProvider;import org.springframework.cloud.netflix.zuul.filters.route.apache.HttpClientRibbonCommandFactory;import org.springframework.cloud.netflix.zuul.filters.route.okhttp.OkHttpRibbonCommandFactory;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Conditional;import org.springframework.context.annotation.Configuration;/** * @author Dave Syer * */public class RibbonCommandFactoryConfiguration &#123; @Configuration @ConditionalOnRibbonRestClient protected static class RestClientRibbonConfiguration &#123; @Autowired(required = false) private Set&lt;ZuulFallbackProvider&gt; zuulFallbackProviders = Collections.emptySet(); @Bean @ConditionalOnMissingBean public RibbonCommandFactory&lt;?&gt; ribbonCommandFactory( SpringClientFactory clientFactory, ZuulProperties zuulProperties) &#123; return new RestClientRibbonCommandFactory(clientFactory, zuulProperties, zuulFallbackProviders); &#125; &#125; @Configuration @ConditionalOnRibbonOkHttpClient @ConditionalOnClass(name = &quot;okhttp3.OkHttpClient&quot;) protected static class OkHttpRibbonConfiguration &#123; @Autowired(required = false) private Set&lt;ZuulFallbackProvider&gt; zuulFallbackProviders = Collections.emptySet(); @Bean @ConditionalOnMissingBean public RibbonCommandFactory&lt;?&gt; ribbonCommandFactory( SpringClientFactory clientFactory, ZuulProperties zuulProperties) &#123; return new OkHttpRibbonCommandFactory(clientFactory, zuulProperties, zuulFallbackProviders); &#125; &#125; @Configuration @ConditionalOnRibbonHttpClient protected static class HttpClientRibbonConfiguration &#123; @Autowired(required = false) private Set&lt;ZuulFallbackProvider&gt; zuulFallbackProviders = Collections.emptySet(); @Bean @ConditionalOnMissingBean public RibbonCommandFactory&lt;?&gt; ribbonCommandFactory( SpringClientFactory clientFactory, ZuulProperties zuulProperties) &#123; return new HttpClientRibbonCommandFactory(clientFactory, zuulProperties, zuulFallbackProviders); &#125; &#125; @Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(OnRibbonHttpClientCondition.class) @interface ConditionalOnRibbonHttpClient &#123; &#125; private static class OnRibbonHttpClientCondition extends AnyNestedCondition &#123; public OnRibbonHttpClientCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @Deprecated //remove in Edgware&quot; @ConditionalOnProperty(name = &quot;zuul.ribbon.httpclient.enabled&quot;, matchIfMissing = true) static class ZuulProperty &#123;&#125; @ConditionalOnProperty(name = &quot;ribbon.httpclient.enabled&quot;, matchIfMissing = true) static class RibbonProperty &#123;&#125; &#125; @Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(OnRibbonOkHttpClientCondition.class) @interface ConditionalOnRibbonOkHttpClient &#123; &#125; private static class OnRibbonOkHttpClientCondition extends AnyNestedCondition &#123; public OnRibbonOkHttpClientCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @Deprecated //remove in Edgware&quot; @ConditionalOnProperty(&quot;zuul.ribbon.okhttp.enabled&quot;) static class ZuulProperty &#123;&#125; @ConditionalOnProperty(&quot;ribbon.okhttp.enabled&quot;) static class RibbonProperty &#123;&#125; &#125; @Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(OnRibbonRestClientCondition.class) @interface ConditionalOnRibbonRestClient &#123; &#125; private static class OnRibbonRestClientCondition extends AnyNestedCondition &#123; public OnRibbonRestClientCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @Deprecated //remove in Edgware&quot; @ConditionalOnProperty(&quot;zuul.ribbon.restclient.enabled&quot;) static class ZuulProperty &#123;&#125; @ConditionalOnProperty(&quot;ribbon.restclient.enabled&quot;) static class RibbonProperty &#123;&#125; &#125; &#125; 解读:我们很清楚Zuul的负载均衡实现就通过Ribbon的实现,所以Http客户端的配置自然也是对Ribbon组件的配置,源代码中很明显都是通过@Conditional实现了条件加载,其中该类提供了不止一种的Http客户端(RestClient,默认的HttpClient,OkhttpClient)配置实现.要想确保改造成功,则需要在其内部类OkHttpRibbonConfiguration中的RibbonCommandFactory打上端点,看有没有进即可. Feign中Okhttp应用大家也都知道Fegin的底层也是Ribbon,上述方式可以解决,但是更推荐Feign端开始解决. 首先在服务调用方加入以下依赖 12345&lt;!-- feign整合OkHttp --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 在application.yml文件配置 12345feign: httpclient: enabled: false okhttp: enabled: true 测试是否配置成功a, 启动服务进行接口调用,可以分析日志 1234567891011121314151617181920[2018-01-30 13:04:03.398] [DEBUG] [restartedMain] o.s.c.e.PropertySourcesPropertyResolver -Found key &apos;feign.okhttp.enabled&apos; in [applicationConfigurationProperties] with type [String][2018-01-30 13:04:03.398] [DEBUG] [restartedMain] o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &apos;autoConfigurationReport&apos;[2018-01-30 13:04:03.398] [DEBUG] [restartedMain] o.s.c.a.ConfigurationClassBeanDefinitionReader - Registered bean definition for imported class &apos;org.springframework.cloud.netflix.feign.ribbon.FeignRibbonClientAutoConfiguration$OkHttpFeignLoadBalancedConfiguration&apos;[2018-01-30 13:04:03.399] [DEBUG] [restartedMain] o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &apos;org.springframework.boot.autoconfigure.condition.BeanTypeRegistry&apos;[2018-01-30 13:04:03.399] [DEBUG] [restartedMain] o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &apos;org.springframework.boot.autoconfigure.condition.BeanTypeRegistry&apos;[2018-01-30 13:04:03.399] [DEBUG] [restartedMain] o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &apos;autoConfigurationReport&apos;[2018-01-30 13:04:03.399] [DEBUG] [restartedMain] o.s.c.a.ConfigurationClassBeanDefinitionReader -Registering bean definition for @Bean method org.springframework.cloud.netflix.feign.ribbon.FeignRibbonClientAutoConfiguration$OkHttpFeignLoadBalancedConfigur 如上述日志文件Found key ‘feign.okhttp.enabled’可以看出替换成功.b, 分析调用源码来测试是否成功替换成Okhttp其自动装配源码在FeignRibbonClientAutoConfiguration中12345678910111213141516171819@ConditionalOnClass(&#123; ILoadBalancer.class, Feign.class &#125;)@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)//Order is important here, last should be the default, first should be optional@Import(&#123; HttpClientFeignLoadBalancedConfiguration.class, OkHttpFeignLoadBalancedConfiguration.class, DefaultFeignLoadBalancedConfiguration.class &#125;)public class FeignRibbonClientAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; //Feign默认的客户端是Client.Default return new LoadBalancerFeignClient(new Client.Default(null, null), cachingFactory, clientFactory); &#125; //省略类中的内容...&#125; 从该类中的注释可以看出,DefaultFeignLoadBalancedConfiguration.class是默认配置,HttpClientFeignLoadBalancedConfiguration.class是可选的.Debug启动服务并进行远程Feign的一路调用发现,会走如下的方法:123456789101112131415161718192021222324252627282930313233343536373839404142final class SynchronousMethodHandler implements MethodHandler &#123; @Override public Object invoke(Object[] argv) throws Throwable &#123; RequestTemplate template = buildTemplateFromArgs.create(argv); Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; return executeAndDecode(template); &#125; catch (RetryableException e) &#123; retryer.continueOrPropagate(e); if (logLevel != Logger.Level.NONE) &#123; logger.logRetry(metadata.configKey(), logLevel); &#125; continue; &#125; &#125; &#125; Object executeAndDecode(RequestTemplate template) throws Throwable &#123; Request request = targetRequest(template); if (logLevel != Logger.Level.NONE) &#123; logger.logRequest(metadata.configKey(), logLevel, request); &#125; Response response; long start = System.nanoTime(); try &#123; response = client.execute(request, options); // ensure the request is set. TODO: remove in Feign 10 response.toBuilder().request(request).build(); &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start)); &#125; throw errorExecuting(request, e); &#125; //省略代码...... &#125;&#125; 我们发现SynchronousMethodHandler中的invoke()方法又去调用executeAndDecode()方法,在执行下列一段代码的时候,你会发现到底是用哪个Http客户端进行调用1response = client.execute(request, options); Client是Feign的Client接口声明,这时候会有好几个实现:Default,LoadBalancerFeignClinet,OkHttpClient,TraceFeignClient.这下明显了,如果你的classpath下有okhttp的依赖,则会走feign.okhttp.OkHttpClient.execute()方法,如果没有依赖,就会走feign.Client.Default.execute()方法.okhttp没什么说的,可以看一下默认的Feign Client - Default中的execute()代码片段:12345@Override public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build(); &#125; 由上面代码片段可以得出,Spring Cloud默认Feign的客户端是HttpURLConnection构建的.需要注意的是,无论Feign是哪种Client,默认都是开启的,重点在于classpath下的依赖,而不是application.yml里的开关配置.之所以配置开关是因为关闭掉无用的Client. 默认配置解说Feign 读取时间配置：默认读取连接时间10s,默认连接读取时间60s源码:123456789101112131415161718public final class Request &#123; public static class Options &#123; private final int connectTimeoutMillis; private final int readTimeoutMillis; public Options(int connectTimeoutMillis, int readTimeoutMillis) &#123; this.connectTimeoutMillis = connectTimeoutMillis; this.readTimeoutMillis = readTimeoutMillis; &#125; //默认构造器时间 public Options() &#123; this(10 * 1000, 60 * 1000); &#125; &#125;&#125; 手动设置默认的读取时间和连接时间:1234@Beanpublic Request.Options options() &#123; Request.Options options = new Request.Options(5 * 1000, 5 * 1000);&#125; 手动配置Okhttp312345678910111213141516171819@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig &#123; @Autowired OkHttpLoggingInterceptor okHttpLoggingInterceptor; @Bean public okhttp3.OkHttpClient okHttpClient()&#123; return new okhttp3.OkHttpClient.Builder() .readTimeout(60, TimeUnit.SECONDS) //设置读取超时时间 .connectTimeout(60, TimeUnit.SECONDS) //设置连接超时时间 .writeTimeout(120, TimeUnit.SECONDS) .connectionPool(new ConnectionPool()) // .addInterceptor(); //添加请求拦截器 .build(); &#125;&#125; 参考文献:官方文档Feign产生的问题Feign源码解读","categories":[{"name":"backend","slug":"backend","permalink":"http://ltyeamin.github.io/categories/backend/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ltyeamin.github.io/tags/Spring-Cloud/"}]},{"title":"ES6新的数据类型-generator","slug":"ES6新的数据类型-generator","date":"2017-12-15T07:39:23.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2017/12/15/ES6新的数据类型-generator/","link":"","permalink":"http://ltyeamin.github.io/2017/12/15/ES6新的数据类型-generator/","excerpt":"","text":"新的数据类型-generatorgenerator（生成器）是ES6标准引入的新的数据类型。一个generator看上去像一个函数，但可以返回多次.ES6定义generator标准的哥们借鉴了Python的generator的概念和语法.我们先复习函数的概念。一个函数是一段完整的代码，调用一个函数就是传入参数，然后返回结果:1234function foo(x) &#123; return x + x;&#125;var r = foo(1); // 调用foo函数 函数在执行过程中，如果没有遇到return语句（函数末尾如果没有return，就是隐含的return undefined;），控制权无法交回被调用的代码。generator跟函数很像，定义如下:12345function* foo(x) &#123; yield x + 1; yield x + 2; return x + 3;&#125; generator和函数不同的是，generator由function定义（注意多出的号），并且，除了return语句，还可以用yield返回多次。大多数同学立刻就晕了，generator就是能够返回多次的“函数”？返回多次有啥用？还是举个例子吧。我们以一个著名的斐波那契数列为例，它由0，1开头:10 1 1 2 3 5 8 13 21 34 ... 要编写一个产生斐波那契数列的函数，可以这么写:12345678910111213141516function fib(max) &#123; var t, a = 0, b = 1, arr = [0, 1]; while (arr.length &lt; max) &#123; [a, b] = [b, a + b]; arr.push(b); &#125; return arr;&#125;// 测试:fib(5); // [0, 1, 1, 2, 3]fib(10); // [0, 1, 1, 2, 3, 5, 8, 13, 21, 34] 函数只能返回一次，所以必须返回一个Array。但是，如果换成generator，就可以一次返回一个数，不断返回多次。用generator改写如下:12345678910111213function* fib(max) &#123; var t, a = 0, b = 1, n = 0; while (n &lt; max) &#123; yield a; [a, b] = [b, a + b]; n ++; &#125; return;&#125; 直接调用试试:1fib(5); // fib &#123;[[GeneratorStatus]]: &quot;suspended&quot;, [[GeneratorReceiver]]: Window&#125; 直接调用一个generator和调用函数不一样，fib(5)仅仅是创建了一个generator对象，还没有去执行它。调用generator对象有两个方法，一是不断地调用generator对象的next()方法:1234567var f = fib(5);f.next(); // &#123;value: 0, done: false&#125;f.next(); // &#123;value: 1, done: false&#125;f.next(); // &#123;value: 1, done: false&#125;f.next(); // &#123;value: 2, done: false&#125;f.next(); // &#123;value: 3, done: false&#125;f.next(); // &#123;value: undefined, done: true&#125; next()方法会执行generator的代码，然后，每次遇到yield x;就返回一个对象{value: x, done: true/false}，然后“暂停”。返回的value就是yield的返回值，done表示这个generator是否已经执行结束了。如果done为true，则value就是return的返回值。当执行到done为true时，这个generator对象就已经全部执行完毕，不要再继续调用next()了。第二个方法是直接用for … of循环迭代generator对象，这种方式不需要我们自己判断done:123for (var x of fib(10)) &#123; console.log(x); // 依次输出0, 1, 1, 2, 3, ...&#125; generator和普通函数相比，有什么用?因为generator可以在执行过程中多次返回，所以它看上去就像一个可以记住执行状态的函数，利用这一点，写一个generator就可以实现需要用面向对象才能实现的功能。例如，用一个对象来保存状态，得这么写:12345678910111213141516171819var fib = &#123; a: 0, b: 1, n: 0, max: 5, next: function () &#123; var r = this.a, t = this.a + this.b; this.a = this.b; this.b = t; if (this.n &lt; this.max) &#123; this.n ++; return r; &#125; else &#123; return undefined; &#125; &#125;&#125;; 用对象的属性来保存状态，相当繁琐。generator还有另一个巨大的好处，就是把异步回调代码变成”同步”代码。这个好处要等到后面学了AJAX以后才能体会到。没有generator之前的黑暗时代，用AJAX时需要这么写代码:12345678910111213141516ajax(&apos;http://url-1&apos;, data1, function (err, result) &#123; if (err) &#123; return handle(err); &#125; ajax(&apos;http://url-2&apos;, data2, function (err, result) &#123; if (err) &#123; return handle(err); &#125; ajax(&apos;http://url-3&apos;, data3, function (err, result) &#123; if (err) &#123; return handle(err); &#125; return success(result); &#125;); &#125;);&#125;); 回调越多，代码越难看。有了generator的美好时代，用AJAX时可以这么写:123456789try &#123; r1 = yield ajax(&apos;http://url-1&apos;, data1); r2 = yield ajax(&apos;http://url-2&apos;, data2); r3 = yield ajax(&apos;http://url-3&apos;, data3); success(r3);&#125;catch (err) &#123; handle(err);&#125; 看上去是同步的代码，实际执行是异步的.","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"箭头函数","slug":"箭头函数","date":"2017-12-15T07:10:46.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2017/12/15/箭头函数/","link":"","permalink":"http://ltyeamin.github.io/2017/12/15/箭头函数/","excerpt":"","text":"箭头函数ES6标准新增了一种新的函数：Arrow Function（箭头函数）。为什么叫Arrow Function？因为它的定义用的就是一个箭头:12var fn = x =&gt; x * x;alert(fn(5)); //25 上面的箭头函数相当于:1234function (x) &#123; return x * x;&#125;alert(fn(5)); //25 箭头函数相当于匿名函数，并且简化了函数定义。箭头函数有两种格式，一种像上面的，只包含一个表达式，连{ … }和return都省略掉了。还有一种可以包含多条语句，这时候就不能省略{ … }和return:12345678x =&gt; &#123; if (x &gt; 0) &#123; return x * x; &#125; else &#123; return - x * x; &#125;&#125; 如果参数不是一个，就需要用括号()括起来:1234567891011121314// 两个参数:(x, y) =&gt; x * x + y * y// 无参数:() =&gt; 3.14// 可变参数:(x, y, ...rest) =&gt; &#123; var i, sum = x + y; for (i=0; i&lt;rest.length; i++) &#123; sum += rest[i]; &#125; return sum;&#125; 如果要返回一个对象，就要注意，如果是单表达式，这么写的话会报错:12// SyntaxError:x =&gt; &#123; foo: x &#125; 因为和函数体的{ … }有语法冲突，所以要改为:12// ok:x =&gt; (&#123; foo: x &#125;) 解决this绑定错误的问题箭头函数看上去是匿名函数的一种简写，但实际上，箭头函数和匿名函数有个明显的区别：箭头函数内部的this是词法作用域，由上下文确定。回顾前面的例子，由于JavaScript函数对this绑定的错误处理，下面的例子无法得到预期结果:12345678910var obj = &#123; birth: 1990, getAge: function () &#123; var b = this.birth; // 1990 var fn = function () &#123; return new Date().getFullYear() - this.birth; // this指向window或undefined &#125;; return fn(); &#125;&#125;; 现在，箭头函数完全修复了this的指向，this总是指向词法作用域，也就是外层调用者obj:123456789var obj = &#123; birth: 1990, getAge: function () &#123; var b = this.birth; // 1990 var fn = () =&gt; new Date().getFullYear() - this.birth; // this指向obj对象 return fn(); &#125;&#125;;obj.getAge(); // 25 如果使用箭头函数，以前的那种hack写法:1var that = this; 就不再需要了。由于this在箭头函数中已经按照词法作用域绑定了，所以，用call()或者apply()调用箭头函数时，无法对this进行绑定，即传入的第一个参数被忽略:123456789var obj = &#123; birth: 1990, getAge: function (year) &#123; var b = this.birth; // 1990 var fn = (y) =&gt; y - this.birth; // this.birth仍是1990 return fn.call(&#123;birth:2000&#125;, year); &#125;&#125;;obj.getAge(2015); // 25","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"闭包","slug":"闭包","date":"2017-12-13T09:54:10.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2017/12/13/闭包/","link":"","permalink":"http://ltyeamin.github.io/2017/12/13/闭包/","excerpt":"","text":"函数作为返回值高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。我们来实现一个对Array的求和。通常情况下，求和的函数是这样定义的:123456function sum(arr) &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;);&#125;sum([1, 2, 3, 4, 5]); // 15 但是，如果不需要立刻求和，而是在后面的代码中，根据需要再计算怎么办？可以不返回求和的结果，而是返回求和的函数!12345678function lazy_sum(arr) &#123; var sum = function () &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;); &#125; return sum;&#125; 当我们调用lazy_sum()时，返回的并不是求和结果，而是求和函数:1var f = lazy_sum([1, 2, 3, 4, 5]); // function sum() 调用函数f时，才真正计算求和的结果:1f(); // 15 在这个例子中，我们在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”的程序结构拥有极大的威力。请再注意一点，当我们调用lazy_sum()时，每次调用都会返回一个新的函数，即使传入相同的参数:123var f1 = lazy_sum([1, 2, 3, 4, 5]);var f2 = lazy_sum([1, 2, 3, 4, 5]);f1 === f2; // false f1()和f2()的调用结果互不影响。 闭包注意到返回的函数在其定义内部引用了局部变量arr，所以，当一个函数返回了一个函数后，其内部的局部变量还被新函数引用，所以，闭包用起来简单，实现起来可不容易。另一个需要注意的问题是，返回的函数并没有立刻执行，而是直到调用了f()才执行。我们来看一个例子:12345678910111213function count() &#123; var arr = []; for (var i=1; i&lt;=3; i++) &#123; arr.push(function () &#123; return i * i; &#125;); &#125; return arr;&#125;var results = count();var f1 = results[0];var f2 = results[1];var f3 = results[2]; 在上面的例子中，每次循环，都创建了一个新的函数，然后，把创建的3个函数都添加到一个Array中返回了。你可能认为调用f1()，f2()和f3()结果应该是1，4，9，但实际结果是:123f1(); // 16f2(); // 16f3(); // 16 全部都是16！原因就在于返回的函数引用了变量i，但它并非立刻执行。等到3个函数都返回时，它们所引用的变量i已经变成了4，因此最终结果为16。返回闭包时牢记的一点就是：返回函数不要引用任何循环变量，或者后续会发生变化的变量。如果一定要引用循环变量怎么办？方法是再创建一个函数，用该函数的参数绑定循环变量当前的值，无论该循环变量后续如何更改，已绑定到函数参数的值不变:123456789101112131415161718function count() &#123; var arr = []; for (var i=1; i&lt;=3; i++) &#123; arr.push((function (n) &#123; return function () &#123; return n * n; &#125; &#125;)(i)); &#125; return arr;&#125;var results = count();var f1 = results[0];var f2 = results[1];var f3 = results[2];f1(); // 1f2(); // 4f3(); // 9 注意这里用了一个”创建一个匿名函数并立刻执行”的语法:(function (x) { return x * x;})(3); // 9理论上讲，创建一个匿名函数并立刻执行可以这么写:1function (x) &#123; return x * x &#125; (3); 但是由于JavaScript语法解析的问题，会报SyntaxError错误，因此需要用括号把整个函数定义括起来:1(function (x) &#123; return x * x &#125;) (3); 通常，一个立即执行的匿名函数可以把函数体拆开，一般这么写:123(function (x) &#123; return x * x;&#125;)(3); 说了这么多，难道闭包就是为了返回一个函数然后延迟执行吗?当然不是！闭包有非常强大的功能。举个例子：在面向对象的程序设计语言里，比如Java和C++，要在对象内部封装一个私有变量，可以用private修饰一个成员变量。在没有class机制，只有函数的语言里，借助闭包，同样可以封装一个私有变量。我们用JavaScript创建一个计数器：123456789function create_counter(initial) &#123; var x = initial || 0; return &#123; inc: function () &#123; x += 1; return x; &#125; &#125;&#125; 它用起来像这样:12345678var c1 = create_counter();c1.inc(); // 1c1.inc(); // 2c1.inc(); // 3var c2 = create_counter(10);c2.inc(); // 11c2.inc(); // 12c2.inc(); // 13 在返回的对象中，实现了一个闭包，该闭包携带了局部变量x，并且，从外部代码根本无法访问到变量x。换句话说，闭包就是携带状态的函数，并且它的状态可以完全对外隐藏起来。闭包还可以把多参数的函数变成单参数的函数。例如，要计算xy可以用Math.pow(x, y)函数，不过考虑到经常计算x2或x3，我们可以利用闭包创建新的函数pow2和pow3:1234567891011&apos;use strict&apos;;function make_pow(n) &#123; return function (x) &#123; return Math.pow(x, n); &#125;&#125;// 创建两个新函数:var pow2 = make_pow(2);var pow3 = make_pow(3);console.log(pow2(5)); // 25console.log(pow3(7)); // 343","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"高阶函数","slug":"高阶函数","date":"2017-12-13T08:37:15.000Z","updated":"2019-05-29T14:03:53.000Z","comments":true,"path":"2017/12/13/高阶函数/","link":"","permalink":"http://ltyeamin.github.io/2017/12/13/高阶函数/","excerpt":"","text":"高阶函数概述高阶函数英文叫Higher-order function。那么什么是高阶函数？JavaScript的函数其实都指向某个变量。既然变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数。一个最简单的高阶函数: 12345function add(x, y, f) &#123; return f(x) + f(y);&#125;var x = add(-5, 6, Math.abs); console.log(x); // 11 当我们调用add(-5, 6, Math.abs)时，参数x，y和f分别接收-5，6和函数Math.abs，根据函数定义，我们可以推导计算过程为:123456//分析思路x = -5;y = 6;f = Math.abs;f(x) + f(y) ==&gt; Math.abs(-5) + Math.abs(6) ==&gt; 11;return 11; 编写高阶函数，就是让函数的参数能够接收别的函数. map/reduce举例说明，比如我们有一个函数f(x)=$x^2​$，要把这个函数作用在一个数组[1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用map实现如下图:由于map()方法定义在JavaScript的Array中，我们调用Array的map()方法，传入我们自己的函数，就得到了一个新的Array作为结果:12345678&apos;use strict&apos;;function pow(x) &#123; return x * x;&#125;var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9];var results = arr.map(pow); // [1, 4, 9, 16, 25, 36, 49, 64, 81]console.log(results); 注意：map()传入的参数是pow，即函数对象本身.你可能会想，不需要map()，写一个循环，也可以计算出结果:12345678var f = function (x) &#123; return x * x;&#125;;var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9];var result = [];for (var i=0; i&lt;arr.length; i++) &#123; result.push(f(arr[i]));&#125; 的确可以，但是，从上面的循环代码，我们无法一眼看明白“把f(x)作用在Array的每一个元素并把结果生成一个新的Array”。所以，map()作为高阶函数，事实上它把运算规则抽象了，因此，我们不但可以计算简单的f(x)=x2，还可以计算任意复杂的函数，比如，把Array的所有数字转为字符串：12var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9];arr.map(String); // [&apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;] 只需要一行代码。再看reduce的用法。Array的reduce()把一个函数作用在这个Array的[x1, x2, x3…]上，这个函数必须接收两个参数，reduce()把结果继续和序列的下一个元素做累积计算，其效果就是:1[x1, x2, x3, x4].reduce(f) = f(f(f(x1, x2), x3), x4) 比方说对一个Array求和，就可以用reduce实现1234var arr = [1, 3, 5, 7, 9];arr.reduce(function (x, y) &#123; return x + y;&#125;); // 25 要把[1, 3, 5, 7, 9]变换成整数13579，reduce()也能派上用场:1234var arr = [1, 3, 5, 7, 9];arr.reduce(function (x, y) &#123; return x * 10 + y;&#125;); // 13579 filterfilter也是一个常用的操作，它用于把Array的某些元素过滤掉，然后返回剩下的元素。和map()类似，Array的filter()也接收一个函数。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是true还是false决定保留还是丢弃该元素。例如，在一个Array中，删掉偶数，只保留奇数，可以这么写:12345var arr = [1, 2, 4, 5, 6, 9, 10, 15];var r = arr.filter(function (x) &#123; return x % 2 !== 0;&#125;);r; // [1, 5, 9, 15] 把一个Array中的空字符串删掉，可以这么写:12345var arr = [&apos;A&apos;, &apos;&apos;, &apos;B&apos;, null, undefined, &apos;C&apos;, &apos; &apos;];var r = arr.filter(function (s) &#123; return s &amp;&amp; s.trim(); // 注意：IE9以下的版本没有trim()方法&#125;);r; // [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;] 可见用filter()这个高阶函数，关键在于正确实现一个”筛选”函数. 回调函数filter()接收的回调函数，其实可以有多个参数。通常我们仅使用第一个参数，表示Array的某个元素。回调函数还可以接收另外两个参数，表示元素的位置和数组本身：1234567var arr = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;];var r = arr.filter(function (element, index, self) &#123; console.log(element); // 依次打印&apos;A&apos;, &apos;B&apos;, &apos;C&apos; console.log(index); // 依次打印0, 1, 2 console.log(self); // self就是变量arr return true;&#125;); 利用filter，可以巧妙地去除Array的重复元素:123456&apos;use strict&apos;;var r,arr = [&apos;apple&apos;, &apos;strawberry&apos;, &apos;banana&apos;, &apos;pear&apos;, &apos;apple&apos;, &apos;orange&apos;, &apos;orange&apos;, &apos;strawberry&apos;];r = arr.filter(function (element, index, self) &#123; return self.indexOf(element) === index;&#125;);console.log(r.toString()); //apple,strawberry,banana,pear,orange 去除重复元素依靠的是indexOf总是返回第一个元素的位置，后续的重复元素位置与indexOf返回的位置不相等，因此被filter滤掉了. sort排序算法排序也是在程序中经常用到的算法。无论使用冒泡排序还是快速排序，排序的核心是比较两个元素的大小。如果是数字，我们可以直接比较，但如果是字符串或者两个对象呢？直接比较数学上的大小是没有意义的，因此，比较的过程必须通过函数抽象出来。通常规定，对于两个元素x和y，如果认为x &lt; y，则返回-1，如果认为x == y，则返回0，如果认为x &gt; y，则返回1，这样，排序算法就不用关心具体的比较过程，而是根据比较结果直接排序。JavaScript的Array的sort()方法就是用于排序的，但是排序结果可能让你大吃一惊:123456// 看上去正常的结果:[&apos;Google&apos;, &apos;Apple&apos;, &apos;Microsoft&apos;].sort(); // [&apos;Apple&apos;, &apos;Google&apos;, &apos;Microsoft&apos;];// apple排在了最后:[&apos;Google&apos;, &apos;apple&apos;, &apos;Microsoft&apos;].sort(); // [&apos;Google&apos;, &apos;Microsoft&quot;, &apos;apple&apos;]// 无法理解的结果:[10, 20, 1, 2].sort(); // [1, 10, 2, 20] 第二个排序把apple排在了最后，是因为字符串根据ASCII码进行排序，而小写字母a的ASCII码在大写字母之后。第三个排序结果是什么鬼？简单的数字排序都能错？这是因为Array的sort()方法默认把所有元素先转换为String再排序，结果’10’排在了’2’的前面，因为字符’1’比字符’2’的ASCII码小。如果不知道sort()方法的默认排序规则，直接对数字排序，绝对栽进坑里！幸运的是，sort()方法也是一个高阶函数，它还可以接收一个比较函数来实现自定义的排序。要按数字大小排序，我们可以这么写:123456789101112&apos;use strict&apos;;var arr = [10, 20, 1, 2];arr.sort(function (x, y) &#123; if (x &lt; y) &#123; return -1; &#125; if (x &gt; y) &#123; return 1; &#125; return 0;&#125;);console.log(arr); // [1, 2, 10, 20] 如果要倒序排序，我们可以把大的数放前面:12345678910var arr = [10, 20, 1, 2];arr.sort(function (x, y) &#123; if (x &lt; y) &#123; return 1; &#125; if (x &gt; y) &#123; return -1; &#125; return 0;&#125;); // [20, 10, 2, 1] 默认情况下，对字符串排序，是按照ASCII的大小比较的，现在，我们提出排序应该忽略大小写，按照字母序排序。要实现这个算法，不必对现有代码大加改动，只要我们能定义出忽略大小写的比较算法就可以:123456789101112var arr = [&apos;Google&apos;, &apos;apple&apos;, &apos;Microsoft&apos;];arr.sort(function (s1, s2) &#123; x1 = s1.toUpperCase(); x2 = s2.toUpperCase(); if (x1 &lt; x2) &#123; return -1; &#125; if (x1 &gt; x2) &#123; return 1; &#125; return 0;&#125;); // [&apos;apple&apos;, &apos;Google&apos;, &apos;Microsoft&apos;] 忽略大小写来比较两个字符串，实际上就是先把字符串都变成大写（或者都变成小写），再比较。从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且，核心代码可以保持得非常简洁。最后友情提示，sort()方法会直接对Array进行修改，它返回的结果仍是当前Array:12345var a1 = [&apos;B&apos;, &apos;A&apos;, &apos;C&apos;];var a2 = a1.sort();a1; // [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]a2; // [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]a1 === a2; // true, a1和a2是同一对象","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"JS方法","slug":"JS方法","date":"2017-12-13T08:18:31.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2017/12/13/JS方法/","link":"","permalink":"http://ltyeamin.github.io/2017/12/13/JS方法/","excerpt":"","text":"对象的方法在一个对象中绑定函数，称为这个对象的方法。在JavaScript中，对象的定义是这样的:1234var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990&#125;; 但是，如果我们给xiaoming绑定一个函数，就可以做更多的事情。比如，写个age()方法，返回xiaoming的年龄:1234567891011var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;;xiaoming.age; // function xiaoming.age()xiaoming.age(); // 今年调用是25,明年调用就变成26了 绑定到对象上的函数称为方法，和普通函数也没啥区别，但是它在内部使用了一个this关键字，这个东东是什么?在一个方法内部，this是一个特殊变量，它始终指向当前对象，也就是xiaoming这个变量。所以，this.birth可以拿到xiaoming的birth属性。让我们拆开写：1234567891011function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: getAge&#125;;xiaoming.age(); // 25, 正常结果getAge(); // NaN 单独调用函数getAge()怎么返回了NaN？请注意，我们已经进入到了JavaScript的一个大坑里.JavaScript的函数内部如果调用了this，那么这个this到底指向谁?答案是，视情况而定!如果以对象的方法形式调用，比如xiaoming.age()，该函数的this指向被调用的对象，也就是xiaoming，这是符合我们预期的.如果单独调用函数，比如getAge()，此时，该函数的this指向全局对象，也就是window.坑爹啊!更坑爹的是，如果这么写:12var fn = xiaoming.age; // 先拿到xiaoming的age函数fn(); // NaN 也是不行的！要保证this指向正确，必须用obj.xxx()的形式调用！由于这是一个巨大的设计错误，要想纠正可没那么简单。ECMA决定，在strict模式下让函数的this指向undefined，因此，在strict模式下，你会得到一个错误:12345678910111213&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;;var fn = xiaoming.age;fn(); // Uncaught TypeError: Cannot read property &apos;birth&apos; of undefined 这个决定只是让错误及时暴露出来，并没有解决this应该指向的正确位置。有些时候，喜欢重构的你把方法重构了一下:1234567891011121314&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; function getAgeFromBirth() &#123; var y = new Date().getFullYear(); return y - this.birth; &#125; return getAgeFromBirth(); &#125;&#125;;xiaoming.age(); // Uncaught TypeError: Cannot read property &apos;birth&apos; of undefined 结果又报错了！原因是this指针只在age方法的函数内指向xiaoming，在函数内部定义的函数，this又指向undefined了！（在非strict模式下，它重新指向全局对象window！）修复的办法也不是没有，我们用一个that变量首先捕获this：123456789101112131415&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var that = this; // 在方法内部一开始就捕获this function getAgeFromBirth() &#123; var y = new Date().getFullYear(); return y - that.birth; // 用that而不是this &#125; return getAgeFromBirth(); &#125;&#125;;xiaoming.age(); // 25 用var that = this;，你就可以放心地在方法内部定义其他函数，而不是把所有语句都堆到一个方法中. apply方法详解虽然在一个独立的函数调用中，根据是否是strict模式，this指向undefined或window，不过，我们还是可以控制this的指向的！要指定函数的this指向哪个对象，可以用函数本身的apply方法，它接收两个参数，第一个参数就是需要绑定的this变量，第二个参数是Array，表示函数本身的参数。用apply修复getAge()调用:1234567891011function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: getAge&#125;;xiaoming.age(); // 25getAge.apply(xiaoming, []); // 25, this指向xiaoming, 参数为空 另一个与apply()类似的方法是call()，唯一区别是: apply()把参数打包成Array再传入; call()把参数按顺序传入.比如调用Math.max(3, 5, 4)，分别用apply()和call()实现如下:12Math.max.apply(null, [3, 5, 4]); // 5Math.max.call(null, 3, 5, 4); // 5 对普通函数调用，我们通常把this绑定为null. 装饰器利用apply()，我们还可以动态改变函数的行为。JavaScript的所有对象都是动态的，即使内置的函数，我们也可以重新指向新的函数。现在假定我们想统计一下代码一共调用了多少次parseInt()，可以把所有的调用都找出来，然后手动加上count += 1，不过这样做太傻了。最佳方案是用我们自己的函数替换掉默认的parseInt()：1234567891011121314&apos;use strict&apos;;var count = 0;var oldParseInt = parseInt; // 保存原函数window.parseInt = function () &#123; count += 1; return oldParseInt.apply(null, arguments); // 调用原函数&#125;;// 测试:parseInt(&apos;10&apos;);parseInt(&apos;20&apos;);parseInt(&apos;30&apos;);console.log(&apos;count = &apos; + count); // 3","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"变量作用域与解构赋值","slug":"变量作用域与解构赋值","date":"2017-12-13T07:04:21.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2017/12/13/变量作用域与解构赋值/","link":"","permalink":"http://ltyeamin.github.io/2017/12/13/变量作用域与解构赋值/","excerpt":"","text":"变量作用域在JavaScript中，用var申明的变量实际上是有作用域的。如果一个变量在函数体内部申明，则该变量的作用域为整个函数体，在函数体外不可引用该变量:12345function foo() &#123; var x = 1; x = x + 1;&#125;x = x + 2; // ReferenceError! 无法在函数体外引用变量x 如果两个不同的函数各自申明了同一个变量，那么该变量只在各自的函数体内起作用。换句话说，不同函数内部的同名变量互相独立，互不影响:123456789function foo() &#123; var x = 1; x = x + 1;&#125;function bar() &#123; var x = &apos;A&apos;; x = x + &apos;B&apos;;&#125; 由于JavaScript的函数可以嵌套，此时，内部函数可以访问外部函数定义的变量，反过来则不行:1234567function foo() &#123; var x = 1; function bar() &#123; var y = x + 1; // bar可以访问foo的变量x! &#125; var z = y + 1; // ReferenceError! foo不可以访问bar的变量y!&#125; 如果内部函数和外部函数的变量名重名怎么办？来测试一下:12345678910function foo() &#123; var x = 1; function bar() &#123; var x = &apos;A&apos;; console.log(&apos;x in bar() = &apos; + x); // &apos;A&apos; &#125; console.log(&apos;x in foo() = &apos; + x); // 1 bar();&#125;foo(); 这说明JavaScript的函数在查找变量时从自身函数定义开始，从“内”向“外”查找。如果内部函数定义了与外部函数重名的变量，则内部函数的变量将“屏蔽”外部函数的变量。 变量提升JavaScript的函数定义有个特点，它会先扫描整个函数体的语句，把所有申明的变量“提升”到函数顶部:1234567&apos;use strict&apos;;function foo() &#123; var x = &apos;Hello, &apos; + y; console.log(x); var y = &apos;Bob&apos;;&#125;foo(); 虽然是strict模式，但语句var x = ‘Hello, ‘ + y;并不报错，原因是变量y在稍后申明了。但是console.log显示Hello, undefined，说明变量y的值为undefined。这正是因为JavaScript引擎自动提升了变量y的声明，但不会提升变量y的赋值。对于上述foo()函数，JavaScript引擎看到的代码相当于:123456function foo() &#123; var y; // 提升变量y的申明，此时y为undefined var x = &apos;Hello, &apos; + y; console.log(x); y = &apos;Bob&apos;;&#125; 由于JavaScript的这一怪异的“特性”，我们在函数内部定义变量时，请严格遵守“在函数内部首先申明所有变量”这一规则。最常见的做法是用一个var申明函数内部用到的所有变量：12345678910function foo() &#123; var x = 1, // x初始化为1 y = x + 1, // y初始化为2 z, i; // z和i为undefined // 其他语句: for (i=0; i&lt;100; i++) &#123; ... &#125;&#125; 全局作用域不在任何函数内定义的变量就具有全局作用域。实际上，JavaScript默认有一个全局对象window，全局作用域的变量实际上被绑定到window的一个属性:1234&apos;use strict&apos;;var course = &apos;Learn JavaScript&apos;;alert(course); // &apos;Learn JavaScript&apos;alert(window.course); // &apos;Learn JavaScript&apos; 因此，直接访问全局变量course和访问window.course是完全一样的。你可能猜到了，由于函数定义有两种方式，以变量方式var foo = function () {}定义的函数实际上也是一个全局变量，因此，顶层函数的定义也被视为一个全局变量，并绑定到window对象:123456&apos;use strict&apos;;function foo() &#123; alert(&apos;foo&apos;);&#125;foo(); // 直接调用foo()window.foo(); // 通过window.foo()调用 进一步大胆地猜测，我们每次直接调用的alert()函数其实也是window的一个变量：12345678910&apos;use strict&apos;;window.alert(&apos;调用window.alert()&apos;);// 把alert保存到另一个变量:var old_alert = window.alert;// 给alert赋一个新函数:window.alert = function () &#123;&#125;alert(&apos;无法用alert()显示了!&apos;);// 恢复alert:window.alert = old_alert;alert(&apos;又可以用alert()了!&apos;); 这说明JavaScript实际上只有一个全局作用域。任何变量（函数也视为变量），如果没有在当前函数作用域中找到，就会继续往上查找，最后如果在全局作用域中也没有找到，则报ReferenceError错误. 名称空间全局变量会绑定到window上，不同的JavaScript文件如果使用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，并且很难被发现。减少冲突的一个方法是把自己的所有变量和函数全部绑定到一个全局变量中。例如:123456789// 唯一的全局变量MYAPP:var MYAPP = &#123;&#125;;// 其他变量:MYAPP.name = &apos;myapp&apos;;MYAPP.version = 1.0;// 其他函数:MYAPP.foo = function () &#123; return &apos;foo&apos;;&#125;; 把自己的代码全部放入唯一的名字空间MYAPP中，会大大减少全局变量冲突的可能。许多著名的JavaScript库都是这么干的：jQuery，YUI，underscore等等。 局部作用域由于JavaScript的变量作用域实际上是函数内部，我们在for循环等语句块中是无法定义具有局部作用域的变量的:12345678&apos;use strict&apos;;function foo() &#123; for (var i=0; i&lt;100; i++) &#123; // &#125; i += 100; // 仍然可以引用变量i&#125; 为了解决块级作用域，ES6引入了新的关键字let，用let替代var可以申明一个块级作用域的变量:12345678function foo() &#123; var sum = 0; for (let i=0; i&lt;100; i++) &#123; sum += i; &#125; // SyntaxError: i += 1;&#125; 常量由于var和let申明的是变量，如果要申明一个常量，在ES6之前是不行的，我们通常用全部大写的变量来表示“这是一个常量，不要修改它的值”:1var PI = 3.14; ES6标准引入了新的关键字const来定义常量，const与let都具有块级作用域:1234&apos;use strict&apos;;const PI = 3.14;PI = 3; // 某些浏览器不报错，但是无效果！PI; // 3.14 解构赋值从ES6开始，JavaScript引入了解构赋值，可以同时对一组变量进行赋值。什么是解构赋值？我们先看看传统的做法，如何把一个数组的元素分别赋值给几个变量:123456var array = [&apos;李彤&apos;, &apos;奕明创意传媒&apos;, &apos;艺术源于生活,但高于生活&apos;];//一般赋值方法var x = array[0];var y = array[1];var z = array[2];console.log(&apos;x : &apos; + x + &apos;, y : &apos; + y + &apos;, z : &apos; + z); //x : 李彤, y : 奕明创意传媒, z : 艺术源于生活,但高于生活 现在，在ES6中，可以使用解构赋值，直接对多个变量同时赋值:12var [x, y, z] = [&apos;Java&apos;, &apos;JavaScript&apos;, &apos;Python&apos;];console.log(&apos;x : &apos; + x + &apos;, y : &apos; + y + &apos;, z : &apos; + z); //x : Java, y : JavaScript, z : Python 注意，对数组元素进行解构赋值时，多个变量要用[…]括起来。如果数组本身还有嵌套，也可以通过下面的形式进行解构赋值，注意嵌套层次和位置要保持一致:1234let [x, [y, z]] = [&apos;hello&apos;, [&apos;JavaScript&apos;, &apos;ES6&apos;]];x; // &apos;hello&apos;y; // &apos;JavaScript&apos;z; // &apos;ES6&apos; 解构赋值还可以忽略某些元素：12let [, , z] = [&apos;hello&apos;, &apos;JavaScript&apos;, &apos;ES6&apos;]; // 忽略前两个元素，只对z赋值第三个元素z; // &apos;ES6&apos; 如果需要从一个对象中取出若干属性，也可以使用解构赋值，便于快速获取对象的指定属性:12345678910var person = &#123; name: &apos;旺财&apos;, age: 20, gender: &apos;male&apos;, passport: &apos;G-12345678&apos;, school: &apos;No.4 middle school&apos;&#125;;var &#123;name, age, passport&#125; = person;// name, age, passport分别被赋值为对应属性:console.log(&apos;name = &apos; + name + &apos;, age = &apos; + age + &apos;, passport = &apos; + passport); //name = 旺财, age = 20, passport = G-12345678 对一个对象进行解构赋值时，同样可以直接对嵌套的对象属性进行赋值，只要保证对应的层次是一致的:123456789101112131415161718var person = &#123; name: &apos;小强&apos;, age: 20, gender: &apos;male&apos;, passport: &apos;G-12345678&apos;, school: &apos;No.4 middle school&apos;, address: &#123; city: &apos;Beijing&apos;, street: &apos;No.1 Road&apos;, zipcode: &apos;100001&apos; &#125;&#125;;var &#123;name, address: &#123;city, zip&#125;&#125; = person;name; // &apos;小强&apos;city; // &apos;Beijing&apos;zip; // undefined, 因为属性名是zipcode而不是zip// 注意: address不是变量，而是为了让city和zip获得嵌套的address对象的属性:address; // Uncaught ReferenceError: address is not defined 使用解构赋值对对象属性进行赋值时，如果对应的属性不存在，变量将被赋值为undefined，这和引用一个不存在的属性获得undefined是一致的。如果要使用的变量名和属性名不一致，可以用下面的语法获取:1234567891011121314var person = &#123; name: &apos;小强&apos;, age: 20, gender: &apos;male&apos;, passport: &apos;G-12345678&apos;, school: &apos;No.4 middle school&apos;&#125;;// 把passport属性赋值给变量id:let &#123;name, passport:id&#125; = person;name; // &apos;小强&apos;id; // &apos;G-12345678&apos;// 注意: passport不是变量，而是为了让变量id获得passport属性:passport; // Uncaught ReferenceError: passport is not defined 解构赋值还可以使用默认值，这样就避免了不存在的属性返回undefined的问题:1234567891011var person = &#123; name: &apos;小强&apos;, age: 20, gender: &apos;male&apos;, passport: &apos;G-12345678&apos;&#125;;// 如果person对象没有single属性，默认赋值为true:var &#123;name, single=true&#125; = person;name; // &apos;小强&apos;single; // true 有些时候，如果变量已经被声明了，再次赋值的时候，正确的写法也会报语法错误:12345// 声明变量:var x, y;// 解构赋值:&#123;x, y&#125; = &#123; name: &apos;小强&apos;, x: 100, y: 200&#125;;// 语法错误: Uncaught SyntaxError: Unexpected token = 这是因为JavaScript引擎把{开头的语句当作了块处理，于是=不再合法。解决方法是用小括号括起来:1(&#123;x, y&#125; = &#123; name: &apos;小强&apos;, x: 100, y: 200&#125;); 解析赋值使用场景 解构赋值在很多时候可以大大简化代码。例如，交换两个变量x和y的值，可以这么写，不再需要临时变量: 12var x=1, y=2;[x, y] = [y, x] 快速获取当前页面的域名和路径: 123var &#123;hostname:domain, pathname:path&#125; = location;domain //&quot;ltyeamin.github.io&quot;path // &quot;/2017/12/04/JS%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%E5%92%8C%E8%B0%83%E7%94%A8/&quot; 如果一个函数接收一个对象作为参数，那么，可以使用解构直接把对象的属性绑定到变量中。例如，下面的函数可以快速创建一个Date对象: 123function buildDate(&#123;year, month, day, hour=0, minute=0, second=0&#125;) &#123; return new Date(year + &apos;-&apos; + month + &apos;-&apos; + day + &apos; &apos; + hour + &apos;:&apos; + minute + &apos;:&apos; + second);&#125; 它的方便之处在于传入的对象只需要year、month和day这三个属性: 1buildDate(&#123; year: 2017, month: 12, day: 4 &#125;); // Mon Dec 04 2017 00:00:00 GMT+0800 (中国标准时间) 也可以传入hour、minute和second属性: 1buildDate(&#123; year: 2017, month: 1, day: 1, hour: 20, minute: 15 &#125;); // Sun Jan 01 2017 20:15:00 GMT+0800 (中国标准时间) 使用解构赋值可以减少代码量，但是，需要在支持ES6解构赋值特性的现代浏览器中才能正常运行。目前支持解构赋值的浏览器包括Chrome，Firefox，Edge等.","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]},{"title":"JS函数定义和调用","slug":"JS函数定义和调用","date":"2017-12-04T13:53:01.000Z","updated":"2019-05-29T14:03:52.000Z","comments":true,"path":"2017/12/04/JS函数定义和调用/","link":"","permalink":"http://ltyeamin.github.io/2017/12/04/JS函数定义和调用/","excerpt":"","text":"定义函数JavaScript函数时参数化的,并且每次调用还会有个上下文(this关键字).如果函数挂载在一个对象上,作为对象的一个属性,那就是对象的方法.JS的函数可以嵌套在其他函数中定义,这样它们就可以访问它们被定义时所处的作用域中的任何遍历.这意味着JS函数构成了一个闭包(closure).在JavaScript中，定义函数的方式如下:1234567function abs(x) &#123; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125; 上述abs()函数的定义如下: function指出这是一个函数定义; abs是函数的名称; 括号内列出函数的参数，多个参数以,分隔; {…}之间的代码是函数体，可以包含若干语句，甚至可以没有任何语句。 请注意，函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回。因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。如果没有return语句，函数执行完毕后也会返回结果，只是结果为undefined。由于JavaScript的函数也是一个对象，上述定义的abs()函数实际上是一个函数对象，而函数名abs可以视为指向该函数的变量。因此，第二种定义函数(匿名函数)的方式如下：1234567var abs = function (x) &#123; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125;; 在这种方式下，function(x){…}是一个匿名函数，它没有函数名。但是，这个匿名函数赋值给了变量abs.所以,通过变量abs就可以调用该函数。上述两种定义完全等价，注意第二种方式按照完整语法需要在函数体末尾加一个;，表示赋值语句结束。 调用函数调用函数时，按顺序传入参数即可:12abs(10); // 返回10abs(-9); // 返回9 由于JavaScript允许传入任意个参数而不影响调用，因此传入的参数比定义的参数多也没有问题(强类型语言不允许)，虽然函数内部并不需要这些参数:12abs(10, &apos;blablabla&apos;); // 返回10abs(-9, &apos;haha&apos;, &apos;hehe&apos;, null); // 返回9 传入的参数比定义的少也没有问题:1abs(); // 返回NaN 此时abs(x)函数的参数x将收到undefined，计算结果为NaN。要避免收到undefined，可以对参数进行检查:12345678910function abs(x) &#123; if (typeof x !== &apos;number&apos;) &#123; throw &apos;Not a number&apos;; &#125; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125; argumentsJavaScript还有一个免费赠送的关键字arguments，它只在函数内部起作用，并且永远指向当前函数的调用者传入的所有参数。arguments类似Array但它不是一个Array:1234567function sayHello () &#123; //验证arguments封装了所有的调用参数 for (var i = 0; i &lt; arguments.length; i++) &#123; console.log(&apos;arg&apos; + i +&apos; = &apos; + arguments[i]) &#125;&#125;sayHello(&apos;李彤&apos;,22,&apos;上海&apos;,&apos;Java-JavaScript-Python&apos;); 利用arguments，你可以获得调用者传入的所有参数。也就是说，即使函数不定义任何参数，还是可以拿到参数的值.实际上arguments最常用于判断传入参数的个数。你可能会看到这样的写法:12345678910// foo(a[, b], c)// 接收2~3个参数，b是可选参数，如果只传2个参数，b默认为null：function foo(a, b, c) &#123; if (arguments.length === 2) &#123; // 实际拿到的参数是a和b，c为undefined c = b; // 把b赋给c b = null; // b变为默认值 &#125; // ...&#125; 要把中间的参数b变为“可选”参数，就只能通过arguments判断，然后重新调整参数并赋值。 rest参数由于JavaScript函数允许接收任意个参数，于是我们就不得不用arguments来获取所有参数:1234567891011function foo(a, b) &#123; var i, rest = []; if (arguments.length &gt; 2) &#123; for (i = 2; i&lt;arguments.length; i++) &#123; rest.push(arguments[i]); &#125; &#125; console.log(&apos;a = &apos; + a); console.log(&apos;b = &apos; + b); console.log(rest);&#125; 为了获取除了已定义参数a、b之外的参数，我们不得不用arguments，并且循环要从索引2开始以便排除前两个参数，这种写法很别扭，只是为了获得额外的rest参数，有没有更好的方法?ES6标准(注意浏览器是否支持ES6)引入了rest参数，上面的函数可以改写为:1234567891011121314151617function foo(a, b, ...rest) &#123; console.log(&apos;a = &apos; + a); console.log(&apos;b = &apos; + b); console.log(rest);&#125;foo(1, 2, 3, 4, 5);// 结果:// a = 1// b = 2// Array [ 3, 4, 5 ]foo(1);// 结果:// a = 1// b = undefined// Array [] rest参数只能写在最后，前面用…标识，从运行结果可知，传入的参数先绑定a、b，多余的参数以数组形式交给变量rest，所以，不再需要arguments我们就获取了全部参数。如果传入的参数连正常定义的参数都没填满，也不要紧，rest参数会接收一个空数组(注意不是undefined)。 小心你的return语句JavaScript引擎有一个在行末自动添加分号的机制，这可能让你栽到return语句的一个大坑:12345function foo() &#123; return &#123; name: &apos;foo&apos; &#125;;&#125;foo(); // &#123; name: &apos;foo&apos; &#125; 如果把return语句拆成两行:123456function foo() &#123; return &#123; name: &apos;foo&apos; &#125;;&#125;foo(); // undefined 要小心了，由于JavaScript引擎在行末自动添加分号的机制，上面的代码实际上变成了:1234function foo() &#123; return; // 自动添加了分号，相当于return undefined; &#123; name: &apos;foo&apos; &#125;; // 这行语句已经没法执行到了&#125; 所以正确的多行写法是:12345function foo() &#123; return &#123; // 这里不会自动加分号，因为&#123;表示语句尚未结束 name: &apos;foo&apos; &#125;;&#125;","categories":[{"name":"frontend","slug":"frontend","permalink":"http://ltyeamin.github.io/categories/frontend/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://ltyeamin.github.io/tags/JavaScript/"}]}]}